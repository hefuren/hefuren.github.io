<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2Fblog%2F4a17b156.html</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PMO建设的思考]]></title>
    <url>%2Fblog%2Fee47eef0.html</url>
    <content type="text"><![CDATA[PMO，即项目管理办公室的简称。行业里面，PMO类型一般分为如下三种： 支持型：担当顾问的角色，向项目提供模板、最佳实践、培训、信息通道、以及来自其他经验教训。它对项目的控制程度很低，甚至对项目无控制权。（在企业中，支持型PMO大多数对项目无控制权） 控制型：不仅给项目提供支持，而且通过各种手段要求项目服从，它对项目的控制程度属于中等。 指令型：直接管理或控制项目，它对项目的控制程度很高；项目经理由PMO指定并向其报告。 之前从事研发项目管理工作，担任项目经理角色，最近转身从事PMO工作，简单谈下个人对PMO工作的理解和认识。PMO主要工作职责：项目管理能力建设、项目治理、项目管理IT系统建设。 项目管理能力建设公司组织级项目管理能力建设，包括：项目管理流程建设、项目经理能力培养、项目运营/监控、项目治理。 #####1、项目管理流程建设 每个公司有不同的业务形态，不同的组织阵型，需根据实际业务，建设或选择合适的业务流程和项目管理流程。项目管理流程的建设，不能脱离和独立于业务，需对业务服务。项目管理流程的建设，可参考PMI PMBOK中项目管理十大知识域来定义各角色的参与的活动。 项目管理活动定义示意： 序号 阶段 活动 角色 活动描述 输入 交付件 1 项目启动 创建项目 项目经理 在xx项目管理系统中填写项目基本信息，完成项目创建。 项目立项决策函、项目立项材料等 完成项目创建 2 项目启动 项目编码申请 项目经理 完善项目人力、费用、项目里程碑计划等信息，提交并完成项目编码申请 项目立项材料等 完成项目编码申请 3 项目启动 组建项目核心团队 项目经理 组建项目核心团队，发布项目任命，明确项目各关键角色职责 4 …… …… …… …… …… …… 5 …… …… …… …… …… …… 注：项目管理流程活动，属于业务流程活动的子集。项目管理流程活动侧重在与项目管理业务相关的活动上，流程定义时，注意区别。 流程建设并非一蹴而就，流程成熟度一般分为5个等级（初始级、已管理级、已定义级、已量化级、可持续优化级），因此企业需要持续运营、持续优化。 项目管理流程定义后，通过项目管理办公室（PMO）进行流程正式发布。流程发布后，各部门遵照执行。建议每年针对项目管理流程或业务流程开展1 ~ 2次流程过程和交付件审核，同时每年11~12月可以组织进行一次流程成熟度评估。通过流程过程&amp;交付件审核和流程成熟度评估，识别问题并持续改进。 小经验：企业项目管理流程建设一般会涉及：《项目管理过程与交付件》、《代码分支管理规范》、《项目编码/命名规范》、《项目变更管理PCR规范》、《分层授权规范》、《项目管理流程成熟度评估问卷》等定义。 未完，待补充。]]></content>
      <categories>
        <category>项目管理</category>
      </categories>
      <tags>
        <tag>项目管理</tag>
        <tag>PMO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[10年回首]]></title>
    <url>%2Fblog%2F7d700905.html</url>
    <content type="text"><![CDATA[转眼间，2017已逝去，迎来了2018。从踏出校园的大门开始，已经过去了10个春秋。在过去的这10年里，人生行走的轨迹已与当初理想有了很大的不一样。这就是理想很丰满，现实很骨感。 大学四年学的专业是机械设计制造及自动化，毕业时却任性的选择从事计算机相关的工作。当初以为自己在计算机领域比较擅长，现在看来，其实自己也就芸芸众生而已。从机械专业跨入计算机/IT行业，不管现在怎么样，内心里还是要感谢涂海宁老师的。通过涂老师的推荐，进入了泰豪软件，才有了后来在计算机/IT行业摸爬滚打的经历。 2007年毕业季，所有同学都找本专业的工作。我做了一个C#的毕业设计，考了个计算机三级（数据库）认证，自学了写Java基础知识，就任性的找计算机相关的工作。不是科班出生，没有系统化的学过计算机所有的课程，面试屡屡碰壁。毕业的时候，所有的同学都收到了offer，只有我一个人还在找工作。这个时候，涂老师叫我跟着他做项目，想也没多想就答应。跟着涂老师做项目也就近两个月的时间，学了一些基础的C#。后来涂老师在江联的项目没有接下来，无奈之中，就找了南昌大学和泰豪软件合作的机会，把我推荐到了泰豪软件。自此正式正规的进入了软件行业。 在泰豪软件的前两个月，参与了江西省电力公司的线损管理系统的开发工作。主要是基于原有的线损管理系统，做一些定制化的报表。当时所用的编程语言是C#，那个时候C#也就学了几个月而已。买了一本微软的红皮书，不懂就翻翻，也算把项目支撑下来，并交付了。项目结束后，个人想从事Java的开发，于是选择了Java项目组，进而从C#转入了Java领域。在泰豪的软件的时间不长，前前后后差不多一年的时间，也得到领导和同事的认可。后来想去深圳发展，就辞职离开了南昌。 2008年6月，从南昌来了深圳。现在想想以前，都佩服自己那是的魄力。找了同学落了脚，也没怎么休息调整，便开始四处投简历找工作。起初的两天里面，没有任何面试电话。后来每天基本都面试一两家公司。第一次出来找工作，也不了解各公司的招聘流程。面试了近一个星期，都无果。那时多少有点自信心被打击。在一个周六的时候，忽然收到一家公司的电话，说面试通过了。同一天下午，又收到另一家公司的电话，面试也通过了。那个时候有些喜出望外，顿时整个人轻松许多。在两家公司比较之后，毅然选择了一家仅5个人的创业公司。后来在这家创业公司一呆就是6年。 在这６年里，自己得到了不少的成长。做了两年的软件开发，4年的项目交付，接触了许多行业和客户，项目交付期间也得到不少客户的赞许。这6年横向发展了许多，了解了项目管理如何管，软件研发流程涉及的领域：配置管理、需求管理、项目管理、版本管理等。这6年里，过得很忙碌且充实。 有了这６年的沉淀，也使得自己有幸加入了HW。HW这3年里，经历了4次换部门，4次换领导，3次专业任职从头开始，很是无奈。现实并不总是自己希望的那样好，但人总是要朝前看。无论怎么，生活总会继续，自己唯有努力才行。幸福总是努力得到的，不会唾手可得。]]></content>
      <categories>
        <category>心情札记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[大学札记（回忆篇）]]></title>
    <url>%2Fblog%2F8f2159dc.html</url>
    <content type="text"><![CDATA[时间飞逝，大学四年生活即将结束，回忆起这四年的经历，其间有着许许多多美好的回忆，为了不想让记忆淡去，为此写下这篇文章，算是给自己留下追忆的痕迹。 先说说我是如何踏上这段旅途的。在我五岁半时，同一条街的孩子们都上学了，我一个人没得玩，于是便嚷着父母让我去上学，就这样我便开始上学了。从上学的第一天起，父母就灌输我思想，要好好学习，长大了才有出息。当时自己也没理会太多，不过在学校里表现还算出类拔萃，就这样理所当然的小学升初中，初中升到市里的重点高中。可是直到读到高二的时候，我还不知道我为什么读高中（当时就认为这是自然的事吧）。等到上了高三，自己才有种恍悟的感觉，原来这一切是为了考大学。至此之后才发现自己有了自己的思想，于是学习变得主动而有趣了。然，第一年的高考，自己考得很不理想，没能上重点，于是便打算复读。当时父亲挺支持我的（母亲和舅舅一帮亲戚则劝我上二本算了），现在回想起来，很是感谢父亲，要不现在的我走的将是另一条路了。经过一 年准备后，迎来了第二次高考，宁我叹息的是，在第二次高考中我发挥还是有欠水准，自己理想的学府没去成，还好当时成绩已过本省重点线，就这样我以超出重点50多分被南昌大学捡到这里来了。 南昌大学确实算不上什么名校，又不是985重点高校，但当时的想法很简单了，因为她毕竟也还是211重点院校，我所学的专业机械设计制造及自动化属于工科专业，自己也还算喜欢，于是我欣然地接受了，父母也欣然地接受了，算是圆了他们的梦，就这样我来到了这里。 03年10月9日那天，父亲送我来学校的路上，我们挤在拥挤的列车车厢里，面对着一个个陌生的面孔，这些都是外出打工的人们，看着他们，我感受到了生活中的艰辛，这一刻心中感到很痛楚，因为想到了父母这十多年来的劳苦，他们为了我，太辛苦了。那一刻起我便在心中对自己说，我要好好经营大学四年时光，不为自己，也要为报答父母辛苦的付出。那一刻自己长大了许多。 大学第一个学期里，学习时间较短。我们10月10日报到，之后便进行半个月的军训，直到11月1日才开始正式上课的。当时我们住在的新校区刚刚落成，学校里的教学设施还不齐备，于是我和所有的大一新生一样，按部就班地过着大学里最轻松自由的生活。也是在这一最轻松自由的日子里我完整地看完了两本书，《一切从大学出发》和《假如给我三天光明》。《一切从大学出发》一书，很适合大一新生阅读，它教会我要好好珍惜大学时光，不要给自己留下遗憾。书中有这样一段话我很喜欢：30岁之前是要做“怎么思考”这个事情，30岁之后才真正创业，决定自己一辈子要干哪种事业。有前面的思考作基础，以后干起事情来，很可能会事半功倍。《假如给我三天光明》一书看了之后，颇受主人公海伦·凯勒的感染。她一个盲、聋、哑的人，竟毕业于哈佛大学克利夫学院，不能不说是奇迹。她那不屈不挠的精神，惊人的毅力的确很值得我去学习。看过她的事迹后，再遇到什么困难挫折，想想她便觉得一切都是那么的渺小。第一学期的生活，除了学习娱乐之外，便以看完两本书而结束了。迎来是另一个新学期的开始。 第二个学期开始在和煦的春天，不过我们住在的这新校区，看不到春天焕然的景象，这儿仅有的是那一块块黄土地，也难怪我们这一届有学生称这片土地为“南大荒”。其实这也没什么不好的，最起码我们鉴定着学校的修建历程。学校的环境虽没看到春天的气息，但可以从我们身上找寻到青春的活力。记得在 04年2月28日那天我们班上有一场足球赛，可是天公不作美，下起小雨来。原本我们打算取消比赛的，然对方球队坚持比赛，没办法，我们只能应战。说实话当时我心里是那个的不愿淋雨踢球的。可上场后，自己完全熔入比赛中了，有种很强的意志力和一种必胜的信心在驱动着自己在球场中拼搏，在球场中激进。比赛最后以0 ：0打平了，大家带着一身的泥和满脸的愉悦在雨中留下了合影。在后来的比赛中，在球场中依然可以找到我的身影。在那个充满生机的春天里，我们活得很有活力。现在回想起来，当时的那种精神已不复在，打心底的很怀念那球场中的一幕一幕，很怀念我们的那支球队，很怀念和对友们在一起的日子。 这个学期里活动可谓是多呀！除了学校里的足球联赛外，04年3月28日那天，班上还组织我们到南昌附近的小庐山——梅岭去春游。其实个人觉得除了天下一绝的黄山外，我更多的还是喜欢贵州的山。反正没什么了，就跟他们去踏踏青，呼吸下大自然的清新空气了。这次游玩中印象中最深的有二，其一是我们在划竹筏在湖中打水仗了。当时树敌太多，结果遭到多方攻击，那个惨样现在想起来真狼狈呀。其二便是当我登上梅岭最高峰狮子峰时，站在最高处呼喊我的座右铭：“海到尽头天作岸，山临绝顶我为峰”时别有一种说不出来的气概和心情。 这学期里活动是很丰富的，学习上我也没放松。这学期增开了一门大学物理课，经过那年补习之后，我对物理便产生了兴趣，所以尽管大学物理不是我们专业课和基础课，但我还是很认真的学习。当时学校里举行南昌大学首届大学物理竞赛，我自然是积极参加了。不过在5月份的期中考试中，我物理成绩竟然没有及格，真是倍受打击。于是在那段日子里，我天天坚持去上自习，认真复习，终于在物理竞赛中获得了二等奖。总算没有白费自己的努力，算是对得起自己了，也对得住饶志刚（高中物理老师）了。 第二个学期的丰富精彩生活便走过了。 悄然而来的大二学年生活便接着开始了，回忆起这一的学习生活，可算是大学中过得最充实的一年了。这一年里忙碌着辅修计算机科学与技术第二专业和全身心的投入数学建模竞赛。说真的，对于辅修第二专业，当时报名时真是想认真学点东西，等发下书来后，让我大失所望。所学课程就是几款常用软件的应用，和VB、Java和网络技术。辅修课和公共选修课其实差不多，无非就是花钱买个证书。说真的，在这里我没学到很有用的东西，而后Java的学习完全是自学的。不过大二学年精彩生活不在这里，而在后期的数学建模竞赛的过程中。说真的，当时参加这个竞赛还真要感谢魏巍，最初我并不那么热情于数学建模（主要是当时还忙于其他事），后来再他的说服下答应了他，于是我们找了另一个队友刘建珍一起参加当时的南昌大学举办的大学生数学建模竞赛。在我们三个人中，刘建珍的悟性算是最高的了（计算机系第一，后保送哈工大研究生），魏巍吗，说句实话就只能听我俩说后组织语言写论文。6月6日那天，卷子发下来后我们就各自拿了份卷子先做做，等第二天在相互讨论。题目是关于最优化的问题，虽然不是很难，但要解的未知数有三四十个，普通的笔算是不可能解答出来的。在第二天的讨论过程中，我和队长刘建珍的思路完全吻合，而且她已经把方程都已经列出来了，于是我们就以她所列的方程开始想方法解题。最初，数学软件我不会用，那时只有寄以希望在小队长身上了，希望她能用C语言编个算法把问题给解决了。到了第三天6月8日，小队长那里还是没什么进展，估计是解不出来了的。而有其他组已经先把题目给解出来了，当时我们备感压力，于是那天下午没课，我找了本书，现学Lingo的应用。研习了一个下午和晚上的时间，总算让我找到了行之有效的方法，当时的感觉只有那么好了。有了思路了后，于6月9日中午时我就把方程的30多个未知数给解出来了，并且得到了所需的最优化结果。这样剩下来的工作就是论文的写作了。这个可是重中之重呢，不管你做得再好，给人看的就只是这篇论文，所以怎样表示出你的思想才是重要的。自上大学后，我就很少动笔了，感觉自己文笔太差，于是我就把这个责任推给了魏巍。当时我们团队还是比较团结的，大家都很进心，在后来论文写作上，大家彼此协作，我负责画流程图，他们负责撰写论文，最后大家在统一修订。忙碌整整一个星期，总算按时完成了工作。在后来的结果中，总算不负我们的努力，我们队拿了校内一等奖，这样为后面入围全国大学生数学建模竞赛起到了关键性作用。 为了能代表学校参加这一年的全国大学生数学建模竞赛,那一年暑假我们把它奉献出来了。就这样，在炎热的7月里，我们参加了赛前培训。培训的过程中，老师除了给我们介绍新颖的数学解题方法和思想外，还给我们重点介绍了Matlab,lingo和Mathematica三款数学软件的使用。在那段时间里，早上我们听课，下午学习软件的使用，晚上则实战演练具体的题目。我们的团队在当时整个建模的前期工作中一直都表现得很出色。有队长敏捷的思维和严密的逻辑分析能力，有魏巍的语言组织能力，再加上我对软件的熟悉，这样对于每个实际问题的解决我们都能游刃有余。最开始这样的表现，让我们在赛前感到无比的自信，当时对参赛寄的希望就是拿个全国奖，但后来的结果并非我们所期望的那样，最后我们仅仅拿了个江西省二等奖，对于我们来说有些遗憾。但结果并不是重要的，重要的是我们曾经参与在其中的乐趣。现在回想起那不眠的72小时的经历，真是历历在目，当时的激情真是无可比。总的来说，这学年里给我收获最多就是数模，同时也让我交了两个朋友，一个我队长刘建珍，一个何彦宁。他们在我们后来的学习和生活中都给了不少的帮助和鼓励。 大二学年生活可以完美的划下句号，接着大三的学习生活是我人生的一个转折点。…… ………… ………… ……]]></content>
      <categories>
        <category>心情札记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[The Girl To Slip Through My Fingers]]></title>
    <url>%2Fblog%2F2bddb782.html</url>
    <content type="text"><![CDATA[I have not been knowing which way to go very much all the time for a period of time, can’t look for myself direction. An important reason which myself is fettered for a girl. Hey, it is strange to think about, I who am always opinionated will be fettered by this so-called emotion too. Assume as a matter of course always by I since always think how it is, but non- so fact. Did not know until today , the person at my side did not treasure , had known regretting already late while waiting until losing originally. The girl missing is not coming back , I only bless her, Right, the cardialgia feeling only goes to have a trial test by myself. Night is silent, my heart should be silent too. Think carefully what , for whom I really pursue in this period of time.The girl to slip through my fingers can not back my side, I can’t stay in the past forever . Has looked for a job since last year, it is indefinite to walk back and forth all the time till now, more or less the factor to consider her. She has already left me now, I prepare for myself hard, future is myself after all, I must become a strong-minded person , can’t give up the future of all my life because of some setbacks of emotion . By Elwin HeDate at 2007-04-10 21:31:35]]></content>
      <categories>
        <category>心情札记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[开启“潘多拉魔盒”之旅——启章]]></title>
    <url>%2Fblog%2F6bbf70d1.html</url>
    <content type="text"><![CDATA[开启“潘多拉魔盒”（树莓派+DuerOS）之旅——启章序曲 离开一线程序开发已经有几年了，虽然工作不再接触程序开发的工作。但是一直有颗程序员的心。总爱躁动地看看这个世界，关注软件开发前沿技术和新闻。 今年７月份，百度在开发者大会上正式推出全新的ＤuerOS系统后，关注了一段时间，待百度向开发者提供“DuerOS开发套件个人版”时，便毫不犹豫的提交了申请。其实，早在7月11日时，就得收到了百度的邮件回复，要求提供DuerOS开发套件个人版需求（开发计划和产品需求）。由于工作的原因，迟迟没有提交需求申请，直到9月17日才提交需求申请。然等了一个星期，仍未收到任何回复，于是又多次提交了需求申请，最后还是杳无音信。本以为需求审核不通过，或者百度不再提供开发版了。后来在DuerOS公众号上看到百度又派发了个人套件开发版，然后就留言问了问。后来跟公众号运营人员沟通后，重新让他们确认了我提交的邮件，随即派送了开发版。（MD，猜测之前提交N多申请时，邮件可能被他们忽略了，或者被收到垃圾邮箱了，才杳无音信） 于是便开启了“潘多拉魔盒”之旅。 “旅程装备”准备 “潘多拉魔盒”之旅会怎样的呢？得准备好装备，才能看清这个奇幻＋充满想象的世界。 参考百度《DuerOS开发套件个人版软件安装使用指南 v1.0.pdf》说明，准备装备如下： 电脑：用来烧录SD卡，为树莓派烧录系统 SD卡及读卡器：准备一张容量大于8GB的Micro SD卡及读卡器 USB转Micro USB数据线：准备好两个数据线，一根用于连接树莓派与DuerOS开发版，一根作为USB电源线。 外接音箱 树莓派3B ＤuerOS开发版已有，其它的备件哪里找呢？俗话说：外事不决问百度，内事不决问老婆。买东西，自然让淘宝/天猫了，哈哈。赶紧下单，坐等收货…… …… …… 快递火箭哥终于把装备送到。 组装装备+刷系统 装备到手了，可参看《DuerOS开发套件个人版软件安装使用指南 v1.1.pdf》组装树莓派和开发版。然后可到https://etcher.io/网站下载Etcher软件，用于将DuerOS开发套件个人版镜像文件烧录到SD卡中。同时下载DuerOS系统镜像文件 。 传送门直达：DuerOS文档 ，DuerOS系统镜像 最后完工如下图所示： 个人在这里有一个入坑的地方：忘记用USB转Micro USB数据线连接DuerOS开发版和树莓派了，导致树莓派上电启动后，无法唤醒“小度”。 上电，唤醒小度，感受潘多拉魔盒的魔力 接上电源，树莓派自动启动，这个时候可以下载一个“小度之家”App，便于配置无线网络功能。待无线网络配置成功后，重启树莓派，期间就可以听到小度的说话，待系统启动完毕后，小度会给予提示。系统启动完毕后，便可以唤醒小度，开启潘多拉魔盒唤醒万物的体验。]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>DuerOS</tag>
        <tag>树莓派</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【转】RESTful架构详解]]></title>
    <url>%2Fblog%2Fda71840e.html</url>
    <content type="text"><![CDATA[转自：http://www.runoob.com/w3cnote/restful-architecture.html 1. 什么是REST REST全称是Representational State Transfer，中文意思是表述（编者注：通常译为表征）性状态转移。 它首次出现在2000年Roy Fielding的博士论文中，Roy Fielding是HTTP规范的主要编写者之一。 他在论文中提到：”我这篇文章的写作目的，就是想在符合架构原理的前提下，理解和评估以网络为基础的应用软件的架构设计，得到一个功能强、性能好、适宜通信的架构。REST指的是一组架构约束条件和原则。” 如果一个架构符合REST的约束条件和原则，我们就称它为RESTful架构。 REST本身并没有创造新的技术、组件或服务，而隐藏在RESTful背后的理念就是使用Web的现有特征和能力， 更好地使用现有Web标准中的一些准则和约束。虽然REST本身受Web技术的影响很深， 但是理论上REST架构风格并不是绑定在HTTP上，只不过目前HTTP是唯一与REST相关的实例。 所以我们这里描述的REST也是通过HTTP实现的REST。 2. 理解RESTful要理解RESTful架构，需要理解Representational State Transfer这个词组到底是什么意思，它的每一个词都有些什么涵义。 下面我们结合REST原则，围绕资源展开讨论，从资源的定义、获取、表述、关联、状态变迁等角度，列举一些关键概念并加以解释。 资源与URI 统一资源接口 资源的表述 资源的链接 状态的转移 2. 1 资源与URIREST全称是表述性状态转移，那究竟指的是什么的表述? 其实指的就是资源。任何事物，只要有被引用到的必要，它就是一个资源。资源可以是实体(例如手机号码)，也可以只是一个抽象概念(例如价值) 。下面是一些资源的例子： 某用户的手机号码 某用户的个人信息 最多用户订购的GPRS套餐 两个产品之间的依赖关系 某用户可以办理的优惠套餐 某手机号码的潜在价值 要让一个资源可以被识别，需要有个唯一标识，在Web中这个唯一标识就是URI(Uniform Resource Identifier)。 URI既可以看成是资源的地址，也可以看成是资源的名称。如果某些信息没有使用URI来表示，那它就不能算是一个资源， 只能算是资源的一些信息而已。URI的设计应该遵循可寻址性原则，具有自描述性，需要在形式上给人以直觉上的关联。这里以github网站为例，给出一些还算不错的URI： https://github.com/git https://github.com/git/git https://github.com/git/git/blob/master/block-sha1/sha1.h https://github.com/git/git/commit/e3af72cdafab5993d18fae056f87e1d675913d08 https://github.com/git/git/pulls https://github.com/git/git/pulls?state=closed https://github.com/git/git/compare/master…next 下面让我们来看看URI设计上的一些技巧: 使用_或-来让URI可读性更好 曾经Web上的URI都是冰冷的数字或者无意义的字符串，但现在越来越多的网站使用_或-来分隔一些单词，让URI看上去更为人性化。 例如国内比较出名的开源中国社区，它上面的新闻地址就采用这种风格， 如http://www.oschina.net/news/38119/oschina-translate-reward-plan。 使用/来表示资源的层级关系 例如上述/git/git/commit/e3af72cdafab5993d18fae056f87e1d675913d08就表示了一个多级的资源， 指的是git用户的git项目的某次提交记录，又例如/orders/2012/10可以用来表示2012年10月的订单记录。 使用?用来过滤资源 很多人只是把?简单的当做是参数的传递，很容易造成URI过于复杂、难以理解。可以把?用于对资源的过滤， 例如/git/git/pulls用来表示git项目的所有推入请求，而/pulls?state=closed用来表示git项目中已经关闭的推入请求， 这种URL通常对应的是一些特定条件的查询结果或算法运算结果。 ,或;可以用来表示同级资源的关系 有时候我们需要表示同级资源的关系时，可以使用,或;来进行分割。例如哪天github可以比较某个文件在随意两次提交记录之间的差异，或许可以使用/git/git /block-sha1/sha1.h/compare/e3af72cdafab5993d18fae056f87e1d675913d08;bd63e61bdf38e872d5215c07b264dcc16e4febca作为URI。 不过，现在github是使用…来做这个事情的，例如/git/git/compare/master…next。 2. 2 统一资源接口RESTful架构应该遵循统一接口原则，统一接口包含了一组受限的预定义的操作，不论什么样的资源，都是通过使用相同的接口进行资源的访问。接口应该使用标准的HTTP方法如GET，PUT和POST，并遵循这些方法的语义。 如果按照HTTP方法的语义来暴露资源，那么接口将会拥有安全性和幂等性的特性，例如GET和HEAD请求都是安全的， 无论请求多少次，都不会改变服务器状态。而GET、HEAD、PUT和DELETE请求都是幂等的，无论对资源操作多少次， 结果总是一样的，后面的请求并不会产生比第一次更多的影响。 下面列出了GET，DELETE，PUT和POST的典型用法: GET 安全且幂等 获取表示 变更时获取表示（缓存） 200（OK） - 表示已在响应中发出 204（无内容） - 资源有空表示 301（Moved Permanently） - 资源的URI已被更新 303（See Other） - 其他（如，负载均衡） 304（not modified）- 资源未更改（缓存） 400 （bad request）- 指代坏请求（如，参数错误） 404 （not found）- 资源不存在 406 （not acceptable）- 服务端不支持所需表示 500 （internal server error）- 通用错误响应 503 （Service Unavailable）- 服务端当前无法处理请求 POST 不安全且不幂等 使用服务端管理的（自动产生）的实例号创建资源 创建子资源 部分更新资源 如果没有被修改，则不过更新资源（乐观锁） 200（OK）- 如果现有资源已被更改 201（created）- 如果新资源被创建 202（accepted）- 已接受处理请求但尚未完成（异步处理） 301（Moved Permanently）- 资源的URI被更新 303（See Other）- 其他（如，负载均衡） 400（bad request）- 指代坏请求 404 （not found）- 资源不存在 406 （not acceptable）- 服务端不支持所需表示 409 （conflict）- 通用冲突 412 （Precondition Failed）- 前置条件失败（如执行条件更新时的冲突） 415 （unsupported media type）- 接受到的表示不受支持 500 （internal server error）- 通用错误响应 503 （Service Unavailable）- 服务当前无法处理请求 PUT 不安全但幂等 用客户端管理的实例号创建一个资源 通过替换的方式更新资源 如果未被修改，则更新资源（乐观锁） 200 （OK）- 如果已存在资源被更改 201 （created）- 如果新资源被创建 301（Moved Permanently）- 资源的URI已更改 303 （See Other）- 其他（如，负载均衡） 400 （bad request）- 指代坏请求 404 （not found）- 资源不存在 406 （not acceptable）- 服务端不支持所需表示 409 （conflict）- 通用冲突 412 （Precondition Failed）- 前置条件失败（如执行条件更新时的冲突） 415 （unsupported media type）- 接受到的表示不受支持 500 （internal server error）- 通用错误响应 503 （Service Unavailable）- 服务当前无法处理请求 DELETE 不安全但幂等 删除资源 200 （OK）- 资源已被删除 301 （Moved Permanently）- 资源的URI已更改 303 （See Other）- 其他，如负载均衡 400 （bad request）- 指代坏请求 404 （not found）- 资源不存在 409 （conflict）- 通用冲突 500 （internal server error）- 通用错误响应 503 （Service Unavailable）- 服务端当前无法处理请求 下面我们来看一些实践中常见的问题: POST和PUT用于创建资源时有什么区别? POST和PUT在创建资源的区别在于，所创建的资源的名称(URI)是否由客户端决定。 例如为我的博文增加一个java的分类，生成的路径就是分类名/categories/java，那么就可以采用PUT方法。不过很多人直接把POST、GET、PUT、DELETE直接对应上CRUD，例如在一个典型的rails实现的RESTful应用中就是这么做的。 我认为，这是因为rails默认使用服务端生成的ID作为URI的缘故，而不少人就是通过rails实践REST的，所以很容易造成这种误解。 客户端不一定都支持这些HTTP方法吧? 的确有这种情况，特别是一些比较古老的基于浏览器的客户端，只能支持GET和POST两种方法。 在实践上，客户端和服务端都可能需要做一些妥协。例如rails框架就支持通过隐藏参数_method=DELETE来传递真实的请求方法， 而像Backbone这样的客户端MVC框架则允许传递_method传输和设置X-HTTP-Method-Override头来规避这个问题。 统一接口是否意味着不能扩展带特殊语义的方法? 统一接口并不阻止你扩展方法，只要方法对资源的操作有着具体的、可识别的语义即可，并能够保持整个接口的统一性。 像WebDAV就对HTTP方法进行了扩展，增加了LOCK、UPLOCK等方法。而github的API则支持使用PATCH方法来进行issue的更新，例如: 1PATCH /repos/:owner/:repo/issues/:number 不过，需要注意的是，像PATCH这种不是HTTP标准方法的，服务端需要考虑客户端是否能够支持的问题。 统一资源接口对URI有什么指导意义? 统一资源接口要求使用标准的HTTP方法对资源进行操作，所以URI只应该来表示资源的名称，而不应该包括资源的操作。 通俗来说，URI不应该使用动作来描述。例如，下面是一些不符合统一接口要求的URI: GET /getUser/1 POST /createUser PUT /updateUser/1 DELETE /deleteUser/1 如果GET请求增加计数器，这是否违反安全性? 安全性不代表请求不产生副作用，例如像很多API开发平台，都对请求流量做限制。像github，就会限制没有认证的请求每小时只能请求60次。 但客户端不是为了追求副作用而发出这些GET或HEAD请求的，产生副作用是服务端”自作主张”的。 另外，服务端在设计时，也不应该让副作用太大，因为客户端认为这些请求是不会产生副作用的。 直接忽视缓存可取吗? 即使你按各个动词的原本意图来使用它们，你仍可以轻易禁止缓存机制。 最简单的做法就是在你的HTTP响应里增加这样一个报头： Cache-control: no-cache。 但是，同时你也对失去了高效的缓存与再验证的支持(使用Etag等机制)。 对于客户端来说，在为一个REST式服务实现程序客户端时，也应该充分利用现有的缓存机制，以免每次都重新获取表示。 响应代码的处理有必要吗? HTTP的响应代码可用于应付不同场合，正确使用这些状态代码意味着客户端与服务器可以在一个具备较丰富语义的层次上进行沟通。 例如，201（”Created”）响应代码表明已经创建了一个新的资源，其URI在Location响应报头里。 假如你不利用HTTP状态代码丰富的应用语义，那么你将错失提高重用性、增强互操作性和提升松耦合性的机会。 如果这些所谓的RESTful应用必须通过响应实体才能给出错误信息，那么SOAP就是这样的了，它就能够满足了。 2. 3 资源的表述上面提到，客户端通过HTTP方法可以获取资源，是吧? 不，确切的说，客户端获取的只是资源的表述而已。 资源在外界的具体呈现，可以有多种表述(或成为表现、表示)形式，在客户端和服务端之间传送的也是资源的表述，而不是资源本身。 例如文本资源可以采用html、xml、json等格式，图片可以使用PNG或JPG展现出来。 资源的表述包括数据和描述数据的元数据，例如，HTTP头”Content-Type” 就是这样一个元数据属性。 那么客户端如何知道服务端提供哪种表述形式呢? 答案是可以通过HTTP内容协商，客户端可以通过Accept头请求一种特定格式的表述，服务端则通过Content-Type告诉客户端资源的表述形式。 以github为例，请求某组织资源的json格式的表述形式: 假如github也能够支持xml格式的表述格式，那么结果就是这样的: 下面我们来看一些实践上常见的设计: 在URI里边带上版本号有些API在URI里边带上版本号，例如: http://api.example.com/1.0/foo http://api.example.com/1.2/foo http://api.example.com/2.0/foo 如果我们把版本号理解成资源的不同表述形式的话，就应该只是用一个URL，并通过Accept头部来区分，还是以github为例，它的Accept的完整格式是:application/vnd.github[.version].param[+json] 对于v3版本的话，就是Accept: application/vnd.github.v3。对于上面的例子，同理可以使用使用下面的头部: Accept: vnd.example-com.foo+json; version=1.0 Accept: vnd.example-com.foo+json; version=1.2 Accept: vnd.example-com.foo+json; version=2.0 使用URI后缀来区分表述格式像rails框架，就支持使用/users.xml或/users.json来区分不同的格式。 这样的方式对于客户端来说，无疑是更为直观，但混淆了资源的名称和资源的表述形式。 我个人认为，还是应该优先使用内容协商来区分表述格式。 如何处理不支持的表述格式当服务器不支持所请求的表述格式，那么应该怎么办？若服务器不支持，它应该返回一个HTTP 406响应，表示拒绝处理该请求。下面以github为例，展示了一个请求XML表述资源的结果： 2. 4 资源的链接我们知道REST是使用标准的HTTP方法来操作资源的，但仅仅因此就理解成带CURD的Web数据库架构就太过于简单了。 这种反模式忽略了一个核心概念：”超媒体即应用状态引擎（hypermedia as the engine of application state）”。 超媒体是什么? 当你浏览Web网页时，从一个连接跳到一个页面，再从另一个连接跳到另外一个页面，就是利用了超媒体的概念：把一个个把资源链接起来. 要达到这个目的，就要求在表述格式里边加入链接来引导客户端。在《RESTful Web Services》一书中，作者把这种具有链接的特性成为连通性。下面我们具体来看一些例子。 下面展示的是github获取某个组织下的项目列表的请求，可以看到在响应头里边增加Link头告诉客户端怎么访问下一页和最后一页的记录。 而在响应体里边，用url来链接项目所有者和项目地址。 又例如下面这个例子，创建订单后通过链接引导客户端如何去付款。 上面的例子展示了如何使用超媒体来增强资源的连通性。很多人在设计RESTful架构时，使用很多时间来寻找漂亮的URI，而忽略了超媒体。所以，应该多花一些时间来给资源的表述提供链接，而不是专注于”资源的CRUD”。 2. 5 状态的转移有了上面的铺垫，再讨论REST里边的状态转移就会很容易理解了。 不过，我们先来讨论一下REST原则中的无状态通信原则。初看一下，好像自相矛盾了，既然无状态，何来状态转移一说? 其实，这里说的无状态通信原则，并不是说客户端应用不能有状态，而是指服务端不应该保存客户端状态。 2. 5.1 应用状态与资源状态实际上，状态应该区分应用状态和资源状态，客户端负责维护应用状态，而服务端维护资源状态。 客户端与服务端的交互必须是无状态的，并在每一次请求中包含处理该请求所需的一切信息。 服务端不需要在请求间保留应用状态，只有在接受到实际请求的时候，服务端才会关注应用状态。 这种无状态通信原则，使得服务端和中介能够理解独立的请求和响应。 在多次请求中，同一客户端也不再需要依赖于同一服务器，方便实现高可扩展和高可用性的服务端。 但有时候我们会做出违反无状态通信原则的设计，例如利用Cookie跟踪某个服务端会话状态，常见的像J2EE里边的JSESSIONID。 这意味着，浏览器随各次请求发出去的Cookie是被用于构建会话状态的。 当然，如果Cookie保存的是一些服务器不依赖于会话状态即可验证的信息（比如认证令牌），这样的Cookie也是符合REST原则的。 2. 5.2 应用状态的转移状态转移到这里已经很好理解了， “会话”状态不是作为资源状态保存在服务端的，而是被客户端作为应用状态进行跟踪的。客户端应用状态在服务端提供的超媒体的指引下发生变迁。服务端通过超媒体告诉客户端当前状态有哪些后续状态可以进入。 这些类似”下一页”之类的链接起的就是这种推进状态的作用——指引你如何从当前状态进入下一个可能的状态。 3. 总结现在广东XXX版本、XXX等项目中均使用传统的RPC、SOAP方式的Web服务，而移动南方基地XXXX项目的后台， 虽然采用了JSON格式进行交互，但还是属于RPC风格的。本文从资源的定义、获取、表述、关联、状态变迁等角度， 试图快速理解RESTful架构背后的概念。RESTful架构与传统的RPC、SOAP等方式在理念上有很大的不同，希望本文能对各位理解REST有所帮助。]]></content>
      <categories>
        <category>架构设计</category>
      </categories>
      <tags>
        <tag>RESTful</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[转]:李彦宏：专注才能更好地生存（下）]]></title>
    <url>%2Fblog%2Fdbb06ca.html</url>
    <content type="text"><![CDATA[尽管在财富榜上炙手可热，这个在下属眼中冷静得可怕的人仍然在不断地讲，百度距离破产只有30天…… 毫无疑问，这个人的崛起迎合了商业社会财富新贵的几乎所有特征，比如年轻、英俊、海归背景、一个俗气但成天被人挂在嘴边的英文名字、与纳斯达克关系密切、从事着最时髦的行当——IT业，最重要的是，他在一夜之间拥有了近百亿身价，并因此使得追随他的人群中突然冒出了7个亿万富翁、51个千万富翁、240多个百万富翁……这个浮出水面的人物迅速被媒体和公众追捧、蚕食，关于他的“传奇”、“神话”乃至各种小道消息不胫而走，传遍了大街小巷。而与此同时，这个长相腼腆但老谋深算的37岁晋商后裔也刻意以低调神秘和貌似谦逊的姿态，不时出现在他觉得有必要露面的电视颁奖晚会和财富论坛现场，抛出一些精心准备的言论和说辞。这个少年时代曾经无限痴迷戏剧的“超男”就这样雄心勃勃地在新经济的舞台上长袖善舞，以至于当我们利用他一手创办的全球最大的中文搜索引擎“百度”(baidu)来搜索关于他的新闻的时候，会发现这个名叫“李彦宏”的人人气多么之旺！ 因此，了解李彦宏是一件令人烦恼的事。除了要绕开他手下那群已经发财(因而显得有些傲慢)的部属，企图用单一的色彩或仅仅从一个方面来描绘他的性格也是不成功的。比如，百度公司大门口有一巨幅宣传画，上面六个大字“百度人民很行”，密密麻麻签满了每一位员工的名字，常常令初来乍到者一不留神就念成了“百度 人民银行”。如果你因此觉得李彦宏先生故弄玄虚的话，显然对他并不公平；一个技术员出身的企业家和他创办的公司能够在全球最热门的高科技领域“战胜”跨国公司，肯定不是依赖于故弄玄虚。又比如，当你有幸在北京理想国际大厦12层看见除了洗手间外，几乎每一间房门上都标着诸如“青玉案”“月满楼”之类的词牌名，抱着大枕头、趿着拖鞋的IT人士在其间走来窜去，对老板直呼“Robin”，并且开会时谁先到谁选择座位，最为普通的一名员工经常心安理得地坐在那个被认为最显贵的位置上…… 如果你因此觉得李彦宏先生随意而和善的话，那么显然同样不尽客观；其实不少员工私下里说他像唐僧，喜欢唠叨，他与多数人都会保持一种微妙的距离，甚至有人说“李彦宏是个冷静得可怕的人”。许多喜欢李彦宏的人认为他讲朋友义气、重感情、温和而良善；与李彦宏反目的例子同样并不鲜见，一位愤然出走的百度员工当年不顾李的劝说，毅然绝然放弃了如今价值千万的股票期权，而最近在MSN上仍认为“毫不后悔”，至于对李彦宏口诛笔伐，甚至与百度打官司的也大有人在。事实上，构成李彦宏性格的因素非常之多，而且各不相同，谁搞得清呢？但有一点是得到公认的——似乎可以套用亨利·基辛格当年说过的一句话,即聪明不足以使人成为企业领袖，对一个企业领袖来说，必须具备的是魄力，是勇气，是狡黠和魅力。 “选择”的魔力 “在人生选择道路上，我好像没有很不顺利的过程，只是面临着一些选择。”李彦宏说。当坐在你对面的这个人慢吞吞地、谨慎地、矜持而又儒雅地说出这句话的时候，你是否火冒三丈，盘算着弄一台榨汁机来对付李彦宏，以获得你想要的答案？事实上，除非他自己愿意说出来，你别指望能从李彦宏嘴里套出什么，哪怕是一群记者围着他长枪短炮地开火。 无论从哪个角度来看，这个踌躇满志、身手敏捷的老年轻人的37岁人生履历，都有如一段几乎谈不上曲折的光滑沙滩，上面除了一串还算清晰的脚印之外，一览无余。而这些脚印，便是他所谓的“选择”—— 比如1968年。李彦宏无可选择地以男孩的身份出生在山西小城阳泉的一个普通家庭，父母都是工人，三个姐姐，一个妹妹，子女多，负担重，手忙脚乱的父母显然顾不上孩子的成长。如果这时候非要说“选择”的话，李彦宏除了选择童年的玩伴之外，根本不知道什么叫选择。所以，“小学的时候，考过戏剧学院，后来放弃了。现在觉得放弃也挺好，技术能带来更大的影响力。”李彦宏回忆说。少年时代，他着迷于戏曲，曾被山西阳泉晋剧团录取，但中学时代，又回归“主业”，全身心投入功课学习中——否则，今天我们恐怕会少一个新经济的精英分子，而大抵只能用别的搜索引擎(比如Google)去搜索一个也许并不知名的晋剧演员的名字了。 1987年，李彦宏以阳泉市第一名的成绩考上了北京大学图书情报专业。这个高中时就参加过全国青少年程序设计大赛的“乖孩子”依然不懂得什么叫做选择，自然也没搞明白什么叫做设计，他唯一能做的是步人后尘——他的三姐先他考上了北大。所以，尽管这个19岁的男孩一边为离开阳泉迈进中国最高学府激动不已，一边却也在为图书情报学的枯燥、乏味沮丧不已。左右为难的他甚至一眼看到了自己那一代人关于未来的最好选择：毕业，进机关，娶妻生子，熬年头，熬资历，然后过着大多数中国小职员和小市民的生活，人生按部就班，简单而平凡……这样的人生道路显然并不是李彦宏所期待的，“在我看来，选择出国是一条自然而然的道路。”话虽如此，他还是不懂得什么叫选择，那时候的李彦宏只不过顺应了一个绝大多数北大学生都会顺应的潮流：出国留学。并且，他的三姐再次起到了言传身教的作用，先他留学去了美国。 “我是一个非常专注的人，一旦认定方向就不会改变，直到把它做好。”从大学三年级起，这个已经被出国、留学刺激得彻夜难眠的中国青年开始心无旁骛，像很多同类一样买来托福、GRE等书狂啃，过起了“教室——图书馆——宿舍”三点一线的清教徒式生活，唯一的目标就是留学美国，方向锁定在计算机专业。 如果说人生的过程就是在爬山，你的每一次行动都是在选择道路，那么，不同的道路将把你带到不同的位置，并且每一次的跨越、攀登和坚持，都有可能成为你人生风景的分水岭。1991年，李彦宏再一次挤过了独木桥，收到美国布法罗纽约州立大学计算机系的录取通知书。那一天正值圣诞节，23岁的李彦宏背着满满一行囊的豪情壮志，奔大洋彼岸而去。 美国布法罗纽约州立大学一年里有六个月都飘着雪。在这里，李彦宏将白天上课、晚上补习英语和熬夜编写程序当成一个中国留学生初来乍到必然的吃苦方式。“现在回想起来，觉得当时挺苦的，但年轻就应该吃苦。”李彦宏评价这段经历说，“我出国不是一帆风顺。因为换专业，刚到美国学计算机，很多功课一开始都跟不上。有时和教授面谈，由于较心急，谈一些自己不是很了解的领域，结果那些教授就觉得我不行。”李彦宏没有选择，他唯一能做的就是尽一切可能去适应环境。在学校待了一年后，他总算获得了一个机会到位于普林斯顿的松下信息技术研究所实习，“这三个多月的实习，对我后来职业道路的选择起了至关重要的作用。” 那么，这种影响到底是什么呢？其实就是放弃。在松下实习的那段日子，工作之余，李彦宏经常坐在花园里看《华尔街日报》，报上时常会刊登描写硅谷商战的文章：微软如何跳出来公然反叛IBM，又怎样以软件教父的身份对抗SUN、网景……一个个鲜活的商战故事，让李彦宏感觉到：“原来技术本身并不是唯一的决定性因素，商战策略才是真正决胜千里的因素。”受其影响，李彦宏决定放弃攻读博士学位。1994年夏天，他进入华尔街一家公司——道·琼斯子公司做起了金融信息检索技术，“那时候，中国留学生中有一股风气，就是读博士的学生一旦找到工作就放弃学业。起先，我认为自己不会这样。但这家公司老板也是个技术专家，他对我的研究非常赏识。两人大有相见恨晚的感觉。‘士为知己者死’，于是我决心离开学校，接受这家公司高级顾问的职位。” 李彦宏所说的这个老板，是一位耶鲁博士，从贝尔实验室出来办公司，再把公司卖给道·琼斯。正是从他身上，李彦宏看到了“一个有知识的人如何利用知识发财致富，在泡时间读硕士博士当教授之外，另有一条明亮的成功途径”。此后，他成为《华尔街日报》网络版实时金融信息系统设计人员。石安简评：李的老板是个聪明人，既是技术专家，也有精明的生意头脑，当办起一家公司后能把公司卖掉，卖个好价钱，便是成功了。 问题是，在华尔街最有前途的是金融家而不是计算机天才。对于李彦宏来说，自己的热爱和长处只在计算机，他的前途依然不甚明朗。李彦宏再次面临选择。于是，1997年李彦宏离开自己为之奋斗了三年的华尔街，前往硅谷著名的搜索引擎公司Infoseek(搜信)供职。在硅谷，他亲见了当时最成功的搜索技术公司如何在股市上呼风唤雨，见识了一个每天支持上千万流量的大型工业界信息系统是怎样工作运转，并在这里写成了第二代搜索引擎程序。与此同时，他也见证了Infoseek后来的每况愈下和惨淡经营，并从中悟出任何一个企业家在追求成功的过程中必须历练的谨慎和勤俭——这些心得，无一例外地被李彦宏在1998年写进了畅销书《硅谷商战》，并且将其牢牢地保持在了自己后来的创业历程中。石安简评：你曾经供职过的单位和行业往往会成为你迈向成功的阶梯，因为他们会让你预先去实践一些想法，而不必冒令自己破产的风险。]]></content>
      <categories>
        <category>心情札记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[[转]:李彦宏：专注才能更好地生存（上）]]></title>
    <url>%2Fblog%2Fb50761af.html</url>
    <content type="text"><![CDATA[尽管在财富榜上炙手可热，这个在下属眼中冷静得可怕的人仍然在不断地讲，百度距离破产只有30天…… 毫无疑问，这个人的崛起迎合了商业社会财富新贵的几乎所有特征，比如年轻、英俊、海归背景、一个俗气但成天被人挂在嘴边的英文名字、与纳斯达克关系密切、从事着最时髦的行当——IT业，最重要的是，他在一夜之间拥有了近百亿身价，并因此使得追随他的人群中突然冒出了7个亿万富翁、51个千万富翁、240多个百万富翁……这个浮出水面的人物迅速被媒体和公众追捧、蚕食，关于他的“传奇”、“神话”乃至各种小道消息不胫而走，传遍了大街小巷。而与此同时，这个长相腼腆但老谋深算的37岁晋商后裔也刻意以低调神秘和貌似谦逊的姿态，不时出现在他觉得有必要露面的电视颁奖晚会和财富论坛现场，抛出一些精心准备的言论和说辞。这个少年时代曾经无限痴迷戏剧的“超男”就这样雄心勃勃地在新经济的舞台上长袖善舞，以至于当我们利用他一手创办的全球最大的中文搜索引擎“百度”(baidu)来搜索关于他的新闻的时候，会发现这个名叫“李彦宏”的人人气多么之旺！ 因此，了解李彦宏是一件令人烦恼的事。除了要绕开他手下那群已经发财(因而显得有些傲慢)的部属，企图用单一的色彩或仅仅从一个方面来描绘他的性格也是不成功的。比如，百度公司大门口有一巨幅宣传画，上面六个大字“百度人民很行”，密密麻麻签满了每一位员工的名字，常常令初来乍到者一不留神就念成了“百度 人民银行”。如果你因此觉得李彦宏先生故弄玄虚的话，显然对他并不公平；一个技术员出身的企业家和他创办的公司能够在全球最热门的高科技领域“战胜”跨国公司，肯定不是依赖于故弄玄虚。又比如，当你有幸在北京理想国际大厦12层看见除了洗手间外，几乎每一间房门上都标着诸如“青玉案”“月满楼”之类的词牌名，抱着大枕头、趿着拖鞋的IT人士在其间走来窜去，对老板直呼“Robin”，并且开会时谁先到谁选择座位，最为普通的一名员工经常心安理得地坐在那个被认为最显贵的位置上…… 如果你因此觉得李彦宏先生随意而和善的话，那么显然同样不尽客观；其实不少员工私下里说他像唐僧，喜欢唠叨，他与多数人都会保持一种微妙的距离，甚至有人说“李彦宏是个冷静得可怕的人”。许多喜欢李彦宏的人认为他讲朋友义气、重感情、温和而良善；与李彦宏反目的例子同样并不鲜见，一位愤然出走的百度员工当年不顾李的劝说，毅然绝然放弃了如今价值千万的股票期权，而最近在MSN上仍认为“毫不后悔”，至于对李彦宏口诛笔伐，甚至与百度打官司的也大有人在。事实上，构成李彦宏性格的因素非常之多，而且各不相同，谁搞得清呢？但有一点是得到公认的——似乎可以套用亨利·基辛格当年说过的一句话,即聪明不足以使人成为企业领袖，对一个企业领袖来说，必须具备的是魄力，是勇气，是狡黠和魅力。 “选择”的魔力 “在人生选择道路上，我好像没有很不顺利的过程，只是面临着一些选择。”李彦宏说。当坐在你对面的这个人慢吞吞地、谨慎地、矜持而又儒雅地说出这句话的时候，你是否火冒三丈，盘算着弄一台榨汁机来对付李彦宏，以获得你想要的答案？事实上，除非他自己愿意说出来，你别指望能从李彦宏嘴里套出什么，哪怕是一群记者围着他长枪短炮地开火。 无论从哪个角度来看，这个踌躇满志、身手敏捷的老年轻人的37岁人生履历，都有如一段几乎谈不上曲折的光滑沙滩，上面除了一串还算清晰的脚印之外，一览无余。而这些脚印，便是他所谓的“选择”—— 比如1968年。李彦宏无可选择地以男孩的身份出生在山西小城阳泉的一个普通家庭，父母都是工人，三个姐姐，一个妹妹，子女多，负担重，手忙脚乱的父母显然顾不上孩子的成长。如果这时候非要说“选择”的话，李彦宏除了选择童年的玩伴之外，根本不知道什么叫选择。所以，“小学的时候，考过戏剧学院，后来放弃了。现在觉得放弃也挺好，技术能带来更大的影响力。”李彦宏回忆说。少年时代，他着迷于戏曲，曾被山西阳泉晋剧团录取，但中学时代，又回归“主业”，全身心投入功课学习中——否则，今天我们恐怕会少一个新经济的精英分子，而大抵只能用别的搜索引擎(比如Google)去搜索一个也许并不知名的晋剧演员的名字了。 1987年，李彦宏以阳泉市第一名的成绩考上了 北京大学图书情报专业。这个高中时就参加过全国青少年程序设计大赛的“乖孩子”依然不懂得什么叫做选择，自然也没搞明白什么叫做设计，他唯一能做的是步人后尘——他的三姐先他考上了北大。所以，尽管这个19岁的男孩一边为离开阳泉迈进中国最高学府激动不已，一边却也在为图书情报学的枯燥、乏味沮丧不已。左右为难的他甚至一眼看到了自己那一代人关于未来的最好选择：毕业，进机关，娶妻生子，熬年头，熬资历，然后过着大多数中国小职员和小市民的生活，人生按部就班，简单而平凡……这样的人生道路显然并不是李彦宏所期待的，“在我看来，选择出国是一条自然而然的道路。”话虽如此，他还是不懂得什么叫选择，那时候的李彦宏只不过顺应了一个绝大多数北大学生都会顺应的潮流：出国留学。并且，他的三姐再次起到了言传身教的作用，先他留学去了美国。 “我是一个非常专注的人，一旦认定方向就不会改变，直到把它做好。”从大学三年级起，这个已经被出国、留学刺激得彻夜难眠的中国青年开始心无旁骛，像很多同类一样买来托福、GRE等书狂啃，过起了“教室——图书馆——宿舍”三点一线的清教徒式生活，唯一的目标就是留学美国，方向锁定在计算机专业。 如果说人生的过程就是在爬山，你的每一次行动都是在选择道路，那么，不同的道路将把你带到不同的位置，并且每一次的跨越、攀登和坚持，都有可能成为你人生风景的分水岭。1991年，李彦宏再一次挤过了独木桥，收到美国布法罗纽约州立大学计算机系的录取通知书。那一天正值圣诞节，23岁的李彦宏背着满满一行囊的豪情壮志，奔大洋彼岸而去。 美国布法罗纽约州立大学一年里有六个月都飘着雪。在这里，李彦宏将白天上课、晚上补习英语和熬夜编写程序当成一个中国留学生初来乍到必然的吃苦方式。“现在回想起来，觉得当时挺苦的，但年轻就应该吃苦。”李彦宏评价这段经历说，“我出国不是一帆风顺。因为换专业，刚到美国学计算机，很多功课一开始都跟不上。有时和教授面谈，由于较心急，谈一些自己不是很了解的领域，结果那些教授就觉得我不行。”李彦宏没有选择，他唯一能做的就是尽一切可能去适应环境。在学校待了一年后，他总算获得了一个机会到位于普林斯顿的松下信息技术研究所实习，“这三个多月的实习，对我后来职业道路的选择起了至关重要的作用。” 那么，这种影响到底是什么呢？其实就是放弃。 在松下实习的那段日子，工作之余，李彦宏经常坐在花园里看《华尔街日报》，报上时常会刊登描写硅谷商战的文章：微软如何跳出来公然反叛IBM，又怎样以软件教父的身份对抗SUN、网景……一个个鲜活的商战故事，让李彦宏感觉到：“原来技术本身并不是唯一的决定性因素，商战策略才是真正决胜千里的因素。”受其影响，李彦宏决定放弃攻读博士学位。1994年夏天，他进入华尔街一家公司——道·琼斯子公司做起了金融信息检索技术，“那时候，中国留学生中有一股风气，就是读博士的学生一旦找到工作就放弃学业。起先，我认为自己不会这样。但这家公司老板也是个技术专家，他对我的研究非常赏识。两人大有相见恨晚的感觉。‘士为知己者死’，于是我决心离开学校，接受这家公司高级顾问的职位。” 李彦宏所说的这个老板，是一位耶鲁博士，从贝尔实验室出来办公司，再把公司卖给道·琼斯。正是从他身上，李彦宏看到了“一个有知识的人如何利用知识发财致富，在泡时间读硕士博士当教授之外，另有一条明亮的成功途径”。此后，他成为《华尔街日报》网络版实时金融信息系统设计人员。 石安简评：李的老板是个聪明人，既是技术专家，也有精明的生意头脑，当办起一家公司后能把公司卖掉，卖个好价钱，便是成功了。 问题是，在华尔街最有前途的是金融家而不是计算机天才。对于李彦宏来说，自己的热爱和长处只在计算机，他的前途依然不甚明朗。李彦宏再次面临选择。于是，1997年李彦宏离开自己为之奋斗了三年的华尔街，前往硅谷著名的搜索引擎公司Infoseek(搜信)供职。在硅谷，他亲见了当时最成功的搜索技术公司如何在股市上呼风唤雨，见识了一个每天支持上千万流量的大型工业界信息系统是怎样工作运转，并在这里写成了第二代搜索引擎程序。与此同时，他也见证了Infoseek后来的每况愈下和惨淡经营，并从中悟出任何一个企业家在追求成功的过程中必须历练的谨慎和勤俭——这些心得，无一例外地被李彦宏在1998年写进了畅销书《硅谷商战》，并且将其牢牢地保持在了自己后来的创业历程中。 石安简评：你曾经供职过的单位和行业往往会成为你迈向成功的阶梯，因为他们会让你预先去实践一些想法，而不必冒令自己破产的风险。]]></content>
      <categories>
        <category>心情札记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[“猴子与芒果园”——项目经理的作用]]></title>
    <url>%2Fblog%2F15b39876.html</url>
    <content type="text"><![CDATA[话说有一片美丽的芒果园，园中结满成熟的果实。一群猴子从果园经过，看见满园的芒果，就进入果园。它们摘下芒果，咬过几口便不耐烦地丢下，又去摘下一个。突然一只猴子尖叫起来，原来它被一块大石头打中了。猴子们回过头，发现园丁们正向它们扔石头。它们慌忙逃进附近的森林中，等园丁们离开，又立刻返回。但是它们刚刚开始吃芒果，石头便再次雨点般向它们打来。猴子们只得逃走。 这样的情景一次又一次地再现，最后大多数猴子都受了伤。这时猴王说：“我们应当拥有自己的芒果树，那样就能太太平平地吃果子。”于是猴王召集众猴开会，以寻求解决办法。最聪明的一只猴子说： “我听说芒果树来自芒果中的种子，人类把种子埋到地里，芒果树就会长出来。我们可以偷一只芒果，把种子埋到地里，种出我们自己的树。” 猴子们一致认为这是个好主意，于是它们派出最灵活的一只猴子回到果园。它躲开园丁的几块石头，摘下一颗硕大的芒果，带着它奔回森林。猴子们挖了一个坑，放进一颗种子，盖上土。然后它们围坐在坑的周围，目不转睛地盯着树坑，期待着树长出来。10分钟过去了，芒果树并没长出来，一些小猴子们坐不住了，偷偷地溜走。10分钟又过去了，芒果树仍然没有长出来，一些大猴子也溜走了。最后猴王喝道： “都回来!你们要去哪儿?” “我们不想等下去了。果园里有那么多芒果可吃。” “你们不明白吗？吃别人的果子是没有前途的，我们必须有自己的树。我确信它很快会长出来。” 众猴们在猴王的号召下又等了整整一天，但是芒果树还是没有长出来。第二天又过去了，芒果树还是没有长出来。“等这么长时间是不正常的!”一只猴子说，“把它挖出来，看看出了什么问题。”“耐心点。”猴王说。第三天过去了，芒果树依旧没有长出来。全体猴子一齐求猴王让它们把种子挖出来，看看发生了什么。最后猴王同意了，猴子们挖下去，种子露了出来，但是它们把刚刚萌发的细芽弄断了。 “你们看见了，孩子们!”猴王说，“愿望不会一夜成真。你们有拥有一棵树的梦想，也有了种子，却没有实现梦想的耐心。” 听了故事之后不知道在座的各位有什么感想，但事实是这个“芳果树种植”的项目彻底的失败了，大家也许会一致认为主要原因是群猴们没有耐心，但我个人认为主要原因在于猴王这个项目经理的错误管理，从软件工程的角度考虑，主要表现在以下几个方面： 需求分析没有做好：这里正确的需求应该是拥有自己的芒果园，而不是单单的一颗芒果树。 解决方案没有做好：猴王召集众猴开会，以寻求解决办法，这个可以认为是“头脑风暴”方式的问题办法，但风暴后的结果却是错误的，因为有只公认的聪明的猴子说“我听说芒果树来自芒果中的种子，人类把种子埋到地里，芒果树就会长出来。我们可以偷一只芒果，把种子埋到地里，种出我们自己的树。”并且猴子们一致认为这是个好主意，其实这是个错误的主意。其一：这个解决方案只是听说，并没有进行可行性研究；其二：偷一只芒果，显然是资源需求没有做好，一只芒果的种子的数量是远远不够的 项目成本投入太少：最灵活的一只猴子回到果园。摘下一颗硕大的芒果，带着它奔回森林。猴子们挖了一个坑，放进一颗种子，盖上土。大家注意，这里整个项目组只挖了一个坑，并且只投入了一颗种子。显然成本投入太少。 资源管理混乱，没有进行科学的任务分配：种子种下之后，他应该只派一两只猴子看守种子的成长情况，以观察项目的进度；再派其它猴子偷学园丁的果园管理技术，以及芒果树的种植技术;还得加强一批猴子的技术训练如敏捷度，并将这只训练有素的队伍外派到人类的果园偷果子，以解决项目组其它成员的火食问题，使项目进行下去。 项目技术不成熟：种子种下之后，应该给予浇水、施肥、甚至给予适当的温度，以保证种子的合理的生长环境。 项目测试混乱：整个项目只经过一次现场测试，也就是Baita测试，但测试的结果是项目因为资源耗尽而导致失败，显然没有进行有效的备份。 推卸责任：项目总结时，猴王是这样总结的：“愿望不会一夜成真。你们有拥有一棵树的梦想，也有了种子，却没有实现梦想的耐心。”挖种子是在猴王的同意之下才进行的，而当萌芽被破坏后，猴王却将责任推向众猴，显然猴王是一个不敢于承担责任的项目经理。 没有进行合理的效益分析：一颗芒果树从生根、发芽再到开花、结果，大约需要三年的时间，整个猴群项目组花三年的时间，就为了培育一颗芒果树，那么项目的成本回收是何年何月，项目出业绩，又是何年何月。 风险意识太差：一颗芒果籽生根、发芽、结果需要多长时间他没想过，就算一颗树结了果实又能养活多少只猴子也没想过。 从辩证法的角度考虑，猴王主要违背了以下四个项目经理具备的辩证论法： 既要计划，又要变化有人说计划赶不上变化，但倘若没有变化,要计划还有何用；“芒果树种植”项目中，没有任何的计划，也没有应对变化的对策。 既要见林，又要见木不要因一叶遮目，但也不能因为整片森林而忽略眼前参天大树；“芒果树种植”项目应该树立远大的目标芒果园，而不是芒果树。 既要冷静分析，又要相信直觉冷静也是一种直觉；猴王这个项目经理没有经过冷静的分析，而只是凭着他个人的感觉，相信“芒果树一定会长出来”，而没有任何依据，如果他能冷静的分析出芒果树的生长规律，相信就不会再犯这样的直觉错误。 既要有原则性，又要有灵活性猴王有原则，但不够坚持。 总的来说，“芒果树种植”项目的失败，主要是项目经理没有合理的调度工期、质量、成本、人员、范围也就是T-Q-C-P-S这五大要素。]]></content>
      <categories>
        <category>项目管理</category>
      </categories>
      <tags>
        <tag>项目管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[软件架构设计随笔]]></title>
    <url>%2Fblog%2F6faa827b.html</url>
    <content type="text"><![CDATA[软件架构设计包括“逻辑视图”和“物理视图”设计。两种视图设计都可参看“分而治之”和“迭代式设计”思想进行设计。 分而治之：聚焦不同方面，更有效思考；相当于化“大问题”为“子问题”。 迭代式设计：不同视图设计交替迭代展开；逻辑划分逐步清晰，促进物理分布设计，反之亦然。 架构设计模式模块划分方法：自顶向下（分层）、水平划分和垂直划分（功能划分） 小西天和大系统的架构设计不同，首先是“概念架构”上的不同，而归根溯源这是由于架构所支撑的“关键需求”不同造成的，概念架构的设计顺序： 首先，选择架构风格、划分顶级子系统。这两项设计任务是相互影响的，相辅相成的。 然后，开发技术选型，集成技术选型、二次开发技术选型。这三项设计任务紧密相关、同时进行。另外可能不需要集成支持，也可以决定不支持二次开发。 概念架构（Conceptual Architechture），界定系统的高层组件、以及它们之间的关系。概念架构意在对系统进行适当分解 、而不陷入细节。借此，可以与管理人员、市场人员、用户等非技术人员交流架构。概念架构规定了每个组件的非正式规约、以及架构视图，但不涉及接口细节。根据上述定义，我们注意到如下几点： 概念架构满足“架构=组件+交互”的基本定义，只不过概念架构仅关注高层组件（high-level components） 概念架构对高层组件的“职责”进行了笼统的界定（informal specification），并给出了高层组件之间的相互关系 而且，必须地，概念架构不应涉及接口细节（without interface detail）。 架构设计的全过程，包括：高层需求分析、需求分析、概念架构设计（对顶级子系统）和细化架构设计（每个子系统）的设计。 高层需求分析包括：系统目标、需求范围、Feature、上下文图 需求分析：流程、功能（用例）、非功能需求 软件架构5维分析 商业模式/功能：支撑系统提供有价值的功能特性的能力。 运行类属性（可靠性、安全、性能、可服务性、可伸缩性、易用性）：支撑系统运行维护的各种DFX属性，相应的基本属性包括可靠性、安全性、可服务性、性能、可伸缩性/可扩展性、节能减排和易用性。 可交付类属性：支撑系统快速交付、快速部署的能力，相应的基本属性包括可供应性、可制造性和可部署性。 开发与演进类属性（可演进性、可测试性等）：支撑系统能够快速、高效、高质量开发出来，并能够方便修改、重用，持续演进，相应的基本属性包括可构建性、可测试性、可演进性、可重用性和易学习性。 生态类系统属性（开放性、可定制性、易集成性、兼容性）：支撑系统构建开放、打造生态系统的能力，相应的基本属性包括开放性、可定制性、易集成性和兼容性。]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>架构设计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[谈API网关的背景、架构以及落地方案]]></title>
    <url>%2Fblog%2Ffe1209ee.html</url>
    <content type="text"><![CDATA[转自： http://www.infoq.com/cn/news/2016/07/API-background-architecture-floo Chris Richardson曾经在他的博客上详细介绍过API网关，包括API网关的背景、解决方案以及案例。对于大多数基于微服务的应用程序而言，API网关都应该是系统的入口，它会负责服务请求路由、组合及协议转换。如Chris所言，在微服务的应用程序中，客户端和微服务之间的交互，有如下几个挑战： 微服务提供的API粒度通常与客户端的需求不同，微服务一般提供细粒度的API，也就是说客户端需要与多个服务进行交互。 不同的客户端需要不同的数据，不同类型客户端的网络性能不同。 服务的划分可能会随时间而变化，因此需要对客户端隐藏细节。 那API网关具体是如何解决这些问题的，在API网关的落地上，需要注意哪些地方，就这些问题，InfoQ编辑采访了普元主任架构师王延炯，与他一起探讨了API网关的来龙去脉。 InfoQ：谈谈你所理解的API网关，以及API网关出现的背景？ 王延炯：API Gateway（API GW / API 网关），顾名思义，是出现在系统边界上的一个面向API的、串行集中式的强管控服务，这里的边界是企业IT系统的边界。在微服务概念的流行之前，API GW的实体就已经诞生了，这时的主要应用场景是OpenAPI，也就是开放平台，面向的是企业外部合作伙伴，对于这个应用场景，相信接触的人会比较多。当在微服务概念流行起来之后，API网关似乎成了在上层应用层集成的标配组件。 其实，在我所经历过的项目中，API GW的定位主要有五类： 面向Web App：这类场景，在物理形态上类似前后端分离，此时的Web App已经不是全功能的Web App，而是根据场景定制、场景化的App。 面向Mobile App：这类场景，移动App是后端Service的使用者，此时的API GW还需要承担一部分MDM（此处是指移动设备管理，不是主数据管理）的职能。 面向Partner OpenAPI这类场景，主要为了满足业务形态对外开放，与企业外部合作伙伴建立生态圈，此时的API GW需要增加配额、流控、令牌等一系列安全管控功能。 面向Partner ExternalAPI这类场景，业界提的比较少，很多时候系统的建设，都是为了满足企业自身业务的需要，实现对企业自有业务的映射。当互联网形态逐渐影响传统企业时，很多系统都会为了导入流量或者内容，依赖外部合作伙伴的能力，一些典型的例子就是使用「合作方账号登录」、「使用第三方支付平台支付」等等，这些对于企业内部来说，都是一些外部能力。此时的API GW就需要在边界上，为企业内部Service 统一调用外部的API做统一的认证、（多租户形式的）授权、以及访问控制。 面向IoT SmartDevice这类场景，业界就提的更少了，但在传统企业，尤其是工业企业，传感器、物理设备从工业控制协议向IP转换，导致具备信息处理能力的「智能产品」在被客户激活使用直至报废过程中，信息的传输不能再基于VPN或者企业内部专线，导致物理链路上会存在一部分公网链路。此时的API GW所需要满足的，就是不是前三种单向的由外而内的数据流，也不是第四种由内而外的数据流，「内外兼修」的双向数据流，对于企业的系统来说终端设备很多情况下都不是直连网关，而是进过一个「客户侧」的集中网关在和企业的接入网关进行通信。 InfoQ：在一个微服务架构中，API网关会在架构中的那一层？他主要的作用是什么？ 王延炯：接续前一个话题，我把API GW分为了五类，对于当前的企业而言被关注的是前三类或者前四类API GW。显然，它们都会出现在企业系统的边界上，也就是和企业外部交互的「独木桥」上。它们除了保证数据的交换之外，还需要实现对接入客户端的身份认证、防报文重放与防数据篡改、功能调用的业务鉴权、响应数据的脱敏、流量与并发控制，甚至基于API调用的计量或者计费。 InfoQ：你有研究过Netflix的API网关吗？在实现方式上，你觉得他们的方式有什么巧妙之处吗？ 王延炯：Netflix 的API GW，主要是指Zuul, Netflix 将他们用于自己的三大场景： Website Service, API Service, Streaming Service。其中前两个定位与我的前两个分类：Web App, Mobile App比较类似，第三个Streaming Service主要是netflix的核心视频业务所形成的特有形态。Netflix在Zuul的实现上，主要特色是：Filter的PRE ROUTING POST ERROR（PRPE 模型），以及采用Groovy脚本的Filter实现机制、采用Cassandra作为filter repository的机制。Filter 以及 Filter的PRPE模型，是典型的「前正后反模型」的实现，为集成的标准化做好了框架层面的铺垫。Netflix其实并没有对API GW进行深入的功能实现（或者说面相业务友好的相关功能），整体上它只提供了一个技术框架、和一些标准的filter实例实现，相信了解过filter chain原理的分布式中间件工程师也能搭出这样的框架。这么做的原因，我认为很大原因是API GW所扮演的角色是一个业务平台，而非技术平台，将行业特征很强的业务部分开源，对于受众意义也不是特别大。另外，除了Netflix Zuul，在商业产品上还有apigee公司所提供的方案，在轻量级开源实现上还有基于Nginx的kong，kong其实提供了19个插件式的功能实现，涵盖的面主要在于安全、监控等领域，但缺少对报文转换的能力（为什么缺 也很显而易见——避免产生业务场景的耦合，更通用）。另外，还有基于TCP协议的GW，比如携程无线应用的后端实现有HTTP和TCP两种，有兴趣的读者也可以深入关注。 InfoQ：在API网关的设计上，需要包含哪些要素？ 王延炯：从三个方面说吧，API网关本身以及API网关客户端，还有配套的自助服务平台。具体如下：API GW本身 NIO接入，异步接出 流控与屏蔽 秘钥交换 客户端认证与报文加解密 业务路由框架 报文转换 HTTP DNS/ Direct IP API GW 客户端 SDK / Library 基本通信 秘钥交换与Cache 身份认证与报文加解密 配套的在线自助服务平台 代码生成 文档生成 沙盒调测 InfoQ：在API网关的落地上，你有可行的方案吗？在API网关的落地上，难点是什么？ 王延炯：在我所服务过的阿里系、非电商互联网公司里，内部的分布式服务调用采用的是Dubbo，但移动应用是iOS和Android，基本上没有PC Web端的客户端，在这种条件下，API GW所承担的一个重要角色就是报文转换，并且是跨语言、跨运行平台的报文转换。报文就是数据，在跨平台、跨语言的条件下，对于数据的描述——元数据——也就是类定义，对于API GW的系统性挑战是巨大的：传输时，报文内不能传输类定义，跨语言的类定义转换、生成与加载。 API GW的落地技术基本贯通没有太大的难度，但形成最佳的实践，有一些外围的前置条件，比如： 后端API粒度 能和原子业务能力找到映射最好，一定要避免「万能接口」的出现。 业务路由的实现和含报文转换的API不停机发布 尽可能的在报文头里面存放业务路由所需要的信息，避免对报文体进行解析。 API GW上线后，面临的很大问题都是后端服务如何自助发布到外部，同时不能重启网关服务，以保障业务的连续。在此过程中，如果涉及到报文格式的转换，那对API网关实现的技术要求比较高。如果让网关完成报文转换，第一种方案，网关需要知道报文的具体格式（也就是报文的元数据，或者是类定义），这部分要支持热更新。第二种方案，需要客户端在报文内另外附加元数据，网关通过运行期加载元数据对报文进行解析在进行报文的转换，这种方案性能不会很好。第三种方案，就是在运行期首次报文转换的时候，根据元数据生成报文转换代码并加载，这种方案对技术实现要求比较高，对网关外围平台支撑力度要求也不低。 客户端的秘钥管理 很多人都会把安全问题简单的用加密算法来解决，这是一个严重的误区，很多时候都存在对秘钥进行系统性管理的短板。打个比方，加密算法就好比家里的保险箱，而秘钥是保险箱的钥匙，而缺乏秘钥管理的安全方案，就好比把钥匙放在自家的客厅茶几上。更何况，安全方案里加解密也只是其中的一部分。 InfoQ：你认为一个设计良好的API网关应该做到什么？ 王延炯：目前业界关注的API GW，主要是在前三类，下文对于API网关的设计上，侧重于「面向接入」的API GW。 在API网关的设计上，仅仅有类似Zuul这样的「面向接入」的运行期框架是远远不够的，因为一个完整的、「面向接入」的API GW需要包含以下功能： 面向运行期 对客户端实现身份认证 通信会话的秘钥协商，报文的加密与解密 日常流控与应急屏蔽 内部响应报文的场景化裁剪 支持「前正后反模型」的集成框架 报文格式的转换 业务路由的支撑 客户端优先的超时机制 全局流水号的生成与应用 面向客户端支持HTTP DNS / Direct IP 面向开发期 自助的沙盒测试环境 面向客户端友好的 SDK / Library以及示例 能够根据后端代码直接生成客户端业务代码框架 完善的报文描述能力（元数据），支撑配置型的报文裁剪 面向运维与运营 支持面向接入方的独立部署与快速水平扩展 面向业务场景或合作伙伴的自助API开通 对外接口性能与线上环境故障定位自助平台]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>API Gateway</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[企业架构设计杂谈]]></title>
    <url>%2Fblog%2Ffe548eb5.html</url>
    <content type="text"><![CDATA[定义企业架构（EA）：组成企业业务运作的流程/组织/IT等要素，明确这些要素之间的相互关系，以更好的实施公司战略。 企业架构的作用：1.EA提供一个共同愿景：通过To Be企业架构，为业务、信息、技术人员提供共同愿景。2.EA是一个描述工具：EA为组织中的所有干系人提供了一种描述手段（模板），使其可以对组织中的业务、信息系统及其之间关系按照各自的视角进行描述。而且由于使用统一的语言进行描述，所有干系人之间也有了无障碍沟通的基础，而这也正是EA最重要的用处。3.EA是一个知识库：EA为组织中所有参与者所提供的针对企业架构各方面的描述提供了一个结构化的知识库，有利于知识的共享和复用。4.EA是一个治理的过程：为了使组织内信息技术与业务的需求、变化相适应，EA提供了一套架构原则、治理机制、管理策略。 EA将围绕公司业务目标，在“战略”和“项目实施”之间架起连接的桥梁，是公司战略执行的基础。 企业架构（EA）的3个层面企业架构自顶向下分为：战略层面（业务战略、业务痛点、CSF）、架构规划层面（架构路标、业务架构、信息架构、IT架构、基础设施架构、架构管控及架构工具）、交付和实施层面（变革项目群/项目、实施项目执行与管理等） EA架构设计包括： 1.To-be业务流程设计 2.To-be应用系统设计（包括软件包选择、集成等） 3.To-be数据模型设计等等 4.从As-is到To-be的迁移计划 EA内容框架 战略 业务架构 信息架构 应用架构 技术架构 1.变革目标 2.变革措施 1. 业务运作模式 2.业务能力框架 3.流程分层图 4.流程集成图 5.流程图 6.流程视图 7.组织结构图 8.团队描述图 9.角色描述图 10. Metric分层图 11.Metric树 1.数据资产目录 2.业务数据标准 3.业务领域概念模型 4.业务领域逻辑数据 5.数据流 6.信息链 7.数据源 1.应用功能模型 （AD/AG/APP/ABB） 2.应用系统模型 3.SOA服务地图 4.应用系统集成模型 5.技术实现模型 1.ETF技术框架 2.技术策略 3.技术标准 4.技术规范 5.技术架构蓝皮书 6.产品架构说明书/技术设计]]></content>
      <categories>
        <category>企业管理</category>
      </categories>
      <tags>
        <tag>架构设计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【分享】凯文·凯利最新演讲：未来的12个趋势]]></title>
    <url>%2Fblog%2F1b7405be.html</url>
    <content type="text"><![CDATA[作为互联网的预言大神级人物，凯文·凯利对于经济和社会发展的趋势预测，影响了许多互联网大咖。20年前，他的作品《失控》一书，便已提前预见了移动互联网的今天与商业应用：物联网、云计算、虚拟现实、网络社区、大众智慧、迭代。 演讲｜凯文·凯利，来源｜混沌大学（ID:dfscx2014），特此感谢！ 以下为演讲内容： 跟30年后的我们相比，现在的我们就是一无所知。必须要相信那些不可能的事情，因为我们尚处于第一天的第一个小时——开始的开始。 我想讲一讲未来20年的技术走向。技术都会有一个前进的方向，我把它叫做必然，就是这个趋势像重力一样，一定会发生。比如有了芯片、电波等，必然会出现互联网，会出现手机。 我不想讲苹果会不会取胜，特斯拉会不会取胜，中国今后怎样，美国将来怎样，这不是我说的必然。我说的是一种总体趋势，我相信这些趋势是可以预测的，但是它的细节无法预测，比如电话一定会出现，但苹果不是；网络一定会出现，但Twitter不是。我想讲一些长期的趋势，这种必然的趋势都是交织在一起的、互相依赖的，但最后朝同一个方向前进。 1.第一个趋势 ：形成（becoming）——所有的东西都在不断升级 这是我的书《必然》中的第一章，就是所有的东西，都变成了另外的东西，所有的东西都是一种流动的状态，都在不断地改变。 下雨时每一滴水会如何进入到山谷，这个路线是肯定无从了解的。但是你一定知道方向——因为有重力，所以必然向下。 而类似于必然发生的“重力”，商业趋势也是必然的，总体趋势一定能够预知。我们是有选择的。在未来，新的技术必然会出现，我们可以选择想要新技术以什么样的形式出现——也就是说“到底出现什么”是我们可以选择的。 而今天聊到的必然趋势，互相依赖互相支持。在未来，所有的东西都变成了另外的东西，都在流动和改变。这样一种流动是时常在发生的。 比如有型的产品变成了无形的订购服务，过去在商场才能买到商品，但是现在，你可以在网上购买相应的服务，服务的一部分包含了你需要的商品。 比如从硬件到软件，现在所有的东西都是软件，这也是流动的趋势。 比如现在，名词变成了动词，有形的东西变成了无形的。还有产品向服务的转型，之前卖成品，是有形的，现在采取订购，订购服务，是无形的。 我们处在一个液态的世界，所有的东西都在不断地流动，不断升级，变得越来越好。比如汽车，这好像是我们能够想象到的最有形的东西，但是你在睡觉时，特斯拉汽车也在不断升级，它的确变得越来越好了，这就是我们将要进入的一个新世界。 这些对我们有什么影响呢？ 首先，终身学习，不断学习。当你一直处于一个学习的状态时，你永远都是一个新的人。所有的东西都是不确定的，你永远都是无知的，不管你多大年纪，处在人生哪个阶段，总会有新的东西出现，所以我们要永远处于学习的状态。 其次，所有的东西都是在形成的过程中，我们之前看到的是产品，现在看到的是过程。比如，我们以前拿到的是已出版的百科全书，现在的维基百科就不是一本百科全书，它是一个创造百科全书的过程。一直在被改变，一直处在创造的过程中。 2.第二个趋势 ：知化（Cognifying）——与人工智能的合作表现决定你的薪酬 未来技术变革的影响是永久性的。技术将和人工智能相关，技术要做的事情是让所有的东西更加智能，这个智化的过程就是技术带来的改变。 未来技术跟人工智能相关，是会给我们社会带来根本性变革的技术趋势，可能就像之前的印刷术一样。很多东西已经变得很聪明了。比如看X光方面的专家会被人工智能所取代的，法律方面的AI可以比人类律师助理更高效地阅读文件。 还有飞机驾驶员，比如一趟飞机的航程是12小时，人类飞行员只要工作七八分钟就行了，剩下的时间都是AI驾驶飞机，这些都是已经发生的。 我们为什么还需要人工智能去帮助我们开车呢？比如Google的无人驾驶汽车。因为他们的思考方式跟我们不一样，不会考虑杂七杂八的事情，只是专注去开车。 我们在AI方面做的事情，并不是让他们比人做得更聪明，因为它们很多方面已经比人更聪明了，我们要做的是各种各样的AI，让他们有多种思维方式。 Google训练人工智能玩电子游戏，十年前就开始做了，Google从来没想过去教AI怎么玩，而是教AI怎么学习，AI与人类的不同只在于思考的方式不同。 未来将有数以万计创业公司，他们从事的是人工智能用于某一个领域的工作。使用者越来越多的话，机器会越来越聪明，这是一种滚雪球的方式。 过去我们对智商的的认知就是一维的，这是一般的认知，我们不应该再这样看待智商。我们的智商像不同的乐器弹奏不同的乐曲，不同的人弹奏出的乐曲也不一样，所以大家的IQ不一样。动物、人类和机器的节奏也不一样，所以IQ也不同。 很多人也非常担心，机器人会跟我们抢工作。有一些工作实际上是可以直接让机器人来做的，我们在AI上做的事情不是要让AI更聪明，而是让AI自己去学习，有更多思考和思维 有很多新工作，是机器人去帮助你完成的，工作职位是不断增加的。 AI帮助人类从电力电气、蒸汽时代到现在多彩纷呈的现代世界。现在的汽车，人类用手的肌肉力量即可开动250马力，我们假设将250马力的车转换成250种思想，那么你开的就不是车，而是自动化的电脑。人类未来的目标，是将智力作为一种服务，可以像电力一样传输。 所以，对效率要求不高的工作更适合人类，比如要求创造力的工作，因为创造本身就是不讲究效率的，不用考虑正确性，这是人类适合去做的工作。任何看上去特别重复性的、没有意思的、没有什么乐趣可为的事情，都可以让机器完成。所以阿尔法狗和人比赛，是不公平的比赛，因为AI吸收了过去所有的套路。未来不管是哪个领域，实际上它都是最聪明的人加上机器。与人工智能的合作表现决定了你的薪酬，你必须要和机器进行合作，而不是和他们对抗。 3.第三个趋势 ：屏读（Screening）——任何一种平面都可以成为屏幕 这个趋势已经围绕在我们周围了，屏幕无处不在。任何一种平面都可以成为屏幕，看的书是一个屏幕，接触的所有平面都可以是一个屏幕。甚至有的人衣服都可以当成屏幕。 不同的屏幕之间形成了生态系统，不仅我们看他们，他们也在看我们。屏幕可以跟踪你的眼神，知道我们注意力聚焦在那儿了，我们重视什么东西，然后改变屏幕上呈现出来的内容。 情绪跟踪就是很好的例子，屏幕可以做注意力跟踪、情绪跟踪。可以根据用户的注意力、情绪做调整。知道你什么时候高兴，什么时候困扰。我们即将进入屏幕时代，无处不在的屏幕，以前是读书，现在是读屏。 原来书本给人权威，现在是流动开放杂乱的世界，现在的真相是要不断地自己组装。 4.第四个趋势 ：流动（Flowing）——你做的所有生意，都是数据 计算机中的三大阶段：原来是文件夹，之后是网络，现在我们处于一个数据流动的时代。现在的阶段就是流标签，云端组成各种各样的流，通过微信、微博、Facebook等等，我们可以听流媒体上的音乐，看流媒体上的电影电视，所有东西都成为一种流。 什么东西在流动呢？数据，不管你是做房地产、医药、化工，还是教育，其实你做的生意都是数据。商业乃数据之商业。归根结底，你在处理的都是数据。处理数据和处理客户一样重要。 全世界都处于同一个经济脉搏，企业不可能永远增长。但是城市不一样，城市永远在增长。因特网像一个城市，而不是一个企业，正因为它拥有着无限增长的特质。比如Facebook现在有15亿的社交连接，15亿人相互连接可以做的事情太多太多了，可以产生的价值也不可估量。 很多公司已经意识到了这一点。这么多的数据像是形成了超级生物体，远远超过人脑的容量了，这样一个巨大的机器星球，其实是全球化的一个运作，全世界的经济好像都以同样的脉搏在跳动，以同样的行为方式在运作。 5.第五个趋势 ：重混（Remixing）——大多数创新都是现有事物的重组 经济学家发现，全新的东西很少，大多数创新都是现有事物的重新组合。这种重组就是我这里所说的重混。这是世界发展的方向，重要的趋势。 做重组或者重混时，首先是要做一个拆解，把它拆解成非常原始的状态，再以另外一种方式进行重组，之后不断进行这样的循环，就像你把乐高拆开后再组装。 其实报纸也是一样，报纸不是一个单一的物体，它是一个组合，就是把不同的东西组合在一起：体育赛事、天气情况、书评，包括菜谱等等。英特网上也是，不同的信息组合在一起，把之前所有的报纸拆解了，然后组合在一起。 同样，我们也可以拆解银行，把不同的银行功能分解之后重新组合起来，汽车也是这样，基本上所有的东西都可以这样做。 把化学概念运用到企业当中来，就像一张元素周期表，看一下企业当中的元素周期表，有哪些必要的元素，进行多次拆解重组，会形成新的东西。企业想要升级，需要拆解企业的构成，再进行重组，在重组的过程中产生新事物。 6.第六个趋势 ：过滤（Filtering）——能吸引注意力，就能赚到钱 这是世界的另一面。现在有各种各样的选择，比如，每年会有600万首新歌，我们不可能听完，电影、书、杂志、文章，也是如此。 我们肯定需要一些人来帮忙，找到我们真正需要的东西，这就叫做过滤。 我们是缺乏注意力的，所有的东西都变得越来越丰富，唯一变得稀缺的是人类注意力，没有哪一种技术可以增加你的注意力时间。 金钱是会随注意力走的，你能够吸引注意力，就会赚到钱。只要人们在这个地方花了注意力，肯定需要这方面产生价值，你在这方面做文章，就会赚到钱。 既然我们的注意力是世界上最珍贵的资源，我付出了注意力，我就应该拿到报酬。比如，我如果看了广告，就应该拿到报酬。 7.第七个趋势 ：互动（Interacting）——它的影响将和AI一样深远 在我看来，互动的影响力可能和AI一样深远，电脑就是依赖于互动的。 为什么现在电视那么有意思呢？过去电视就是一个开关或者直接换一个频道，现在可以和电视互动了，可以搜索了，可以做各种各样的事情。 2050年的时候，电脑会变成什么样子？基本上你可以用整个身体没有任何障碍地互动，电脑是全方位可互动的机器。就像交响乐团的指挥家一样。有一些纳米雷达技术，他可以知道你手指动作的意义。智能手机之后应该是什么呢？一个是虚拟现实VR，把机器戴在脑袋上，你可以看到一些东西。 第二种是MR，也就是现实和虚拟混合。你如果把这样一个眼罩戴上的时候，每一件事情都是以3D的方式存在的，你可以用手控制这些现实，而且你真的是相信这些现实是存在的。 8.第八个趋势 ：使用（Accessing）——所有权价值变成使用权价值 “使用”这个词其实很难去解释，也就是之前我们是拥有一个产品，之后我们去使用某一种服务。 优步是世界上最大的租车公司，但是它并不拥有一辆车，Facebook是世界上最大的媒体公司，但是它却不拥有内容，阿里巴巴是世界上最大的零售商，但是它没有库存。 这种拥有的概念已经不是那么重要了，使用在很多方面比拥有更好，你马上用到一个东西，用完之后马上可以丢掉，肯定比拥有某些东西要更好。因为你的目的是使用，但是拥有的话，你要承担很多的责任。拥有的概念发生了改变，使用权优于所有权。很多东西，我们只需要使用，不需要维护、储存等其他工作。现在很多的软件也是朝这个方向走了，不用购买，而是订阅，不仅是数字行业，在有形的行业也在发生这样的转变，包括汽车，滴滴、优步都是其中的例子。 我们不需要拥有汽车，只需要使用这种服务，使用无需拥有，无需维护无需储存。 未来按需提供的服务比你拥有这件事物的比例要高。按需经济：各行业的优步。有形的企业也在发生改变。 年轻人，我们把他们叫做游牧民族一样的人，他们在世界各地旅行，但是他们随身什么都不带，你需要什么东西的时候，在哪儿都能够拿到。 再过二三十年，新兴人类去哪儿都不用带任何东西了，去任何一个酒店，他们马上提供你想穿的衣服，你穿完后留在那里，酒店会帮你清理好。 甚至连手机都不用上，因为你看到任何一个平板，就可以认出你是谁，变成你的屏幕，任何一个手机可以认出你来，就变成你的手机，整个世界都是你的，非常了解你，你需要什么都可以给你提供，想送到哪儿都可以。不需要行李箱，不需要任何东西，都有相应的服务，就像是新型游牧民族，不需要携带，游走世界。 9.第九个趋势 ：共享（Sharing）——核心不是分享，而是协作 经常会有人讲分享经济，我想拓展一下这个概念。 首先，现在的分享还属于非常初级的阶段，这个世界很大，有很多东西都是可以分享的。对于创业者来说有一个挑战：我们能够做什么？ 能让分享得越多，价值提升越多。 其实我们在讲分享时，不是一般意义的分享，而是在讲协作，即：分享＝合作，以一种规模化的方式合作，可以让成千上万几十亿的人以合作的方式进行互动，这些人的共同协作可以带来社会的变革。这种规模是之前大家都无法想象的，这就是未来分享的趋势所在，不仅仅是分享设备，这会产生巨大的价值和财富，带来巨大的社会变革。 这里面有一个例子，就是区块链，区块链技术就是把一些交易以分布式的方式呈现，所以你可以以合作的方式来进行计算，不是一对一的，而是整个网络上交易都可以计算出来，之前的任何一项交易都会成为之后的网络构建的基础，在这样一个区块链的网络当中，你是无法作弊的。 10.第十个趋势 ：开始（Beginning）——技术的用途，是“用”出来的 关于技术，在最开始的时候，没有人知道新的发明是最适合用于什么的，比如爱迪生的留声机，爱迪生根本不知道这能用来干什么。 留声机慢慢应用于两个场景：一是录下临终的遗言，二是录下教堂里的讲话，包括唱歌，后来留声机主要用于这个用途。 所以，用途很多时候就是通过使用来发现的，不断尝试，在发明的时候，我们可能想不了那么多。新技术出来的时候，我们也不知道可以用来干嘛，只有通过使用。 我们要评估技术的时候，也必须要使用这个技术，而不仅仅是空想，因为这个趋势是必然的，我们要指引和控制技术发展的方向，必须要使用，然后去调试、优化，使这个技术变得更好。 因为这些是很新的东西，虽然我们每天花五个多小时在社交媒体上，我们也不知道社交媒体能够给我们带来什么好处，这些问题都没有想通。它要求我们真正去学习它，使用它，这是需要时间的。我们现在在做的工作可能和两年后完全不一样。150年前，美国70%是农民，现在只有1%的农民，难道那69%的农民就失业了？并不是，设想一下，在多年之后，工作可能就不存在了，我们在不断的时代的演变中，不断改变。先去做，去尝试，去探索然后再思考，再规划，再去重复试验。要先做后想，再做再想。如果没有做就去思考，只是纸上谈兵。所以我们需要不断学习，不断接受新的技能心得知识。我们要迎合这个时代的变化，所有人都是新手。学习是不断创新的，如何去创造新的东西，如何去做创造和引领，不仅仅是学习，要去思考，勇于试错（不能害怕这个错误），犯错和学习进步不能分开。持续性的小错误的容忍性，才能有大的创新的推动。最核心的一点，是需要有思考的原型，然后把它延长下去。 11.第十一个趋势：提问（Questionning）——好问题比完美的答案更重要 今天要找到答案很容易，你可以问百度，可以问谷歌，还有各种AI，他们都特别棒，回答变得越来越便宜。 但是同时，提问变得越来越贵了，我们必须要培训人们去提问，让他们创造问题，一个好的问题，会比一个完美的回答更有价值。 你必须要有非常好的驾驭问题的思维方式，因为问题本身可以开发一个新领域，是一个能动最好的推送者，像引擎一样，推动人的思维不断去创造。 问题比回答更有意义，好的问题是新的领域，问一个好的问题，必须要有一个驾驭问题的能力。必须要有意识去挖掘问题，不管设想是怎样的，问题要提出来。 12.第十二个趋势 ：颠覆（Disruption）——内因从来不是主要原因 最后我想说说颠覆，就是我们的创造性从何而来。当我们在思考颠覆时，有三个规律： 一、不管你在哪个行业，颠覆不是从内部出现的，而是从外部推动的，内因并不是最主要的原因。医药界的创新和发展，并不是医药界推动的。搜索引擎的创新，也不是从搜索开始的。 二、一些一蹴而就的现象和技术，只是看上去很突然，但它其实已经在背后存在了很多年，比如VR已经25岁了，只是因为没有满足成为产品的底限要求，所以到不了大众的视线。 三，创造或者发明，是一个不挣钱的市场。首先大多数的发明都是失败的，风险非常高，一开始的质量非常差，也就意味着利润非常低，任何商人都会告诉你，投资这一行是非常不挣钱的。 市场小、前途未卜是创业公司的坐标，成功的公司不需要承担这些风险。但是创业公司没有选择，因为他们挤不进那些体量大、很赚钱的市场，只能从这块看起来很差的业务做起。下一波技术颠覆： 航空公司的颠覆者是无人机，现在无人机可以搭载人了，未来还会有更多的发展。也就是说航空业的颠覆来自于无人机的公司。 而银行的颠覆来自比特币、支付宝等外部公司。 电信行业颠覆不是来自手机、移动通讯网络，而是来自无线网。 汽车的颠覆不是来自汽车，而是特斯拉，带轮子的计算机。 物种进化过程中不断思考如何进化来提升适应度，低的物种就会被淘汰，高适应度的物种就会存活下来。 所有的企业都在不断追求卓越，也是为了提升适应度。当处于生态圈里卓越的公司，想要攀登到更高峰的时候，需要先下山（降低适应度）再提升来达到顶峰，企业越成功越难下山。 结 语 我最后做一个总结，大家都知道未来令人难以置信，很多年前我在讲电脑，当时的计算机非常大，如果我说，以后计算机可以放到包里，甚至衣服上，人们会觉得我很愚蠢。 这些年来我发现一点，我们必须要相信那些不可能的事情，那些看起来不太可能为我们所使用的东西，将来肯定会为我们所用。我们尚处于开始的开始，处于第一天的第一个小时。现在没有人是AI的专家——很多人懂AI，但是没有人是专家。跟30年后的我们相比，现在的我们就是一无所知。 我们看过去，认为过去是好的创业时机。同样，未来也是最好的时候。我们也处于最好的创业时代，因为我们还处在一个起点的时代。 如果现在我们已经处于20年以后了，人们会怎么说呢？可能会说，天呀，我真希望2017年活在这个世界上去创业，因为那个时候是创业的最好时期，很简单就找到商机了，很容易就改变世界了。世界上最伟大的东西，现在还没有被发明出来，也就是说你现在开始，为时未晚。]]></content>
      <tags>
        <tag>未来趋势</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pattern: API Gateway]]></title>
    <url>%2Fblog%2F5fd03d2c.html</url>
    <content type="text"><![CDATA[Pattern: API Gateway / Backend for Front-EndContextLet’s imagine you are building an online store that uses the Microservice architecture pattern and that you are implementing the product details page. You need to develop multiple versions of the product details user interface: HTML5/JavaScript-based UI for desktop and mobile browsers - HTML is generated by a server-side web application Native Android and iPhone clients - these clients interact with the server via REST APIs In addition, the online store must expose product details via a REST API for use by 3rd party applications. A product details UI can display a lot of information about a product. For example, the Amazon.com details page for POJOs in Actiondisplays: Basic information about the book such as title, author, price, etc. Your purchase history for the book Availability Buying options Other items that are frequently bought with this book Other items bought by customers who bought this book Customer reviews Sellers ranking … Since the online store uses the Microservice architecture pattern the product details data is spread over multiple services. For example, Product Info Service - basic information about the product such as title, author Pricing Service - product price Order service - purchase history for product Inventory service - product availability Review service - customer reviews … Consequently, the code that displays the product details needs to fetch information from all of these services. ProblemHow do the clients of a Microservices-based application access the individual services? Forces The granularity of APIs provided by microservices is often different than what a client needs. Microservices typically provide fine-grained APIs, which means that clients need to interact with multiple services. For example, as described above, a client needing the details for a product needs to fetch data from numerous services. Different clients need different data. For example, the desktop browser version of a product details page desktop is typically more elaborate then the mobile version. Network performance is different for different types of clients. For example, a mobile network is typically much slower and has much higher latency than a non-mobile network. And, of course, any WAN is much slower than a LAN. This means that a native mobile client uses a network that has very difference performance characteristics than a LAN used by a server-side web application. The server-side web application can make multiple requests to backend services without impacting the user experience where as a mobile client can only make a few. The number of service instances and their locations (host+port) changes dynamically Partitioning into services can change over time and should be hidden from clients Services might use a diverse set of protocols, some of which might not be web friendly SolutionImplement an API gateway that is the single entry point for all clients. The API gateway handles requests in one of two ways. Some requests are simply proxied/routed to the appropriate service. It handles other requests by fanning out to multiple services.Rather than provide a one-size-fits-all style API, the API gateway can expose a different API for each client. For example, the Netflix API gateway runs client-specific adapter code that provides each client with an API that’s best suited to its requirements.The API gateway might also implement security, e.g. verify that the client is authorized to perform the request Variation: Backend for front-endA variation of this pattern is the Backend for Front-End pattern. It defines a separate API gateway for each kind of client.In this example, there are three kinds of clients: web application, mobile application, and external 3rd party application. There are three different API gateways. Each one is provides an API for its client. ExamplesNetflix API gatewayA simple Java/Spring API gateway from the Money Transfer example application. Resulting contextUsing an API gateway has the following benefits: Insulates the clients from how the application is partitioned into microservices Insulates the clients from the problem of determining the locations of service instancesProvides the optimal API for each client Reduces the number of requests/roundtrips. For example, the API gateway enables clients to retrieve data from multiple services with a single round-trip. Fewer requests also means less overhead and improves the user experience. An API gateway is essential for mobile applications. Simplifies the client by moving logic for calling multiple services from the client to API gateway Translates from a “standard” public web-friendly API protocol to whatever protocols are used internally The API gateway pattern has some drawbacks: Increased complexity - the API gateway is yet another moving part that must be developed, deployed and managed Increased response time due to the additional network hop through the API gateway - however, for most applications the cost of an extra roundtrip is insignificant. Issues: How implement the API gateway? An event-driven/reactive approach is best if it must scale to scale to handle high loads. On the JVM, NIO-based libraries such as Netty, Spring Reactor, etc. make sense. NodeJS is another option. Related patterns The Microservice architecture pattern creates the need for this pattern. The API gateway must use either the Client-side Discovery pattern or Server-side Discovery pattern to route requests to available service instances. The API Gateway may authenticate the user and pass an Access Token containing information about the user to the services An API Gateway will use a Circuit Breaker to invoke services An API gateway often implements the API Composition pattern Known uses Netflix API gateway]]></content>
      <categories>
        <category>架构设计</category>
      </categories>
      <tags>
        <tag>架构设计</tag>
        <tag>微服务</tag>
        <tag>API 网关</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Keras基本概念]]></title>
    <url>%2Fblog%2F675d4493.html</url>
    <content type="text"><![CDATA[一些基本概念在开始学习Keras之前，我们希望传递一些关于Keras，关于深度学习的基本概念和技术，我们建议新手在使用Keras之前浏览一下本页面提到的内容，这将减少你学习中的困惑 符号计算Keras的底层库使用Theano或TensorFlow，这两个库也称为Keras的后端。无论是Theano还是TensorFlow，都是一个“符号式”的库。 因此，这也使得Keras的编程与传统的Python代码有所差别。笼统的说，符号主义的计算首先定义各种变量，然后建立一个“计算图”，计算图规定了各个变量之间的计算关系。建立好的计算图需要编译以确定其内部细节，然而，此时的计算图还是一个“空壳子”，里面没有任何实际的数据，只有当你把需要运算的输入放进去后，才能在整个模型中形成数据流，从而形成输出值。 就像用管道搭建供水系统，当你在拼水管的时候，里面是没有水的。只有所有的管子都接完了，才能送水。 Keras的模型搭建形式就是这种方法，在你搭建Keras模型完毕后，你的模型就是一个空壳子，只有实际生成可调用的函数后（K.function），输入数据，才会形成真正的数据流。 使用计算图的语言，如Theano，以难以调试而闻名，当Keras的Debug进入Theano这个层次时，往往也令人头痛。没有经验的开发者很难直观的感受到计算图到底在干些什么。尽管很让人头痛，但大多数的深度学习框架使用的都是符号计算这一套方法，因为符号计算能够提供关键的计算优化、自动求导等功能。 我们建议你在使用前稍微了解一下Theano或TensorFlow，Bing/Google一下即可。 张量张量，或tensor，是本文档会经常出现的一个词汇，在此稍作解释。 使用这个词汇的目的是为了表述统一，张量可以看作是向量、矩阵的自然推广，我们用张量来表示广泛的数据类型。 规模最小的张量是0阶张量，即标量，也就是一个数。 当我们把一些数有序的排列起来，就形成了1阶张量，也就是一个向量 如果我们继续把一组向量有序的排列起来，就形成了2阶张量，也就是一个矩阵 把矩阵摞起来，就是3阶张量，我们可以称为一个立方体，具有3个颜色通道的彩色图片就是一个这样的立方体 把立方体摞起来，好吧这次我们真的没有给它起别名了，就叫4阶张量了，不要去试图想像4阶张量是什么样子，它就是个数学上的概念。 张量的阶数有时候也称为维度，或者轴，轴这个词翻译自英文axis。譬如一个矩阵[[1,2],[3,4]]，是一个2阶张量，有两个维度或轴，沿着第0个轴（为了与python的计数方式一致，本文档维度和轴从0算起）你看到的是[1,2]，[3,4]两个向量，沿着第1个轴你看到的是[1,3]，[2,4]两个向量。 要理解“沿着某个轴”是什么意思，不妨试着运行一下下面的代码：12345678import numpy as npa = np.array([[1,2],[3,4]])sum0 = np.sum(a, axis=0)sum1 = np.sum(a, axis=1)print sum0print sum1 关于张量，目前知道这么多就足够了。事实上我也就知道这么多 data_format这是一个无可奈何的问题，在如何表示一组彩色图片的问题上，Theano和TensorFlow发生了分歧，’th’模式，也即Theano模式会把100张RGB三通道的16×32（高为16宽为32）彩色图表示为下面这种形式（100,3,16,32），Caffe采取的也是这种方式。第0个维度是样本维，代表样本的数目，第1个维度是通道维，代表颜色通道数。后面两个就是高和宽了。这种theano风格的数据组织方法，称为“channels_first”，即通道维靠前。 而TensorFlow，的表达形式是（100,16,32,3），即把通道维放在了最后，这种数据组织方式称为“channels_last”。 Keras默认的数据组织形式在~/.keras/keras.json中规定，可查看该文件的image_data_format一项查看，也可在代码中通过K.image_data_format()函数返回，请在网络的训练和测试中保持维度顺序一致。 唉，真是蛋疼，你们商量好不行吗？ 函数式模型函数式模型算是本文档比较原创的词汇了，所以这里要说一下 在Keras 0.x中，模型其实有两种，一种叫Sequential，称为序贯模型，也就是单输入单输出，一条路通到底，层与层之间只有相邻关系，跨层连接统统没有。这种模型编译速度快，操作上也比较简单。第二种模型称为Graph，即图模型，这个模型支持多输入多输出，层与层之间想怎么连怎么连，但是编译速度慢。可以看到，Sequential其实是Graph的一个特殊情况。 在Keras1和Keras2中，图模型被移除，而增加了了“functional model API”，这个东西，更加强调了Sequential是特殊情况这一点。一般的模型就称为Model，然后如果你要用简单的Sequential，OK，那还有一个快捷方式Sequential。 由于functional model API在使用时利用的是“函数式编程”的风格，我们这里将其译为函数式模型。总而言之，只要这个东西接收一个或一些张量作为输入，然后输出的也是一个或一些张量，那不管它是什么鬼，统统都称作“模型”。 batch这个概念与Keras无关，老实讲不应该出现在这里的，但是因为它频繁出现，而且不了解这个技术的话看函数说明会很头痛，这里还是简单说一下。 深度学习的优化算法，说白了就是梯度下降。每次的参数更新有两种方式。 第一种，遍历全部数据集算一次损失函数，然后算函数对各个参数的梯度，更新梯度。这种方法每更新一次参数都要把数据集里的所有样本都看一遍，计算量开销大，计算速度慢，不支持在线学习，这称为Batch gradient descent，批梯度下降。 另一种，每看一个数据就算一下损失函数，然后求梯度更新参数，这个称为随机梯度下降，stochastic gradient descent。这个方法速度比较快，但是收敛性能不太好，可能在最优点附近晃来晃去，hit不到最优点。两次参数的更新也有可能互相抵消掉，造成目标函数震荡的比较剧烈。 为了克服两种方法的缺点，现在一般采用的是一种折中手段，mini-batch gradient decent，小批的梯度下降，这种方法把数据分为若干个批，按批来更新参数，这样，一个批中的一组数据共同决定了本次梯度的方向，下降起来就不容易跑偏，减少了随机性。另一方面因为批的样本数与整个数据集相比小了很多，计算量也不是很大。 基本上现在的梯度下降都是基于mini-batch的，所以Keras的模块中经常会出现batch_size，就是指这个。 顺便说一句，Keras中用的优化器SGD是stochastic gradient descent的缩写，但不代表是一个样本就更新一回，还是基于mini-batch的。 epochs真的不是很想解释这个词，但是新手问的还挺多的…… 简单说，epochs指的就是训练过程中数据将被“轮”多少次，就这样。 关于深度学习由于Keras是为深度学习设计的工具，我们这里只列举深度学习中的一些基本概念。请确保你对下面的概念有一定理解。 有监督学习，无监督学习，分类，聚类，回归 神经元模型，多层感知器，BP算法 目标函数（损失函数），激活函数，梯度下降法 全连接网络、卷积神经网络、递归神经网络 训练集，测试集，交叉验证，欠拟合，过拟合 数据规范化 其他我还没想到的东西……想到再补充]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>AI</tag>
        <tag>Keras</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Keras 序贯（Sequential）模型]]></title>
    <url>%2Fblog%2Fdf5635be.html</url>
    <content type="text"><![CDATA[序贯（Sequential）模型序贯模型是多个网络层的线性堆叠，可理解为多个网络层的线性函数拟合堆叠。 可以通过向Sequential模型传递一个layer的list来构造该模型：123456789from keras.models import Sequentialfrom keras.layers import Dense, Activationmodel = Sequential([Dense(32, units=784),Activation(&apos;relu&apos;),Dense(10),Activation(&apos;softmax&apos;),]) 也可以通过.add()方法一个个的将layer加入模型中：123model = Sequential()model.add(Dense(32, input_shape=(784,)))model.add(Activation(&apos;relu&apos;)) 指定输入数据的shape模型需要知道输入数据的shape，因此，Sequential的第一层需要接受一个关于输入数据shape的参数，后面的各个层则可以自动的推导出中间数据的shape，因此不需要为每个层都指定这个参数。有几种方法来为第一层指定输入数据的shape 传递一个input_shape的关键字参数给第一层，input_shape是一个tuple类型的数据，其中也可以填入None，如果填入None则表示此位置可能是任何正整数。数据的batch大小不应包含在其中 有些2D层，如Dense，支持通过指定其输入维度input_dim来隐含的指定输入数据shape。一些3D的时域层支持通过参数input_dim和input_length来指定输入shape。 如果你需要为输入指定一个固定大小的batch_size（常用于stateful RNN网络），可以传递batch_size参数到一个层中，例如你想指定输入张量的batch大小是32，数据shape是（6，8），则你需要传递batch_size=32和input_shape=(6,8)。 12345model = Sequential()model.add(Dense(32, input_dim=784))model = Sequential()model.add(Dense(32, input_shape=784)) 编译在训练模型之前，我们需要通过compile来对学习过程进行配置。compile接收三个参数： 优化器optimizer：该参数可指定为已预定义的优化器名，如rmsprop、adagrad，或一个Optimizer类的对象，详情见optimizers 损失函数loss：该参数为模型试图最小化的目标函数，它可为预定义的损失函数名，如categorical_crossentropy、mse，也可以为一个损失函数。详情见losses 指标列表metrics：对分类问题，我们一般将该列表设置为metrics=[&#39;accuracy&#39;]。指标可以是一个预定义指标的名字,也可以是一个用户定制的函数.指标函数应该返回单个张量,或一个完成metric_name - &gt; metric_value映射的字典.请参考性能评估 1234567891011121314151617181920212223# For a multi-class classification problemmodel.compile(optimizer=&apos;rmsprop&apos;, loss=&apos;categorical_crossentropy&apos;, metrics=[&apos;accuracy&apos;])# For a binary classification problemmodel.compile(optimizer=&apos;rmsprop&apos;, loss=&apos;binary_crossentropy&apos;, metrics=[&apos;accuracy&apos;])# For a mean squared error regression problemmodel.compile(optimizer=&apos;rmsprop&apos;, loss=&apos;mse&apos;)# For custom metricsimport keras.backend as Kdef mean_pred(y_true, y_pred): return K.mean(y_pred)model.compile(optimizer=&apos;rmsprop&apos;, loss=&apos;binary_crossentropy&apos;, metrics=[&apos;accuracy&apos;, mean_pred]) 训练Keras以Numpy数组作为输入数据和标签的数据类型。训练模型一般使用fit函数。下面是一些例子。 12345678910111213141516# For a single-input model with 2 classes (binary classification):model = Sequential()model.add(Dense(32, activation=&apos;relu&apos;, input_dim=100))model.add(Dense(1, activation=&apos;sigmoid&apos;))model.compile(optimizer=&apos;rmsprop&apos;, loss=&apos;binary_crossentropy&apos;, metrics=[&apos;accuracy&apos;])# Generate dummy dataimport numpy as npdata = np.random.random((1000, 100))labels = np.random.randint(2, size=(1000, 1))# Train the model, iterating on the data in batches of 32 samplesmodel.fit(data, labels, epochs=10, batch_size=32) 12345678910111213141516171819# For a single-input model with 10 classes (categorical classification):model = Sequential()model.add(Dense(32, activation=&apos;relu&apos;, input_dim=100))model.add(Dense(10, activation=&apos;softmax&apos;))model.compile(optimizer=&apos;rmsprop&apos;, loss=&apos;categorical_crossentropy&apos;, metrics=[&apos;accuracy&apos;])# Generate dummy dataimport numpy as npdata = np.random.random((1000, 100))labels = np.random.randint(10, size=(1000, 1))# Convert labels to categorical one-hot encodingone_hot_labels = keras.utils.to_categorical(labels, num_classes=10)# Train the model, iterating on the data in batches of 32 samplesmodel.fit(data, one_hot_labels, epochs=10, batch_size=32)]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>AI</tag>
        <tag>Keras</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Keras 函数式模型API]]></title>
    <url>%2Fblog%2F248338d.html</url>
    <content type="text"><![CDATA[##函数式模型接口 Keras的函数式模型为Model，即广义的拥有输入和输出的模型，我们使用Model来初始化一个函数式模型 123456from keras.models import Modelfrom keras.layers import Input, Densea = Input(shape=(32,))b = Dense(32)(a)model = Model(inputs=a, outputs=b) 在这里，我们的模型以a为输入，以b为输出，同样我们可以构造拥有多输入和多输出的模型 常用Model属性 model.layers：组成模型图的各个层 model.inputs：模型的输入张量列表 model.outputs：模型的输出张量列表 Model模型方法compile1compile(self, optimizer, loss, metrics=None, loss_weights=None, sample_weight_mode=None) 本函数编译模型以供训练，参数有 optimizer：优化器，为预定义优化器名或优化器对象，参考优化器 loss损失函数，为预定义损失函数名或一个目标函数，参考损失函数 metrics：列表，包含评估模型在训练和测试时的性能的指标，典型用法是metrics=[&#39;accuracy&#39;]如果要在多输出模型中为不同的输出指定不同的指标，可像该参数传递一个字典，例如metrics={&#39;ouput_a&#39;: &#39;accuracy&#39;} sample_weight_mode：如果你需要按时间步为样本赋权（2D权矩阵），将该值设为“temporal”。默认为“None”，代表按样本赋权（1D权）。如果模型有多个输出，可以向该参数传入指定sample_weight_mode的字典或列表。在下面fit函数的解释中有相关的参考内容。 kwargs：使用TensorFlow作为后端请忽略该参数，若使用Theano作为后端，kwargs的值将会传递给 K.function 当为参数传入非法值时会抛出异常 【Tips】如果你只是载入模型并利用其predict，可以不用进行compile。在Keras中，compile主要完成损失函数和优化器的一些配置，是为训练服务的。predict会在内部进行符号函数的编译工作（通过调用_make_predict_function生成函数）， fit函数1fit(self, x=None, y=None, batch_size=32, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0) 本函数用以训练模型，参数有： x：输入数据。如果模型只有一个输入，那么x的类型是numpy array，如果模型有多个输入，那么x的类型应当为list，list的元素是对应于各个输入的numpy array。如果模型的每个输入都有名字，则可以传入一个字典，将输入名与其输入数据对应起来。 y：标签，numpy array。如果模型有多个输出，可以传入一个numpy array的list。如果模型的输出拥有名字，则可以传入一个字典，将输出名与其标签对应起来。 batch_size：整数，指定进行梯度下降时每个batch包含的样本数。训练时一个batch的样本会被计算一次梯度下降，使目标函数优化一步。 nb_epoch：整数，训练的轮数，训练数据将会被遍历nb_epoch次。Keras中nb开头的变量均为”number of”的意思 verbose：日志显示，0为不在标准输出流输出日志信息，1为输出进度条记录，2为每个epoch输出一行记录 callbacks：list，其中的元素是keras.callbacks.Callback的对象。这个list中的回调函数将会在训练过程中的适当时机被调用，参考回调函数 validation_split：0~1之间的浮点数，用来指定训练集的一定比例数据作为验证集。验证集将不参与训练，并在每个epoch结束后测试的模型的指标，如损失函数、精确度等。注意，validation_split的划分在shuffle之后，因此如果你的数据本身是有序的，需要先手工打乱再指定validation_split，否则可能会出现验证集样本不均匀。 validation_data：形式为（X，y）或（X，y，sample_weights）的tuple，是指定的验证集。此参数将覆盖validation_spilt。 shuffle：布尔值，表示是否在训练过程中每个epoch前随机打乱输入样本的顺序。 class_weight：字典，将不同的类别映射为不同的权值，该参数用来在训练过程中调整损失函数（只能用于训练）。该参数在处理非平衡的训练数据（某些类的训练样本数很少）时，可以使得损失函数对样本数不足的数据更加关注。 sample_weight：权值的numpy array，用于在训练时调整损失函数（仅用于训练）。可以传递一个1D的与样本等长的向量用于对样本进行1对1的加权，或者在面对时序数据时，传递一个的形式为（samples，sequence_length）的矩阵来为每个时间步上的样本赋不同的权。这种情况下请确定在编译模型时添加了sample_weight_mode=’temporal’。 initial_epoch: 从该参数指定的epoch开始训练，在继续之前的训练时有用。 输入数据与规定数据不匹配时会抛出错误 fit函数返回一个History的对象，其History.history属性记录了损失函数和其他指标的数值随epoch变化的情况，如果有验证集的话，也包含了验证集的这些指标变化情况 evaluate1evaluate(self, x, y, batch_size=32, verbose=1, sample_weight=None) 本函数按batch计算在某些输入数据上模型的误差，其参数有： x：输入数据，与fit一样，是numpy array或numpy array的list y：标签，numpy array batch_size：整数，含义同fit的同名参数 verbose：含义同fit的同名参数，但只能取0或1 sample_weight：numpy array，含义同fit的同名参数 本函数返回一个测试误差的标量值（如果模型没有其他评价指标），或一个标量的list（如果模型还有其他的评价指标）。model.metrics_names将给出list中各个值的含义。 如果没有特殊说明，以下函数的参数均保持与fit的同名参数相同的含义 如果没有特殊说明，以下函数的verbose参数（如果有）均只能取0或1 predict1predict(self, x, batch_size=32, verbose=0) 本函数按batch获得输入数据对应的输出，其参数有： 函数的返回值是预测值的numpy array train_on_batch1train_on_batch(self, x, y, class_weight=None, sample_weight=None) 本函数在一个batch的数据上进行一次参数更新 函数返回训练误差的标量值或标量值的list，与evaluate的情形相同。 test_on_batch1test_on_batch(self, x, y, sample_weight=None) 本函数在一个batch的样本上对模型进行评估 函数的返回与evaluate的情形相同 predict_on_batch1predict_on_batch(self, x) 本函数在一个batch的样本上对模型进行测试 函数返回模型在一个batch上的预测结果 fit_generator1fit_generator(self, generator, steps_per_epoch, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, class_weight=None, max_q_size=10, workers=1, pickle_safe=False, initial_epoch=0) 利用Python的生成器，逐个生成数据的batch并进行训练。生成器与模型将并行执行以提高效率。例如，该函数允许我们在CPU上进行实时的数据提升，同时在GPU上进行模型训练 函数的参数是： generator：生成器函数，生成器的输出应该为： 一个形如（inputs，targets）的tuple 一个形如（inputs, targets,sample_weight）的tuple。所有的返回值都应该包含相同数目的样本。生成器将无限在数据集上循环。每个epoch以经过模型的样本数达到samples_per_epoch时，记一个epoch结束 steps_per_epoch：整数，当生成器返回steps_per_epoch次数据时计一个epoch结束，执行下一个epoch epochs：整数，数据迭代的轮数 verbose：日志显示，0为不在标准输出流输出日志信息，1为输出进度条记录，2为每个epoch输出一行记录 validation_data：具有以下三种形式之一 生成验证集的生成器 一个形如（inputs,targets）的tuple 一个形如（inputs,targets，sample_weights）的tuple validation_steps: 当validation_data为生成器时，本参数指定验证集的生成器返回次数 class_weight：规定类别权重的字典，将类别映射为权重，常用于处理样本不均衡问题。 sample_weight：权值的numpy array，用于在训练时调整损失函数（仅用于训练）。可以传递一个1D的与样本等长的向量用于对样本进行1对1的加权，或者在面对时序数据时，传递一个的形式为（samples，sequence_length）的矩阵来为每个时间步上的样本赋不同的权。这种情况下请确定在编译模型时添加了sample_weight_mode=&#39;temporal&#39;。 workers：最大进程数 max_q_size：生成器队列的最大容量 pickle_safe: 若为真，则使用基于进程的线程。由于该实现依赖多进程，不能传递non picklable（无法被pickle序列化）的参数到生成器中，因为无法轻易将它们传入子进程中。 initial_epoch: 从该参数指定的epoch开始训练，在继续之前的训练时有用。 函数返回一个History对象 例子123456789101112def generate_arrays_from_file(path): while 1: f = open(path) for line in f: # create numpy arrays of input data # and labels, from each line in the file x1, x2, y = process_line(line) yield (&#123;&apos;input_1&apos;: x1, &apos;input_2&apos;: x2&#125;, &#123;&apos;output&apos;: y&#125;) f.close()model.fit_generator(generate_arrays_from_file(&apos;/my_file.txt&apos;), steps_per_epoch=10000, epochs=10) evaluate_generator1evaluate_generator(self, generator, steps, max_q_size=10, workers=1, pickle_safe=False) 本函数使用一个生成器作为数据源，来评估模型，生成器应返回与test_on_batch的输入数据相同类型的数据。 函数的参数是： generator：生成输入batch数据的生成器 val_samples：生成器应该返回的总样本数 steps：生成器要返回数据的轮数 max_q_size：生成器队列的最大容量 nb_worker：使用基于进程的多线程处理时的进程数 pickle_safe：若设置为True，则使用基于进程的线程。注意因为它的实现依赖于多进程处理，不可传递不可pickle的参数到生成器中，因为它们不能轻易的传递到子进程中。 predict_generator1fit_generator(self, generator, steps_per_epoch, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, class_weight=None, max_q_size=10, workers=1, pickle_safe=False, initial_epoch=0) 从一个生成器上获取数据并进行预测，生成器应返回与predict_on_batch输入类似的数据 函数的参数是： generator：生成输入batch数据的生成器 val_samples：生成器应该返回的总样本数 max_q_size：生成器队列的最大容量 nb_worker：使用基于进程的多线程处理时的进程数 pickle_safe：若设置为True，则使用基于进程的线程。注意因为它的实现依赖于多进程处理，不可传递不可pickle的参数到生成器中，因为它们不能轻易的传递到子进程中。]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>AI</tag>
        <tag>Keras</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker 学习笔记]]></title>
    <url>%2Fblog%2F920e92d1.html</url>
    <content type="text"><![CDATA[Docker 的核心组件 Docker客户端和服务器 Docker 镜像 Registry Docker容器 Docker客户端和服务器：Docker是一个客户-服务器（C/S）架构的呈现。Docker客户端只需向Docker服务器或守护进程发出请求，服务器或守护进程将完成所有工作并返回结果。Docker提供一个命令行工具docker以及一整套RESTful API。你可以在同一台宿主机上运行Docker守护进程和客户端，可以从本地的Docker客户端连接到允许在另一台宿主机上远程Docker守护进程。 Docker 镜像：用户基于镜像来允许自己的容器，镜像也是Docker生命周期的“构建”部分。镜像是基于联合(Union)文件系统的一种层次的结果，由一系列指令一步步构建出来的。例如：添加一个文件；执行一个命令；打开一个端口。也可以把镜像当做容器的“源代码”。镜像体积很小，非常“便携”，易于分享、存储和更新。 Registry：Docker用Registry来保存用户构建的镜像。Registry分为公共和私有两种。Docker运营的公共Registry叫做Docker Hub。用户可以在Docker Hub注册账号，分享并保存自己的镜像。你也可以架设自己的私有Registry。 安装Docker 建议读者了解一下如何使用Puppet 或 Chef这样的工具来安装Docker，而不是纯手动安装。例如，可以在网上找到安装Docker的Puppet模块和Chef cookbook。 docker支持很多Linux环境，OS X和Microsoft Windows也能安装Docker。在OS X系统和Windows系统中可以用Boot2Docker工具安装Docker。 Boot2Docker是一个极小的虚拟机，同时提供了一个包装脚本对该虚拟机进行管理。该虚拟机运行一个守护进程，并在OS X或Windows中提供一个本地的Docker守护进程。Docker的客户端工具docker可以作为这些平台的原生程序安装，并连接到在Boot2Docker虚拟机中运行的Docker守护进程。 docker不支持32位CPU。]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>容器</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大数据学习随记]]></title>
    <url>%2Fblog%2Ff006360f.html</url>
    <content type="text"><![CDATA[作者：勾满誉链接：https://www.zhihu.com/question/52187221/answer/129439263来源：知乎著作权归作者所有，转载请联系作者获得授权。 大数据开发一共几个流程，大概概括起来有： 收集、清洗、数仓（建模）、OLAP、可视化 这里边： 收集一般的技术是：Kafka、Flume、高性能HTTP开发（可能）、Avro协议（可能）、Thrift协议（可能），取决于所在公司的技术栈。 清洗：Spark、HiveSQL/SparkSQL、MapReduce（已经过时） 存储：HDFS、Alluxio（分布式内存存储）、Redis（高速缓存）、mongoDB（文档型数据库）… 流式计算：Spark Streaming / Storm 数仓建模：Hive、MongoDB、HBase OLAP：MySQL（常用），PostgreSQL（GreenPlum）MyCAT（小众）… 数据可视化：一般来说这活不归你管， 技术有 echarts.js hicharts.js d3.js … 看眼花了吧？ 其实很好理解， 从上到下就是：数据要怎么存， 数据要怎么查… 你需要学的是： 计算机体系基础： 内存、CPU、指令、等等这些概念，得有个感觉，不然别人一说，你都不知道咋回事，尴尬了。看《深入理解计算机系统》。 网络基础： 这个我还真不知道有什么书， 《TCP/IP详解》有点深了，不过你有时间，慢慢啃下来挺好， 而且第一本就够用，书也不厚。 数据库基础：RMDBS里的MySQL其实我不推荐，但是这玩意已经烂大街了，是个公司就用，不学也得学。postgreSQL很不错，但是用的人少。 Java系的语言你必须得会， 重要的就是Java和Scala， Java用来做传统的开发（你总要写几个接口， 这个时候最常用的就是SpringMVC/Mybatis，这俩兄弟玩明白就行了， 但是什么J2EE，什么Hibernate，什么HTML5，跟你一点关系也！没！有！）。 Scala是我特别推崇的一门语言， 灵活、高效， Java搞懂了就把它也学了，以后写Spark，甚至用Play写Web，都很爽。 Python是必学的一门语言， 灵活的脚本， 以后想早点下班回家，少不了它。 Hadoop生态体系你必须得懂， 不需要一个组件一个组件的文档去看， 先看个大概，知道啥玩意是干啥的， 然后用的时候再去看文档。 Hadoop想自己装是有点蛋疼，跟你导师申请个阿里云几台机， 慢慢折腾去吧。 哦对了， 你想折腾Hadoop，Linux的基础必须得学，至少Shell得用的溜溜的，不然hadoop你怎么装… cd / mv/ cp/ mkdir / chmod / ls / ssh / touch / vim / awk / sed / ifconfig / du / df / 这乱七八糟一大堆命令，一个一个学了吧， linux的各种概念，文件、管道、bash、配置，你得整懂吧？学吧！趁着研究生时间多，短投资大回报！ 作为研究生，建议你多看一看机器学习，说到底大数据还是一个“基础设施”，但要创造价值，还得靠机器学习（数据挖掘的意思就是 机器学习 on 大数据）。]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HBase学习笔记]]></title>
    <url>%2Fblog%2Fd281d21f.html</url>
    <content type="text"><![CDATA[HBase的表、行、列和单元格的概念：最基本的单位是列（column），一列或多列形成一行（row），并由唯一的行键来确定存储。反过来，一个表（Table）中有若干行，其中每列可能有多个版本，在每一个单元格（cell）中存储了不同的值。 除了每个单元格可以保留若干个版本的数据这一点，整个结构看起来像典型的数据库的描述。所有的行按照行键字典序进行排序存储。 一行由若干列组成，若干列又构成一个列族（column family），一个列族的所有列存储在同一个底层的存储文件里，这个存储文件叫做HFile。 所有的列和行的信息都会通过列族在表中定义，每一列的值或单元格的值都具有时间戳，默认由系统指定，也可以由用户显示设置。 数据存储模式：（Table,RowKey,Family,Column,Timestamp）→Value行数据的存取操作是原子的（atomic），可以读写任意数目的列，目前还不支持跨行事务和跨表事务。 自动分区HBase中扩展和负载均衡的基本单元称为region，region本质上是以行键排序的连续存储的区间。每一个region只能由一台region 服务器（region server）加载，每一台region服务器可以同时加载多个region。 存储APIAPI提供了建表、删表、增加列族和删除列族操作，同时还提供了修改表和列族数据的功能，如压缩和设置块大小等。 HBase可以通过add 方法对每一个put操作，这个只适合小数据量的操作，如果有个应用程序需要每秒存储上千行数据到HBase表中，这样的处理不合适。HBase的API配备一个客户端的写缓冲区（write buffer），缓冲区负责收集put操作，然后调用RPC操作一次性将put送往服务器。全局交换机控制着该缓冲区是否在使用，以下是其方法：12void setAutoFlush(boolean autoFlush)boolean isAutoFlush() 默认情况下，客户端缓冲区是禁用的。可以通过将自动刷写（autoflush）设置为false来激活缓冲区，调用如下： 1table.setAutoFlush(false) 激活客户端缓冲区之后，用户可以像单行put那样，将数据存储到HBase中，此时的操作不会产生RPC调用，因为存储的put实例保持在客户端进程的内存中。当需要强制把数据写到服务端时，可以调用另外一个API函数 flushCommits()方法将所有的修改传送到远程服务器。 HBase批量处理操作：事实上，许多基于列表的操作，如delete(List deletes)或者get(List gets)，都是基于batch()方法实现的。它们都是一些为了方便用户使用而保留的方法。如果你是新手，推荐使用batch()方法进行所有操作。 12void batch(List&lt;Row&gt; actions, Object[] results) throws IOException,InterruptedExceptionObject[] batch(List&lt;Row&gt; actions) throws IOException,InterruptedException batch()请求是同步的，会把操作直接发送到服务器端，这个过程没有什么延迟或其他中间操作。这与put()调用明显不同，所以请慎重挑选需要的方法。两种方法的共同点：get、put、delete都支持。如果只选时出现问题，客户端将抛出异常并报告问题。它们都不使用客户端写缓冲区。]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>HBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python学习笔记-操作PostgreSQL]]></title>
    <url>%2Fblog%2F8175fd49.html</url>
    <content type="text"><![CDATA[python操作数据库PostgreSQL 1.简述 python可以操作多种数据库，诸如SQLite、MySql、PostgreSQL等，这里不对所有的数据库操作方法进行赘述，只针对目前项目中用到的PostgreSQL做一下简单介绍，主要包括python操作数据库插件的选择、安装、简单使用方法、测试连接数据库成功。2.数据库操作插件的选择 PostgreSQL至少有三个python接口程序可以实现访问，包括PsyCopg、PyPgSQL、PyGreSQL(PoPy已经整合在PyGreSQL中)，三个接口程序各有利弊，需要根据实践选择最适合项目的方式。 推荐使用PsyCopg，对python开发框架的兼容性都很好，本文中我们只讨论这个插件。3.PsyCopg的下载 官网下载psycopg2-2.5.1.tar.gz：http://initd.org/psycopg/ 4.PsyCopg的安装 直接exe，根据提示安装即可.]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习概念]]></title>
    <url>%2Fblog%2Fd4eed376.html</url>
    <content type="text"><![CDATA[定义：对于某类任务 T 和性能度量P，如果一个计算机程序在T 上以P 衡量的性能随着经验E 而自我完善，那么我们称这个计算机程序在从经验E 学习。 学习系统设计，包括：1.要学习的知识的确切类型2.对于这个目标知识的表示3.一种学习机制 目标函数的选择是一个关键的设计问题。 机器学习的一些观点和问题： 在机器学习方面，一个有效的观点是机器学习问题经常归结于搜索问题，即对非常大的假设空间进行搜索，以确定最佳拟合观察到的数据和学习器已有知识的假设。例如，考虑一下上面的西洋跳棋学习程序输出的假设空间。这个假设空间包含所有可由权w0 到w6 的不同值的评估函数。于是学习器的任务就是搜索这个大的空间，寻找与训练数据最佳拟合的假设。针对拟合权值的LMS 算法通过迭代调整权值实现了这个目的，每当假设的评估函数预测出一个与训练数据有偏差的值时就对每个权值进行校正。当学习器考虑的假设表示定义了一个连续的参数化的潜在假设空间时，这个算法很有效。 机器学习方面普遍问题： 从特定的训练数据学习一般的目标函数存在什么样的算法？如果提供了充足的训练数据，什么样的条件下会使特定的算法收敛到期望的函数？那个算法对哪些问题和表述的性能最好？ 多少训练数据是充足的？怎样找到学习到的假设的置信度与训练数据的数量及提供给学习器的假设空间特性之间的一般关系？ 学习器拥有的先验知识是怎样引导从样例进行泛化的过程的？当先验知识仅仅是近似正确时，它们会有帮助吗？ 对于选择有用的后续训练经验，什么样的策略最好？这个策略的选择会怎样影响学习问题的复杂性？ 怎样把学习任务简化为一个或多个函数逼近问题？换一种方式，系统该试图学习哪些函数？这个过程本身能自动化吗？ 学习器怎样自动地改变表示法来提高表示和学习目标函数的能力？]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[贝叶斯法则]]></title>
    <url>%2Fblog%2F1808a5ac.html</url>
    <content type="text"><![CDATA[什么是贝叶斯法则？ 贝叶斯的统计学中有一个基本的工具叫贝叶斯法则、也称为贝叶斯公式， 尽管它是一个数学公式，但其原理毋需数字也可明了。如果你看到一个人总是做一些好事，则那个人多半会是一个好人。这就是说，当你不能准确知悉一个事物的本质时，你可以依靠与事物特定本质相关的事件出现的多少去判断其本质属性的概率。 用数学语言表达就是：支持某项属性的事件发生得愈多，则该属性成立的可能性就愈大。 贝叶斯法则又被称为贝叶斯定理、贝叶斯规则是概率统计中的应用所观察到的现象对有关概率分布的主观判断（即先验概率）进行修正的标准方法。 所谓贝叶斯法则，是指当分析样本大到接近总体数时，样本中事件发生的概率将接近于总体中事件发生的概率。 但行为经济学家发现，人们在决策过程中往往并不遵循贝叶斯规律，而是给予最近发生的事件和最新的经验以更多的权值，在决策和做出判断时过分看重近期的事件。面对复杂而笼统的问题，人们往往走捷径，依据可能性而非根据概率来决策。这种对经典模型的系统性偏离称为“偏差”。由于心理偏差的存在，投资者在决策判断时并非绝对理性，会行为偏差，进而影响资本市场上价格的变动。但长期以来，由于缺乏有力的替代工具，经济学家不得不在分析中坚持贝叶斯法则。 贝叶斯法则的定理 通常，事件A在事件B(发生)的条件下的概率，与事件B在事件A的条件下的概率是不一样的；然而，这两者是有确定的关系,贝叶斯法则就是这种关系的陈述。 作为一个规范的原理，贝叶斯法则对于所有概率的解释是有效的；然而，频率主义者和贝叶斯主义者对于在应用中概率如何被赋值有着不同的看法：频率主义者根据随机事件发生的频率，或者总体样本里面的个数来赋值概率；贝叶斯主义者要根据未知的命题来赋值概率。一个结果就是，贝叶斯主义者有更多的机会使用贝叶斯法则。 贝叶斯法则是关于随机事件A和B的条件概率和边缘概率的。 其中L(A|B)是在B发生的情况下A发生的可能性。 在贝叶斯法则中，每个名词都有约定俗成的名称： Pr(A)是A的先验概率或边缘概率。之所以称为”先验”是因为它不考虑任何B方面的因素。 Pr(A|B)是已知B发生后A的条件概率，也由于得自B的取值而被称作A的后验概率。 Pr(B|A)是已知A发生后B的条件概率，也由于得自A的取值而被称作B的后验概率。 Pr(B)是B的先验概率或边缘概率，也作标准化常量（normalized constant）。 按这些术语，Bayes法则可表述为： 后验概率 = (相似度 * 先验概率)/标准化常量 也就是说，后验概率与先验概率和相似度的乘积成正比。 另外，比例Pr(B|A)/Pr(B)也有时被称作标准相似度（standardised likelihood），Bayes法则可表述为： 后验概率 = 标准相似度 * 先验概率]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>贝叶斯法则</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[挣值常用计算公式]]></title>
    <url>%2Fblog%2F7df9d698.html</url>
    <content type="text"><![CDATA[挣值最常用的计算公式以下公式用于测量项目绩效： SV=EV-PVSV—进度偏差，用挣值减去计划价值，若得数为负，则表明进度落后于计划进度。 CV=EV-ACCV—成本偏差，用挣值减去实际成本，若得数为负，则表明项目已经出现了成本超支。 SPI=EV/PVSPI—进度绩效指数，挣值除以计划价值，若得数小于1，则表明进度落后于计划进度。 CPI=EV/ACCPI—成本绩效指数，挣值除以实际成本，若得数小于1，则表明项目已经出现了成本超支。 以下公式用于预测： ETC—完工尚需估计，即完成剩余工作所需的估算费用EAC—完工时估算，即完成所有计划工作所需的估算BAC—项目总预算，BAC=完工时的PV总和 ETC=BAC-EV，基于非典型偏差计算ETC此时当前偏差被看作是非典型的，并且项目团队预期在以后将不会发生类似偏差。 ETC=(BAC-EV)/CPI，基于典型偏差计算ETC此时当前偏差被看作是典型的，当前偏差可看作未来偏差的典型代表时。 EAC=AC+ETC，使用新估算计算EAC，即原先估算假设有根本性缺陷或由于条件变化假设条件不再成立时重新估算的ETC。 EAC=AC+BAC-EV，使用剩余预算计算EAC，偏差非典型时使用 EAC=AC+(BAC-EV)/CPI，使用CPI计算EAC，偏差典型时使用 EAC=BAC/CPI]]></content>
      <categories>
        <category>项目管理</category>
      </categories>
      <tags>
        <tag>项目管理</tag>
        <tag>项目挣值</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[项目挣值管理]]></title>
    <url>%2Fblog%2Fd5d99735.html</url>
    <content type="text"><![CDATA[专注于项目管理也有一段时间了，从最开始就接触到挣值管理，然每每看是都看懂了，但为用心去记，以至于再次提到挣值这个概念时，我不得不再去回顾原来的知识。因此，认真做下笔记，帮助自己更深的去理解挣值管理。 1、什么是挣值方法？ 挣值法又称为赢得值法或偏差分析法。挣值分析法是在工程项目实施中使用较多的一种方法，是对项目进度和费用进行综合控制的一种有效方法。 挣值法的价值在于将项目的进度和费用综合度量，从而能准确描述项目的进展状态。挣值法的另一个重要优点是可以预测项目可能发生的工期滞后量和费用超支量，从而及时采取纠正措施，为项目管理和控制提供了有效手段。 2、挣得值方法的基本参数完成时预算（BAC），该项工作的总预算。 计划工作量的预算费用 （BCWS或PV —— Budgeted Cost for Work Scheduled）。 BCWS是指项目实施过程中某阶段计划要求完成的工作量所需的预算费用。BCWS主要是反映进度计划应当完成的工作量（用费用表示）。计算公式为： BCWS = 计划工作量 × 预算定额。 BCWS是与时间相联系的，当考虑资金累计曲线时，是在项目预算S曲线上的某一点的值。当考虑某一项作业或某一时间段时，例如某一月份，BCWS是该作业或该月份包含作业的预算费用。 已完成工作量的实际费用（ACWP或AC —— Actual Cost for Work Performed）。 ACWP是指项目实施过程中某阶段实际完成的工作量所消耗的工时（或费用）。ACWP主要反映项目执行的实际消耗指标。 已完工作量的预算成本（BCWP 或EV —— Budgeted Cost for Work Performed），或称挣值、盈得值和挣得值。 BCWP是指项目实施过程中某阶段按实际完成工作量及按预算定额计算出来的费用，即挣得值（Earned Value）。BCWP的实质内容是将已完成的工作量用预算费用来度量。BCWP的计算公式为： BCWP = 已完工作量 × 预算定额。 3、挣得值方法的四个评价指标 成本偏差（CV —— Cost Variance）：CV是指检查期间BCWP与ACWP之间的差异，计算公式为： CV = BCWP - ACWP 当CV为负值时表示执行效果不佳，即实际消费费用超过预算值即超支。反之当CV为正值时表示实际消耗费用低于预算值，表示有节余或效率高。若CV=0,表示项目按计划执行。 进度偏差（SV —— Schedule Variance）：SV是指检查日期BCWP与BCWS之间的差异。其计算公式为： SV = BCWP - BCWS 当SV为正值时表示进度提前，SV为负值表示进度延误。若SV=0，表明进度按计划执行。 成本绩效指数（CPI —— Cost Performed Index）：CPI是指挣得值与实际成本之比。其计算公式为： CPI = BCWP／ACWP 当 CPI＞1表示低于预算，CPI＜1表示超出预算，CPI＝1表示实际费用与预算费用吻合。若CPI=1,表明项目费用按计划进行。 进度绩效指数（SPI —— Schedule Performed Index）：SPI是指项目挣得值与计划值之比，其计算公式为： SPI = BCWP／BCWS 当 SPI＞1表示进度提前，SPI＜1表示进度延误，SPI＝1表示实际进度等于计划进度。 完成时预计值（估计完成全部工作所需的成本）的计算公式如下： EAC = BAC / CPI，或 EAC= AC -（BAC - EV）/ CPI 4、挣值法评价曲线 挣值法评价曲线如下图所示，下图的横坐标表示时间，纵坐标则表示费用。BCWS曲线为计划工作量的预算费用曲线，表示项目投入的费用随时间的推移在不断积累，直至项目结束达到它的最大值，所以曲线呈S形状，也称为S曲线。ACWP已完成工作量的实际费用，同样是进度的时间参数，随项目推进而不断增加的，也是呈S形的曲线。利用挣值法评价曲线可进行费用进度评价，图中所示的项目，CV&lt;0，SV&lt;0，这表示项目执行效果不佳，即费用超支，进度延误，应采取相应的补救措施。]]></content>
      <categories>
        <category>项目管理</category>
      </categories>
      <tags>
        <tag>项目挣值</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[敏捷工作件：完成标准（Definition of Done）]]></title>
    <url>%2Fblog%2F4b4bc643.html</url>
    <content type="text"><![CDATA[什么是完成标准？ 基于“随时可向用户发布”的目标制定衡量团队工作是否已完成的标准，由团队和PM/Scrum Master形成共识。 完成标准的好处 共同协商的完成标准是团队的自我承诺，团队会更认真； 用于准确评估团队工作进展； 清晰和明确的完成标准保证了每次迭代是高质量的。 完成标准的关键要点 团队自协商： 团队根据项目实际情况定义完成标准，并严格遵守； 有层次： 一般分为三个层次，Story级别，迭代级和发布级，每个级别都有各自完成标准。 完成标准的样例： Story完成标准样例：1.代码合入主干2.代码100%检视3.代码符合规范4.持续集成无错误5.通过验收测试 迭代完成标准样例：1.所有Story完成2.所有缺陷解决3.系统测试用例100%通过4.通过迭代验收 发布完成标准样例：1.通过回归测试2.通过性能测试3.更新配套资料]]></content>
      <categories>
        <category>项目管理</category>
      </categories>
      <tags>
        <tag>敏捷</tag>
        <tag>Scrum</tag>
        <tag>敏捷项目管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Prince 2 学习笔记]]></title>
    <url>%2Fblog%2Fd5b178fa.html</url>
    <content type="text"><![CDATA[为什么项目交付如此困难？ 项目是一个临时的组织，目的在于根据Business Case交付一个/多个商业产品。 变化性 临时性：项目总是有开始日期和结束日期的，因此项目是具有临时性。 跨功能组织性：项目在团队组织上、项目交付的业务上，对会存在跨组织、跨业务。 唯一性：每个项目都是唯一的。同一个组织也许承担许多相似的项目 ，项目的类型、活动也一致。但是每个项目都有自己的独特性：不同的团队、不同的客户、不同的工作地点，不同的客户需求与期望、……，所有的因素决定了项目的独特性。 不确定性：每个项目交付过程中，都会遇到不可变因素，这些不可变因素就是存在着的各种风险，将会对项目的发展产生影响，因此项目交付过程中存在一定的不确定性。项目交付过程中需要识别威胁和计划（项目风险管理）。 为什么我们需要项目管理方法论？ 项目管理是通过制定计划、委托授权、执行和监控项目多方面，，以期达到项目期望的目标（包括时间、成本、质量、范围、收益和风险）。 ###Prince 2项目管理7要素： Business Case（商业机会） Organization（项目组织） Quality（质量管理） Plans（计划管理） Risk（风险管理） Change（变更管理） Progress（过程管理）]]></content>
      <categories>
        <category>项目管理</category>
      </categories>
      <tags>
        <tag>Prince 2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于KPI绩效考核]]></title>
    <url>%2Fblog%2Fa5ee2b24.html</url>
    <content type="text"><![CDATA[组织通过绩效考核来牵引部门/个人工作，绩效考核指标设计时，需要考虑KPI考核方案的牵引方向要与该部门/个人的业务或工作目标一致，这样才能起到积极的作用，不要为了考核而考核，从而失去了考核的初衷。 KPI方案可从四个维度来设计：财务、客户满意度、运营、学习与成长。KPI指标设计的时候，要考虑指标的可度量性、合理性。不要天马行空的设计某些指标，最后不能度量，起不到量化考核的作用，从而无法客观给予评价。 KPI子标字典一般包括： 指标名称 设置目的 指标定义 计算公式 数据来源 测量对象 统计部门/统计人 计量单位 统计周期 说明 指标接口人（解释责任人、测评数据提供人） 指标成熟度（L4-IT级、L3-应用级、L2-数据级、L1-定义级 中选一）]]></content>
      <categories>
        <category>企业管理</category>
      </categories>
      <tags>
        <tag>KPI</tag>
        <tag>绩效管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[交付项目管理——6大阶段]]></title>
    <url>%2Fblog%2F59f85b73.html</url>
    <content type="text"><![CDATA[交付项目管理，如：系统集成交付项目、软件实施项目、工程交付项目等，都可划分为6大阶段进行管理，包括：分析项目阶段、规划项目阶段、建立项目阶段、实施项目阶段、移交项目阶段和关闭项目阶段。 分析项目阶段：项目开始之前的准备阶段，从财务、技术、资源准备和组织的角度分析机会点和评估技术上、商业上的可交付行。 关键活动：项目交付可行性分析和评估 输入：任务委托书，售前交流纪要等；分析阶段项目关键输出：项目交付可行性报告和结论 规划项目阶段:在项目投标阶段，早期介入项目，负责获取项目售前信息、规划项目工作，并开发项目交付方案，集成项目方案、服务交付方案、供应链管理、采购管理方案等，支持项目招标解决方案和合同谈判。 规划项目阶段的主要活动：1、识别范围2、指定交付策略3、准备初始计划4、分析项目风险（包括机会风险）5、准备资源和供应需求计划（如涉及供应、采购等，需要考虑供应需求计划）6、制定交付方案 输入：任务委托书、项目交付可行性分析报告输出：项目范围、交付策略、初始项目计划、资源需求计划、供应需求计划（有供需的项目需要考虑）、风险管理计划、交付方案 建立项目阶段：项目合同签署后，召开项目合同交底会，组建项目团队。安排项目交付解决方案的详细设计、审查交付方案、项目的总体规划、预算等。 建立项目阶段的主要活动：1、建立项目组织（明确项目关键角色，落实职责）2、合同交底和可交付行评估；3、识别干系人和制定沟通计划4、制定项目计划（主计划、资源需求计划、质量管理计划、风险管理计划、版本发布计划、供货子计划、客户及三方配合子计划）5、确定项目目标6、项目kick off（客户方&amp;自己方） 输入：合同/PO注册信息、低阶服务交付方案、投标文件等；输出：项目任命文件和授权书、干系人管理计划、项目沟通计划、合同交底会议纪要、项目目标、DR1报告 实施项目阶段主要活动包括：1、监控项目进度2、管理项目经营3、管理项目Govermance和客户满意度4、管理项目变更5、管理项目风险和问题6、管理项目质量（及EHS）7、管理项目验收 输出：项目状态报告（进度报告、经营报告、风险/问题报告等）、DR2评审结论、验收证书 移交项目阶段：通过验收，确保客户和相关接收项目成果是否正式受理，并把相关职责移交给客户。 关键活动：管理移交输入：移交双方的一致结论输出：移交证明、DR3评审结论 关闭项目阶段：确保项目解决所有重大问题（或相关对策已确认转移），进行最终核算，VOC评价和改进，释放相关的资源，并把项目的经验和教训总结和归档。关键活动：1、启动项目关闭2、项目总结和确认决算3、关闭活动确认 输入：关闭checklist、项目决算报告、采购PO清理报告；输出：checklist自检结果、DR4评审报告、项目决算报告]]></content>
      <categories>
        <category>项目管理</category>
      </categories>
      <tags>
        <tag>项目管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[项目知识管理]]></title>
    <url>%2Fblog%2Fa97c6466.html</url>
    <content type="text"><![CDATA[项目知识管理框架项目知识管理包括：做前学、做中学、做后学三步法，并通过分享互助平台（知识管理平台、知识大讲坛、同行学习兴趣小组等）实现知识的共享与交流，并在企业内不断积累知识资产（知识地图、工具箱、指导书/模板、参考案例、经验教训、社区讨论、原始案例等） 做前学：1、登舰：提前参与到项目中实践学习，亲身实战受训2、团队预集成：统一目标、统一运作、统一计划、三方视图等3、同行协助：与同行专家交流，相互学习优秀的经验 做中学AAR（事后回顾）]]></content>
      <categories>
        <category>项目管理</category>
      </categories>
      <tags>
        <tag>项目知识管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis学习笔记--list类型及操作]]></title>
    <url>%2Fblog%2F65514bcf.html</url>
    <content type="text"><![CDATA[list 是一个链表结构，主要功能是push、pop、获取一个范围的所有值等等，操作中key 理解为链表的名字。 Redis 的list 类型其实就是一个每个子元素都是string 类型的双向链表。链表的最大长度是(2的32 次方)。我们可以通过push,pop 操作从链表的头部或者尾部添加删除元素。这使得list既可以用作栈，也可以用作队列。 有意思的是list 的pop 操作还有阻塞版本的，当我们[lr]pop 一个list 对象时，如果list 是空，或者不存在，会立即返回nil。但是阻塞版本的b[lr]pop 可以则可以阻塞，当然可以加超时时间，超时后也会返回nil。为什么要阻塞版本的pop 呢，主要是为了避免轮询。举个简单的例子如果我们用list 来实现一个工作队列。执行任务的thread 可以调用阻塞版本的pop 去获取任务这样就可以避免轮询去检查是否有任务存在。当任务来时候工作线程可以立即返回，也可以避免轮询带来的延迟。说了这么多，接下来看一下实际操作的方法吧： lpush在key 对应list 的头部添加字符串元素12345678redis 127.0.0.1:6379&gt; lpush mylist &quot;world&quot;(integer) 1redis 127.0.0.1:6379&gt; lpush mylist &quot;hello&quot;(integer) 2redis 127.0.0.1:6379&gt; lrange mylist 0 -11) &quot;hello&quot;2) &quot;world&quot;redis 127.0.0.1:6379&gt; 在此处我们先插入了一个world，然后在world 的头部插入了一个hello。其中lrange 是用于取mylist 的内容。 rpush在key 对应list 的尾部添加字符串元素12345678redis 127.0.0.1:6379&gt; rpush mylist2 &quot;hello&quot;(integer) 1redis 127.0.0.1:6379&gt; rpush mylist2 &quot;world&quot;(integer) 2redis 127.0.0.1:6379&gt; lrange mylist2 0 -11) &quot;hello&quot;2) &quot;world&quot;redis 127.0.0.1:6379&gt; linsert在key 对应list 的特定位置之前或之后添加字符串元素1234567891011redis 127.0.0.1:6379&gt; rpush mylist3 &quot;hello&quot;(integer) 1redis 127.0.0.1:6379&gt; rpush mylist3 &quot;world&quot;(integer) 2redis 127.0.0.1:6379&gt; linsert mylist3 before &quot;world&quot; &quot;there&quot;(integer) 3redis 127.0.0.1:6379&gt; lrange mylist3 0 -11) &quot;hello&quot;2) &quot;there&quot;3) &quot;world&quot;redis 127.0.0.1:6379&gt; 在此处我们先插入了一个hello，然后在hello 的尾部插入了一个world，然后又在world 的前面插入了there。 lset设置list中下表的元素值（下标从0开始）123456789101112131415redis 127.0.0.1:6379&gt; rpush mylist4 &quot;one&quot;(integer) 1redis 127.0.0.1:6379&gt; rpush mylist4 &quot;two&quot;(integer) 2redis 127.0.0.1:6379&gt; rpush mylist4 &quot;three&quot;(integer) 3redis 127.0.0.1:6379&gt; lset mylist4 0 &quot;four&quot;OKredis 127.0.0.1:6379&gt; lset mylist4 -2 &quot;five&quot;OKredis 127.0.0.1:6379&gt; lrange mylist4 0 -11) &quot;four&quot;2) &quot;five&quot;3) &quot;three&quot;redis 127.0.0.1:6379&gt; lrem从key对应list中删除count个和value相同的元素。count&gt;0时，按从头到尾的顺序删除，具体如下：1234567891011121314redis 127.0.0.1:6379&gt; rpush mylist5 &quot;hello&quot;(integer) 1redis 127.0.0.1:6379&gt; rpush mylist5 &quot;hello&quot;(integer) 2redis 127.0.0.1:6379&gt; rpush mylist5 &quot;foo&quot;(integer) 3redis 127.0.0.1:6379&gt; rpush mylist5 &quot;hello&quot;(integer) 4redis 127.0.0.1:6379&gt; lrem mylist5 2 &quot;hello&quot;(integer) 2redis 127.0.0.1:6379&gt; lrange mylist5 0 -11) &quot;foo&quot;2) &quot;hello&quot;redis 127.0.0.1:6379&gt; lrangelrange key start stop：返回存储在 key 的列表里指定范围内的元素。 start 和 end 偏移量都是基于0的下标，即list的第一个元素下标是0（list的表头），第二个元素下标是1，以此类推。 偏移量也可以是负数，表示偏移量是从list尾部开始计数。 例如， -1 表示列表的最后一个元素，-2 是倒数第二个，以此类推。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950redis&gt; RPUSH mylist &quot;one&quot;(integer) 1redis&gt; RPUSH mylist &quot;two&quot;(integer) 2redis&gt; RPUSH mylist &quot;three&quot;(integer) 3redis&gt; LRANGE mylist 0 01) &quot;one&quot;redis&gt; LRANGE mylist -3 21) &quot;one&quot;2) &quot;two&quot;3) &quot;three&quot;redis&gt; LRANGE mylist -100 1001) &quot;one&quot;2) &quot;two&quot;3) &quot;three&quot;redis&gt; LRANGE mylist 5 10(empty list or set)redis&gt; #count&lt;0 时，按从尾到头的顺序删除，具体如下:redis 127.0.0.1:6379&gt; rpush mylist6 &quot;hello&quot;(integer) 1redis 127.0.0.1:6379&gt; rpush mylist6 &quot;hello&quot;(integer) 2redis 127.0.0.1:6379&gt; rpush mylist6 &quot;foo&quot;(integer) 3redis 127.0.0.1:6379&gt; rpush mylist6 &quot;hello&quot;(integer) 4redis 127.0.0.1:6379&gt; lrem mylist6 -2 &quot;hello&quot;(integer) 2redis 127.0.0.1:6379&gt; lrange mylist6 0 -11) &quot;hello&quot;2) &quot;foo&quot;redis 127.0.0.1:6379&gt;#count=0 时，删除全部，具体如下:redis 127.0.0.1:6379&gt; rpush mylist7 &quot;hello&quot;(integer) 1redis 127.0.0.1:6379&gt; rpush mylist7 &quot;hello&quot;(integer) 2redis 127.0.0.1:6379&gt; rpush mylist7 &quot;foo&quot;(integer) 3redis 127.0.0.1:6379&gt; rpush mylist7 &quot;hello&quot;(integer) 4redis 127.0.0.1:6379&gt; lrem mylist7 0 &quot;hello&quot;(integer) 3redis 127.0.0.1:6379&gt; lrange mylist7 0 -11) &quot;foo&quot;redis 127.0.0.1:6379&gt; ltrim保留指定key的值范围内的数据(不在指定范围内的数据，将被删除)123456789101112131415redis 127.0.0.1:6379&gt; rpush mylist8 &quot;one&quot;(integer) 1redis 127.0.0.1:6379&gt; rpush mylist8 &quot;two&quot;(integer) 2redis 127.0.0.1:6379&gt; rpush mylist8 &quot;three&quot;(integer) 3redis 127.0.0.1:6379&gt; rpush mylist8 &quot;four&quot;(integer) 4redis 127.0.0.1:6379&gt; ltrim mylist8 1 -1OKredis 127.0.0.1:6379&gt; lrange mylist8 0 -11) &quot;two&quot;2) &quot;three&quot;3) &quot;four&quot;redis 127.0.0.1:6379&gt; lpop从list的头部删除元素，并返回删除元素。12345678redis 127.0.0.1:6379&gt; lrange mylist 0 -11) &quot;hello&quot;2) &quot;world&quot;redis 127.0.0.1:6379&gt; lpop mylist&quot;hello&quot;redis 127.0.0.1:6379&gt; lrange mylist 0 -11) &quot;world&quot;redis 127.0.0.1:6379&gt; rpop从list的尾部删除元素，并返回删除元素12345678redis 127.0.0.1:6379&gt; lrange mylist2 0 -11) &quot;hello&quot;2) &quot;world&quot;redis 127.0.0.1:6379&gt; rpop mylist2&quot;world&quot;redis 127.0.0.1:6379&gt; lrange mylist2 0 -11) &quot;hello&quot;redis 127.0.0.1:6379&gt; rpoplpush从第一个list 的尾部移除元素，并添加到第二个list 的头部，最后返回被移除的元素值，整个操作是原子的，如果第一个list 是空或者不存在返回nil。12345678910111213141516171819redis 127.0.0.1:6379&gt; lrange mylist5 0 -11) &quot;three&quot;2) &quot;foo&quot;3) &quot;hello&quot;redis 127.0.0.1:6379&gt; lrange mylist6 0 -11) &quot;hello&quot;2) &quot;foo&quot;redis 127.0.0.1:6379&gt; rpoplpush mylist5 mylist6&quot;hello&quot;redis 127.0.0.1:6379&gt; lrange mylist5 0 -11) &quot;three&quot;2) &quot;foo&quot;redis 127.0.0.1:6379&gt; lrange mylist6 0 -11) &quot;hello&quot;2) &quot;hello&quot;3) &quot;foo&quot;redis 127.0.0.1:6379&gt; lindex返回名称为key的list中index位置的元素。12345678redis 127.0.0.1:6379&gt; lrange mylist5 0 -11) &quot;three&quot;2) &quot;foo&quot;redis 127.0.0.1:6379&gt; lindex mylist5 0&quot;three&quot;redis 127.0.0.1:6379&gt; lindex mylist5 1&quot;foo&quot;redis 127.0.0.1:6379&gt; llen返回key 对应list 的长度123redis 127.0.0.1:6379&gt; llen mylist5(integer) 2redis 127.0.0.1:6379&gt;]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis学习笔记--hashes类型及操作]]></title>
    <url>%2Fblog%2F11adac6e.html</url>
    <content type="text"><![CDATA[Redis hash是一个string类型的field和value的映射表。它的添加、删除操作都是O(1)（平均）。hash特别适合用于存储对象。相较于将对象的每个字段存成单个string类型。将一个对象存储在hash类型中会占用更少的内存，并且可以更方便的存取整个对象。 hset设置hash field 为指定值，如果key 不存在，则先创建。123redis 127.0.0.1:6379&gt; hset myhash field1 Hello(integer) 1redis 127.0.0.1:6379&gt; hsetnx设置hash field 为指定值，如果key 不存在，则先创建。如果field 已经存在，返回0，nx 是not exist 的意思。12345redis 127.0.0.1:6379&gt; hsetnx myhash field &quot;Hello&quot;(integer) 1redis 127.0.0.1:6379&gt; hsetnx myhash field &quot;Hello&quot;(integer) 0redis 127.0.0.1:6379&gt; 第一次执行是成功的，但第二次执行相同的命令失败，原因是field 已经存在了。 hmset同时设置hash的多个field。123redis 127.0.0.1:6379&gt; hmset myhash field1 Hello field2 WorldOKredis 127.0.0.1:6379&gt; hget获取指定的hash field.1234567redis 127.0.0.1:6379&gt; hget myhash field1&quot;Hello&quot;redis 127.0.0.1:6379&gt; hget myhash field2&quot;World&quot;redis 127.0.0.1:6379&gt; hget myhash field3 #由于数据库没有field3，所以取到的是一个空值nil(nil)redis 127.0.0.1:6379&gt; hmget获取全部指定的hash filed。12345redis 127.0.0.1:6379&gt; hmget myhash field1 field2 field31) &quot;Hello&quot;2) &quot;World&quot;3) (nil)redis 127.0.0.1:6379&gt; hincrby指定的hash filed加上给定值。123456789redis 127.0.0.1:6379&gt; hset myhash field3 20(integer) 1redis 127.0.0.1:6379&gt; hget myhash field3&quot;20&quot;redis 127.0.0.1:6379&gt; hincrby myhash field3 -8(integer) 12redis 127.0.0.1:6379&gt; hget myhash field3&quot;12&quot;redis 127.0.0.1:6379&gt; hexists测试指定的field是否存在。12345redis 127.0.0.1:6379&gt; hexists myhash field1(integer) 1redis 127.0.0.1:6379&gt; hexists myhash field9(integer) 0redis 127.0.0.1:6379&gt; hlen返回指定的hash的field数量。123redis 127.0.0.1:6379&gt; hlen myhash(integer) 4redis 127.0.0.1:6379&gt; hdel删除指定hash的field，删除成功返回1，否则返回0。1234567redis 127.0.0.1:6379&gt; hlen myhash(integer) 4redis 127.0.0.1:6379&gt; hdel myhash field1(integer) 1redis 127.0.0.1:6379&gt; hlen myhash(integer) 3redis 127.0.0.1:6379&gt; hvals返回hash的所有value。12345redis 127.0.0.1:6379&gt; hvals myhash1) &quot;World&quot;2) &quot;Hello&quot;3) &quot;12&quot;redis 127.0.0.1:6379&gt; 说明这个hash 中有3 个field hgetall获取某个hash中全部的filed及value。12345678redis 127.0.0.1:6379&gt; hgetall myhash1) &quot;field2&quot;2) &quot;World&quot;3) &quot;field&quot;4) &quot;Hello&quot;5) &quot;field3&quot;6) &quot;12&quot;redis 127.0.0.1:6379&gt; 一下子将myhash 中所有的field 及对应的value 都取出来了。]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis学习笔记--strings类型及操作1]]></title>
    <url>%2Fblog%2F9b68d42a.html</url>
    <content type="text"><![CDATA[set设置key 对应的值为string 类型的value。例如我们添加一个name= HongWan 的键值对，可以这样做:123redis 127.0.0.1:6379&gt; set name HongWanOKredis 127.0.0.1:6379&gt; setnx设置key 对应的值为string 类型的value。如果key 已经存在，返回0，nx 是not exist 的意思。例如我们添加一个name= HongWan_new 的键值对，可以这样做:1234567redis 127.0.0.1:6379&gt; get name&quot;HongWan&quot;redis 127.0.0.1:6379&gt; setnx name HongWan_new(integer) 0redis 127.0.0.1:6379&gt; get name&quot;HongWan&quot;redis 127.0.0.1:6379&gt; setex设置key 对应的值为string 类型的value，并指定此键值对应的有效期。例如我们添加一个haircolor= red 的键值对，并指定它的有效期是10 秒，可以这样做:1234567redis 127.0.0.1:6379&gt; setex haircolor 10 redOKredis 127.0.0.1:6379&gt; get haircolor&quot;red&quot;redis 127.0.0.1:6379&gt; get haircolor(nil)redis 127.0.0.1:6379&gt; 可见由于最后一次的调用是10 秒以后了，所以取不到haicolor 这个键对应的值。 setrange设置指定key 的value 值的子字符串。例如我们希望将HongWan 的126 邮箱替换为gmail 邮箱，那么我们可以这样做:1234567redis 127.0.0.1:6379&gt; get name&quot;HongWan@126.com&quot;redis 127.0.0.1:6379&gt; setrange name 8 gmail.com(integer) 17redis 127.0.0.1:6379&gt; get name&quot;HongWan@gmail.com&quot;redis 127.0.0.1:6379&gt; 其中的8 是指从下标为8（包含8）的字符开始替换 mset一次设置多个key 的值，成功返回ok 表示所有的值都设置了，失败返回0 表示没有任何值被设置。1234567redis 127.0.0.1:6379&gt; mset key1 HongWan1 key2 HongWan2OKredis 127.0.0.1:6379&gt; get key1&quot;HongWan1&quot;redis 127.0.0.1:6379&gt; get key2&quot;HongWan2&quot;redis 127.0.0.1:6379&gt; msetnx一次设置多个key 的值，成功返回ok 表示所有的值都设置了，失败返回0 表示没有任何值被设置，但是不会覆盖已经存在的key。12345678910redis 127.0.0.1:6379&gt; get key1&quot;HongWan1&quot;redis 127.0.0.1:6379&gt; get key2&quot;HongWan2&quot;redis 127.0.0.1:6379&gt; msetnx key2 HongWan2_new key3 HongWan3(integer) 0redis 127.0.0.1:6379&gt; get key2&quot;HongWan2&quot;redis 127.0.0.1:6379&gt; get key3(nil) 可以看出如果这条命令返回0，那么里面操作都会回滚，都不会被执行。 get获取key 对应的string 值,如果key 不存在返回nil。例如我们获取一个库中存在的键name，可以很快得到它对应的value12345678redis 127.0.0.1:6379&gt; get name&quot;HongWan&quot;redis 127.0.0.1:6379&gt;//我们获取一个库中不存在的键name1，那么它会返回一个nil 以表时无此键值对redis 127.0.0.1:6379&gt; get name1 (nil)redis 127.0.0.1:6379&gt; getset设置key 的值，并返回key 的旧值。123456789101112redis 127.0.0.1:6379&gt; get name&quot;HongWan&quot;redis 127.0.0.1:6379&gt; getset name HongWan_new&quot;HongWan&quot;redis 127.0.0.1:6379&gt; get name&quot;HongWan_new&quot;redis 127.0.0.1:6379&gt;#接下来我们看一下如果key 不存的时候会什么样儿?redis 127.0.0.1:6379&gt; getset name1 aaa //可见，如果key 不存在，那么将返回nil(nil) redis 127.0.0.1:6379&gt; getrange获取指定key 的value 值的子字符串。具体样例如下:1234567891011121314151617redis 127.0.0.1:6379&gt; get name&quot;HongWan@126.com&quot;#字符串左面下标是从0 开始的redis 127.0.0.1:6379&gt; getrange name 0 6&quot;HongWan&quot;redis 127.0.0.1:6379&gt;#字符串右面下标是从-1 开始的redis 127.0.0.1:6379&gt; getrange name -7 -1&quot;126.com&quot;redis 127.0.0.1:6379&gt;#当下标超出字符串长度时，将默认为是同方向的最大下标redis 127.0.0.1:6379&gt; getrange name 7 100&quot;@126.com&quot;redis 127.0.0.1:6379&gt; mget一次获取多个key 的值，如果对应key 不存在，则对应返回nil。具体样例如下:12345redis 127.0.0.1:6379&gt; mget key1 key2 key31) &quot;HongWan1&quot;2) &quot;HongWan2&quot;3) (nil) //key3 由于没有这个键定义，所以返回nil。redis 127.0.0.1:6379&gt; incr对key 的值做加加操作,并返回新的值。注意incr 一个不是int 的value 会返回错误，incr 一个不存在的key，则设置key 为11234567redis 127.0.0.1:6379&gt; set age 20OKredis 127.0.0.1:6379&gt; incr age(integer) 21redis 127.0.0.1:6379&gt; get age&quot;21&quot;redis 127.0.0.1:6379&gt; incrby同incr 类似，加指定值 ，key 不存在时候会设置key，并认为原来的value 是 0123456789redis 127.0.0.1:6379&gt; get age&quot;21&quot;redis 127.0.0.1:6379&gt; incrby age 5(integer) 26redis 127.0.0.1:6379&gt; get name&quot;HongWan@gmail.com&quot;redis 127.0.0.1:6379&gt; get age&quot;26&quot;redis 127.0.0.1:6379&gt; decr对key 的值做的是减减操作，decr 一个不存在key，则设置key 为-11234567redis 127.0.0.1:6379&gt; get age&quot;26&quot;redis 127.0.0.1:6379&gt; decr age(integer) 25redis 127.0.0.1:6379&gt; get age&quot;25&quot;redis 127.0.0.1:6379&gt; decrby同decr，减指定值。12345678910111213141516redis 127.0.0.1:6379&gt; get age&quot;25&quot;redis 127.0.0.1:6379&gt; decrby age 5(integer) 20redis 127.0.0.1:6379&gt; get age&quot;20&quot;redis 127.0.0.1:6379&gt;#decrby 完全是为了可读性，我们完全可以通过incrby 一个负值来实现同样效果，反之一样。redis 127.0.0.1:6379&gt; get age&quot;20&quot;redis 127.0.0.1:6379&gt; incrby age -5(integer) 15redis 127.0.0.1:6379&gt; get age&quot;15&quot;redis 127.0.0.1:6379&gt; append给指定key 的字符串值追加value,返回新字符串值的长度。例如我们向name 的值追加一个@126.com 字符串，那么可以这样做:12345redis 127.0.0.1:6379&gt; append name @126.com(integer) 15redis 127.0.0.1:6379&gt; get name&quot;HongWan@126.com&quot;redis 127.0.0.1:6379&gt; strlen取指定key 的value 值的长度。123456789redis 127.0.0.1:6379&gt; get name&quot;HongWan_new&quot;redis 127.0.0.1:6379&gt; strlen name(integer) 11redis 127.0.0.1:6379&gt; get age&quot;15&quot;redis 127.0.0.1:6379&gt; strlen age(integer) 2redis 127.0.0.1:6379&gt;]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis学习笔记1]]></title>
    <url>%2Fblog%2Ffb55fc23.html</url>
    <content type="text"><![CDATA[####初识RedisRedis是一个开源使用ANSI C语言编写、支持网络、可基于内存亦可持久化的日志型、key-value数据库，并提供多种语言的API。从2010年3月15日起，Redis的开发工作由VMware主持。 ####数据类型作为Key-Value型数据库，Redis也提供键（key）和键值（Value）的映射关系。但是，除了常规的数值或字符串，Redis的键值还可以是以下形式之一： List （列表） Set（集合） Sorted sets （有序集合） Hashes （哈希表）键值的数据类型决定了该键值支持的操作。Redis支持诸如列表、集合或有序集合的交集、并集、查集等高级原子操作；同时，如果键值的类型是普通数字，Redis则提供自增等原子操作。 ####持久化通常，Redis将数据存储在内存中，或被配置为使用虚拟内存。通过两种方式可以实现数据持久化：使用截图的方式，将内存的数据不断写入磁盘；或使用类似MySQL的日志方式，记录每次更新的日志。前者性能较高，但是可能会引起一定程度的数据丢失；后者相反。 ####操作数据库1234567891011121314#插入数据&gt; set name wwlOK#查询数据&gt; get name&quot;wwl&quot;#删除键值&gt; del name#验证键值是否存在&gt; exists name(integer)0]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB学习笔记--管理]]></title>
    <url>%2Fblog%2F3ec2b753.html</url>
    <content type="text"><![CDATA[启动和停止MongoDB从命令行启动：12#启动MongoDB服务器，让其作为守护进程监听5586端口，并将所有输出记录到mongodb.log$ ./mongod --port 5586 --fork --logpath mongodb.log 停止MongoDB： 如果服务器是作为前台经常运行在终端的，就直接按“Ctrl-C”。否则，就用kill这种命令发出信号。如果mongod的PID是10014,就可以通过命令停止MongoDB： kill -2 10014 (SIGINT) 或者 kill 10014 (SIGINT) 另一种稳妥的方式就是使用 shutdown命令，例如：1234&gt; use adminswitched to db admin&gt; db.shutdownServer();server should be down...... 备份与恢复mongodump 和 mongorestore命名，对MongoDB进行备份与恢复。和大多数MongoDB的命令工具一样，mongodump也可以通过运行 –help选项查看所有选项 ：$ ./mongodump –help 备份与恢复命令：12345//如果你想备份数据库test$ ./mongodump -d test -o test/ //如果你想恢复数据库test$ ./mongorestore -d test -c user test/test/user.bson //利用mongorestore表恢复刚才利用mongodump备份的数据 虽然用mongodump和mongorestore能不停机备份，但是我们却失去了获取实时数据视图的能力。MongoDB的fsync命令能在MongoDB运行时复制数据目录还不会毁坏数据。 fsync命令会强制服务器将所有暖冲区写入磁盘。还可以选择上锁阻止对数据库的进一步写入，直到释放锁为止。写入锁是让fsync在备份时发挥作用的关键。下面的例子展示了如何在shell中操作，强制执行了fsync并获得了写入锁：1234567891011121314&gt; user adminswitched to db admin&gt; db.runCommand(&#123;&quot;fsync&quot;:1,&quot;lock&quot;:1&#125;);&#123; &quot;info&quot;:&quot;now locked against writes, use db.$cmd.sys.unlock.findOne() to unlock&quot;, &quot;ok&quot;:1&#125;#备份好，就要解锁&gt; db.$cmd.sys.unlock.findOne();&#123;&quot;ok&quot;:1,&quot;info&quot;:&quot;unlock requested&quot;&#125;&gt; db.currentOp(); #运行currentOp是为了确保已经解锁了。&#123;&quot;inprog&quot;:[]&#125; 有了fsync命令，就能够非常灵活地备份，不用停掉服务器，也不用牺牲备份的实时性。要付出的代价就是一些写入操作暂时被阻塞。 修复修复所有数据库最简单的方式就是加上 –repair: mongod –repair来启动服务器。修复数据库实际过程实际上非常简单：将所有的文档导出然后马上导入。忽略那些无效的文档。完成以后，会建立索引。 修复数据库还能起到压缩数据的作用。闲置的空间（比如删除体积较大的集合或者删除大量文档后腾出的空间）在修复后被重新回收。 修复损坏的数据是不得已时的最后一招，尽可能稳妥的停掉服务器，利用复制功能实现故障恢复，经常做备份，这些才是最有效管理数据的手段。 1234&gt; use testswitched to db test&gt; db.repairDatabase()&#123;&quot;ok&quot;:1&#125; 复制主从复制主从复制是MongoDB最常用的复制方式。可用于备份、故障恢复、读扩展等。最基本的设置方式就是建立一个主节点和一个或者多个从节点，每个从节点要知道主节点的地址。运行mongod –master就启动了主服务器。运行mongod –slave –source master_address则启动了从服务器，其中master_address就是上面的主节点的地址。 1234567# 设置主节点，并绑定端口10000$ mkdir -p ~/dbs/master$ ./mongod --dbpath ~/dbs/master --port 10000 --master#设置从节点，选择不同的目录和端口（示例配置从节点与主节点在同一台服务器上）$ mkdir -p ~/dbs/slave$ ./mongod --dbpath ~/dbs/slave --port 10001 --slave --source localhost:10000 副本集简单地说，副本集就是有自动故障恢复功能的主从集群。主从集群和副本集最为明显的区别是副本集没有固定的“主节点”：整个集群会选举出一个“主节点”，当其不能工作时则变更到其他节点。副本集中会有一个活跃节点和一个或多个备份节点。副本集最美妙的地方就是所有东西都是自动化的。]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB学习笔记]]></title>
    <url>%2Fblog%2Fa36562d7.html</url>
    <content type="text"><![CDATA[1、$where查询 不是非常必要时，一定要避免使用“$where”查询，因为它们在速度上要比常规查询慢很多。每个文档要从BSON转换成Javascript对象，然后通过“$where”的表达式来运行。同样还不能利用索引。所以，只在走投无路时才考虑“$where”这种用法。 将常规查询作为前置过滤，与“$where”组合使用可以不牺牲性能。如果可能的话，用索引根据非“$where”子句进行过滤，“$where”只用于对结果进行调优。 2、游标 数据库使用游标来返回find的执行结果，客户端对游标的实现通常能够对最终结果进行有效的控制。可以限制结果的数量，略过部分结果，根据任意方向任意键的组合对结果进行各种排序，或者是执行其他一些功能强大的操作。 要想从shell中创建一个游标，首先要对集合填充一些文档，然后对其执行查询，并将结果分配给一个局部变量（用var声明的变量就是局部变量）。要迭代结果，可以使用游标的next方法，也可以使用hasNext来查看有没有其他结果。例如：12345&gt; var cursor = db.collection.find();&gt; while (cursor.hasNext())&#123; obj = cursor.next(); // do stuff&#125; 3、索引建立索引的方法：1234db.people.ensureIndex(&#123;&quot;username&quot;:1&#125;) #以username为索引 db.people.ensureIndex(&#123;&quot;date&quot;:1,&quot;username&quot;:1&#125;) #以date,username为索引db.people.ensureIndex(&#123;&quot;comments.date&quot;:1&#125;) #索引内嵌文档中的键和普通的键创建索引没有什么区别db.people.ensureIndex(&#123;&quot;username&quot;:1&#125;,&#123;&quot;background&quot;:true&#125;) #建立索引既耗时也费力，还需要消耗很多资源。使用&#123;&quot;background&quot;:true&#125;选项可以使这个过程在后台完成，同时正常处理请求 建立索引时要考虑如下问题： 会做什么样的查询？其中哪些键需要索引？ 每个键的索引方向是怎样的？ 如何应对扩展？有没有种不同的键的排列可以使常用数据更多地保留在内存中？要是能回答这些问题，说明你已经做好了索引的准备了。 创建索引的缺点就是每次插入、更新和删除时都会产生额外的开销。这是因为数据库不但需要执行这些操作，还要将这些操作在集合的索引中标记。因此，要尽可能少创建索引。每个集合默认的最大索引个数为64个。 注意：一定不要索引每一个键。这会导致插入非常慢，还会占用很多空间，并且很可能对查询速度提升不大。 MongoDB排序需要将所有数据提取到内存来排序，因此，可以做无索引排序是有个上限的，那就是不可能在内存里面做T级别数据的排序。一旦集合大到不能在内存中排序，MongoDB就会报错。 索引管理：索引的元信息存储在每个数据库的system.indexes集合中。这是一个保留集合，不能对其插入或者删除文档。操作只能通过ensureIndex或者dropIndexes进行。建立索引既耗时也费力，还需要消耗很多资源。使用{“background”:true}选项可以使这个过程在后台完成，同时正常处理请求。 MongoDB支持动态建立普通集合，还支持固定集合（要实现创建，而且大小固定。如果固定集合空间不足，最早的文档就会被删除，为新的文档腾出空间，这意味着固定集合在新文档插入的时候自动淘汰最早的文档。） 固定集合和普通集合还有一个区别，就是在默认情况下固定集合没有索引，即便是“_id”上也没有索引。 固定集合有种特殊的排序方式，叫做“自然排序”。自然排序就是文档在磁盘上的顺序顺时针方向依次的。文档总数安装插入的顺序存储的，自然顺序就是与此相同的。也可以使用自然排序按照反向插入的顺序查询。 尾部游标只能在固定集合上使用。]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB学习笔记——查询]]></title>
    <url>%2Fblog%2Fa995f898.html</url>
    <content type="text"><![CDATA[转自：http://www.cnblogs.com/stephen-liu74/archive/2012/08/03/2553803.html 1、基本查询 1234567891011121314151617181920212223242526//构造查询数据 &gt; db.test.findOne() &#123; &quot;_id&quot; : ObjectId(&quot;4fd58ecbb9ac507e96276f1a&quot;), &quot;name&quot; : &quot;stephen&quot;, &quot;age&quot; : 35, &quot;genda&quot; : &quot;male&quot;, &quot;email&quot; : &quot;stephen@hotmail.com&quot; &#125;// 多条件查询。下面的示例等同于SQL语句的where name = &quot;stephen&quot; and age = 35 &gt; db.test.find(&#123;&#125;, &#123;&quot;name&quot;:1,&quot;age&quot;:1&#125;)&#123; &quot;_id&quot; : ObjectId(&quot;4fd58ecbb9ac507e96276f1a&quot;), &quot;name&quot; : &quot;stephen&quot;, &quot;age&quot; : 35&#125;// 指定不返回的文档键值对。下面的示例将返回除name之外的所有键值对。&gt; db.test.find(&#123;&#125;, &#123;&quot;name&quot;:0&#125;) // 0 表示不查询name属性&#123; &quot;_id&quot; : ObjectId(&quot;4fd58ecbb9ac507e96276f1a&quot;), &quot;age&quot; : 35, &quot;genda&quot; : &quot;male&quot;, &quot;email&quot; : &quot;stephen@hotmail.com&quot; &#125; 2、查询条件MongoDB提供了一组比较操作符：$lt / $lte / $gt / $gte / $ne，依次等价于&lt;,&lt;=, &gt;, &gt;=, != 。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980 //下面的示例返回符合条件age &gt;= 18 &amp;&amp; age &lt;= 40的文档 &gt; db.test.find(&#123;&quot;age&quot;:&#123;&quot;$gte&quot;:18, &quot;$lte&quot;:40&#125;&#125;) &#123; &quot;_id&quot; : ObjectId(&quot;4fd58ecbb9ac507e96276f1a&quot;), &quot;name&quot; : &quot;stephen&quot;, &quot;age&quot; : 35, &quot;genda&quot; : &quot;male&quot;, &quot;email&quot; : &quot;stephen@hotmail.com&quot; &#125;//下面的示例返回条件符合name != &quot;stephen1&quot;&gt; db.test.find(&#123;&quot;name&quot;:&#123;&quot;$ne&quot;:&quot;stephen1&quot;&#125;&#125;) &#123; &quot;_id&quot; : ObjectId(&quot;4fd58ecbb9ac507e96276f1a&quot;), &quot;name&quot; : &quot;stephen&quot;, &quot;age&quot; : 35, &quot;genda&quot; : &quot;male&quot;, &quot;email&quot; : &quot;stephen@hotmail.com&quot; &#125;//$in等同于SQL中的in，下面的示例等同于SQL中的in (&quot;stephen&quot;,&quot;stephen1&quot;) &gt; db.test.find(&#123;&quot;name&quot;:&#123;&quot;$in&quot;:[&quot;stephen&quot;,&quot;stephen1&quot;]&#125;&#125;) &#123; &quot;_id&quot; : ObjectId(&quot;4fd58ecbb9ac507e96276f1a&quot;), &quot;name&quot; : &quot;stephen&quot;, &quot;age&quot; : 35, &quot;genda&quot; : &quot;male&quot;, &quot;email&quot; : &quot;stephen@hotmail.com&quot; &#125; //和SQL不同的是，MongoDB的in list中的数据可以是不同类型。这种情况可用于不同类型的别名场景。 &gt; db.test.find(&#123;&quot;name&quot;:&#123;&quot;$in&quot;:[&quot;stephen&quot;,123]&#125;&#125;) &#123; &quot;_id&quot; : ObjectId(&quot;4fd58ecbb9ac507e96276f1a&quot;), &quot;name&quot; : &quot;stephen&quot;, &quot;age&quot; : 35, &quot;genda&quot; : &quot;male&quot;, &quot;email&quot; : &quot;stephen@hotmail.com&quot; &#125; //$nin等同于SQL中的not in，同时也是$in的取反。如： &gt; db.test.find(&#123;&quot;name&quot;:&#123;&quot;$nin&quot;:[&quot;stephen2&quot;,&quot;stephen1&quot;]&#125;&#125;) &#123; &quot;_id&quot; : ObjectId(&quot;4fd58ecbb9ac507e96276f1a&quot;), &quot;name&quot; : &quot;stephen&quot;, &quot;age&quot; : 35, &quot;genda&quot; : &quot;male&quot;, &quot;email&quot; : &quot;stephen@hotmail.com&quot; &#125;// $or等同于SQL中的or，$or所针对的条件被放到一个数组中，每个数组元素表示or的一个条件。//下面的示例等同于name = &quot;stephen1&quot; or age = 35* &gt; db.test.find(&#123;&quot;$or&quot;: [&#123;&quot;name&quot;:&quot;stephen1&quot;&#125;, &#123;&quot;age&quot;:35&#125;]&#125;) &#123; &quot;_id&quot; : ObjectId(&quot;4fd58ecbb9ac507e96276f1a&quot;), &quot;name&quot; : &quot;stephen&quot;, &quot;age&quot; : 35, &quot;genda&quot; : &quot;male&quot;, &quot;email&quot; : &quot;stephen@hotmail.com&quot; &#125; //下面的示例演示了如何混合使用$or和$in。&gt; db.test.find(&#123;&quot;$or&quot;: [&#123;&quot;name&quot;:&#123;&quot;$in&quot;:[&quot;stephen&quot;,&quot;stephen1&quot;]&#125;&#125;, &#123;&quot;age&quot;:36&#125;]&#125;) &#123; &quot;_id&quot; : ObjectId(&quot;4fd58ecbb9ac507e96276f1a&quot;), &quot;name&quot; : &quot;stephen&quot;, &quot;age&quot; : 35, &quot;genda&quot; : &quot;male&quot;, &quot;email&quot; : &quot;stephen@hotmail.com&quot; &#125;//$not表示取反，等同于SQL中的not。 &gt; db.test.find(&#123;&quot;name&quot;: &#123;&quot;$not&quot;: &#123;&quot;$in&quot;:[&quot;stephen2&quot;,&quot;stephen1&quot;]&#125;&#125;&#125;) &#123; &quot;_id&quot; : ObjectId(&quot;4fd58ecbb9ac507e96276f1a&quot;), &quot;name&quot; : &quot;stephen&quot;, &quot;age&quot; : 35, &quot;genda&quot; : &quot;male&quot;, &quot;email&quot; : &quot;stephen@hotmail.com&quot; &#125; 3、null数据类型的查询123456789101112131415//在进行值为null数据的查询时，所有值为null，以及不包含指定键的文档均会被检索出来。&gt; db.test.find(&#123;&quot;x&quot;:null&#125;)&#123; &quot;_id&quot; : ObjectId(&quot;4fd59d30b9ac507e96276f1b&quot;), &quot;x&quot; : null &#125;&#123; &quot;_id&quot; : ObjectId(&quot;4fd59d49b9ac507e96276f1c&quot;), &quot;y&quot; : 1 &#125; //需要将null作为数组中的一个元素进行相等性判断，即便这个数组中只有一个元素。//再有就是通过$exists判断指定键是否存在。&gt; db.test.find(&#123;&quot;x&quot;: &#123;&quot;$in&quot;: [null], &quot;$exists&quot;:true&#125;&#125;)&#123; &quot;_id&quot; : ObjectId(&quot;4fd59d30b9ac507e96276f1b&quot;), &quot;x&quot; : null &#125;]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB基本命令]]></title>
    <url>%2Fblog%2F5b072929.html</url>
    <content type="text"><![CDATA[MongoDB基本命令1234567891011121314151617181920212223242526//查询所有数据库列表show dbs //查看当前连接哪个数据库db//切换到需要使用的数据库，例如：use testuse database Name//查看当前数据库下有哪些表或者collectionshow collections//想知道mongodb支持哪些命令，可以直接输入help help//如果想知道当前数据库支持哪些方法db.help();//如果想知道当前数据库下的表或者表collection支持哪些方法，可以使用一下命令如db.user.help(); //user为表名 //如果你想备份数据库test$ ./mongodump -d test -o test/ //如果你想恢复数据库test$ ./mongorestore -d test -c user test/test/user.bson //利用mongorestore表恢复刚才利用mongodump备份的数据 help命令：1234567891011HELP show dbs show database names show collections show collections in current database show users show users in current database show profile show most recent system.profile entries with time &gt;= 1ms use &lt;db name&gt; set curent database to &lt;db name&gt; db.help() help on DB methods db.foo.help() help on collection methods db.foo.find() list objects in collection foo db.foo.find( &#123; a : 1 &#125; ) list objects in foo where a == 1 it result of the last line evaluated; use to further iterate db.help()命令：123456789101112131415161718192021222324252627282930313233DB methods: db.addUser(username, password) 添加数据库授权用户 db.auth(username, password) 访问认证 db.cloneDatabase(fromhost) 克隆数据库 db.commandHelp(name) returns the help for the command db.copyDatabase(fromdb, todb, fromhost) 复制数据库 db.createCollection(name, &#123; size : ..., capped : ..., max : ... &#125; ) 创建表 db.currentOp() displays the current operation in the db db.dropDatabase() 删除当前数据库 db.eval_r(func, args) run code server-side db.getCollection(cname) same as db[&apos;cname&apos;] or db.cname db.getCollectionNames() 获取当前数据库的表名 db.getLastError() - just returns the err msg string db.getLastErrorObj() - return full status object db.getMongo() get the server connection object db.getMongo().setSlaveOk() allow this connection to read from the nonmaster member of a replica pair db.getName() db.getPrevError() db.getProfilingLevel() db.getReplicationInfo() db.getSisterDB(name) get the db at the same server as this onew db.killOp() kills the current operation in the db db.printCollectionStats() 打印各表的状态信息 db.printReplicationInfo() 打印主数据库的复制状态信息 db.printSlaveReplicationInfo() 打印从数据库的复制状态信息 db.printShardingStatus() 打印分片状态信息 db.removeUser(username) 删除数据库用户 db.repairDatabase() 修复数据库 db.resetError() db.runCommand(cmdObj) run a database command. if cmdObj is a string, turns it into &#123; cmdObj : 1 &#125; db.setProfilingLevel(level) 0=off 1=slow 2=all db.shutdownServer() db.version() current version of the server]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Win7下MongoDB的安装和部署测试]]></title>
    <url>%2Fblog%2Ff2670fb0.html</url>
    <content type="text"><![CDATA[转自：http://jingyan.baidu.com/article/f3e34a12ac10cef5eb653583.html http://www.cnblogs.com/lzrabbit/p/3682510.html]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RestFul概述]]></title>
    <url>%2Fblog%2F3cf861a2.html</url>
    <content type="text"><![CDATA[一、概述 RestFul是一种软件架构风格，而不是标准，只是提供了一组设计原则和约束条件。它主要用于客户端和服务器交互类的软件。基于这个风格设计的软件可以更简洁，更有层次，更易于实现缓存等机制。 REST（英文：Representational State Transfer，简称REST）描述了一个架构样式的网络系统，比如 web 应用程序。在目前主流的三种Web服务交互方案中，REST相比于SOAP（Simple Object Access protocol，简单对象访问协议）以及XML-RPC更加简单明了，无论是对URL的处理还是对Payload的编码，REST都倾向于用更加简单轻量的方法设计和实现。值得注意的是REST并没有一个明确的标准，而更像是一种设计的风格。 要理解RESTful架构，最好的方法就是去理解Representational State Transfer这个词组到底是什么意思，它的每一个词代表了什么涵义。如果你把这个名称搞懂了，也就不难体会REST是一种什么样的设计。 ● 资源（Resources） REST的名称”表现层状态转化”中，省略了主语。”表现层”其实指的是”资源”（Resources）的”表现层”。 所谓”资源”，就是网络上的一个实体，或者说是网络上的一个具体信息。它可以是一段文本、一张图片、一首歌曲、一种服务，总之就是一个具体的实在。你可以用一个URI（统一资源定位符）指向它，每种资源对应一个特定的URI。要获取这个资源，访问它的URI就可以，因此URI就成了每一个资源的地址或独一无二的识别符。所谓”上网”，就是与互联网上一系列的”资源”互动，调用它的URI。 ● 表现层（Representation） “资源”是一种信息实体，它可以有多种外在表现形式。我们把”资源”具体呈现出来的形式，叫做它的”表现层”（Representation）。比如，文本可以用txt格式表现，也可以用HTML格式、XML格式、JSON格式表现，甚至可以采用二进制格式；图片可以用JPG格式表现，也可以用PNG格式表现。 URI只代表资源的实体，不代表它的形式。严格地说，有些网址最后的”.html”后缀名是不必要的，因为这个后缀名表示格式，属于”表现层”范畴，而URI应该只代表”资源”的位置。它的具体表现形式，应该在HTTP请求的头信息中用Accept和Content-Type字段指定，这两个字段才是对”表现层”的描述。 ● 状态转化（State Transfer） 访问一个网站，就代表了客户端和服务器的一个互动过程。在这个过程中，势必涉及到数据和状态的变化。互联网通信协议HTTP协议，是一个无状态协议。这意味着，所有的状态都保存在服务器端。因此，如果客户端想要操作服务器，必须通过某种手段，让服务器端发生”状态转化”（State Transfer）。而这种转化是建立在表现层之上的，所以就是”表现层状态转化”。客户端用到的手段，只能是HTTP协议。具体来说，就是HTTP协议里面，四个表示操作方式的动词：GET、POST、PUT、DELETE。它们分别对应四种基本操作：GET用来获取资源，POST用来新建资源（也可以用于更新资源），PUT用来更新资源，DELETE用来删除资源。 因此RESTful架构可以理解为：1、每一个URI代表一种资源；2、客户端和服务器之间，传递这种资源的某种表现层；3、客户端通过四个HTTP动词，对服务器端资源进行操作，实现”表现层状态转化”。]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>架构设计</tag>
        <tag>RestFul</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[元数据驱动成熟度模型]]></title>
    <url>%2Fblog%2Fb3220428.html</url>
    <content type="text"><![CDATA[第一代：代码辅助手段**应用定制开放依然以原生C++/JAVA代码为主，元数据主要用于生成原代码的一种辅助手段。 当前很多系统中，大部分元数据处于这个阶段，前端重点只有Gadget元数据其他元数据未抽象呈现，甚至前端没有元数据的概念；后端服务编排（以POJO实现为主）、服务实现（BO全是代码）、数据对象（VO全是代码）也是以代码为主开发。 第二代：端到端元数据（Siebel）应用定制开发基于元数据对象视图进行，从前端界面、组件、事件、接口、流程、服务、模型整个端到端都已经抽象成元数据对象，任意定制需求最终都分解成一个Task去完成整个元数据的配置，定制开发工具以离线IDE为主，在线提供受限的能力。 Siebel 版本开发定制处于这个阶段。 第三代：元数据SaaS化（Salesforce）应用定制开发在现场在定制闭环，应用的定制开发能力通过SaaS化的能力对外提供出来，支持多租户的并发定制，定制开发人员通过Chrome等浏览器就可以完成现场定制需求的配置开发，可在线完成界面主体调整、界面Gadget组件、新Gadget开发、在线流程变更、业务规则调整、模型扩展，甚至新流程、新服务、新模型、新界面的中小特性开发。 同时保证在线配置元数据（包括服务脚本逻辑）的安全性，通过元数据引擎沙箱技术对运行所耗费的CPU时间、内容容量、SQL语句数量等数据来判断元数据是否正常，以避免影响到属于其他租户的应用，对于脚本需要自带能覆盖其75%代码的测试用例否则不允许调用等措施，从而确保平台整体运行的稳定。 Salesforce 版本开发定制处于这个阶段。 第四代：元数据人性化就像CRM从以OCRM为主向以ACRM为主转变，未来可能像HCRM（HappyCRM）转变，不过可以确定的是未来编程肯定会越来越简单，就像公司另外一个同事在硅谷调研发现硅谷有很多创新公司就做一件事：为编程者提供极易的软件创造平台，这样对大部分软件人员来说，编程并不是最重要的，业务本身创造才是；所以抽象的元数据可能会逐步往自然语言的方向进行发展，当然第四代还不是很清晰。]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>架构设计</tag>
        <tag>元数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[什么是元数据驱动开发？]]></title>
    <url>%2Fblog%2F42023a9c.html</url>
    <content type="text"><![CDATA[先看一个例子：Case1：客户资料的一条记录，是我们通常理解的“数据”，描述客户资料的数据结构定义的数据就是“元数据”（描述数据的数据）。 Case2：系统参数的一条记录，是我们配置出来的“数据”，描述系统参数的数据结构定义的数据也是“元数据”。 Case1和Case2的差别：Case1的数据的产生或变化不会在运行期直接改变软件的预置业务功能，只会影响后续业务功能的处理结果。 Case2的数据的产生或变化会在运行期改变软件的行为，直接提供不同的业务功能。 把Case2中的这种通过建模定义元数据的方式，期望提供一种配置化的设计方案从而改变软件提供的业务功能的设计方法称为基于元数据驱动架构。 这种直接基于case2大的类别的元数据，针对性的进行配置从而提供软件不同的业务功能的方式称为元数据驱动开发。元数据驱动开发的基本思想，就是基于元数据对象声明式开发整个应用，围绕元数据对象创建界面、业务流程、领域服务、领域对象及物理存储表结构，围绕元数据对象进行测试（包括测试数据生成、用例管理等），围绕元数据对象进行局点个性化需求定制（包括界面、流程、服务、表结构等），围绕元数据对象进行问题定位，从而达到通过元数据对象驱动整个应用开发过程的进行。 如果基于元数据还把业务需求的需求分析+调测+安装部署+资料都搞定了，那么就是元数据驱动交付。 注意：CASE1和CASE2是相对一个特定系统边界来说的，反例是：对于系统A来说，CASE2中的这个数据就是CASE1的类别，比如：SM就是要管理这个系统参数实体，对系统参数实体的CRUD是SM的“业务”功能，再比如PM会管理商品/产品数据，这个数据对于PM来说是CASE1类型，对于OM来说就是CASE2类型的，因为不同的商品/产品,相同商品/产品的不同属性对于OM来说是要提供不同的业务功能的。]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>架构设计</tag>
        <tag>元数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 编程最佳实践]]></title>
    <url>%2Fblog%2Fcf66995.html</url>
    <content type="text"><![CDATA[项目结构定义： Sample RepositoryThis is what Kenneth Reitz recommends.This repository is available on GitHub. 1234567891011README.rstLICENSEsetup.pyrequirements.txtsample/__init__.pysample/core.pysample/helpers.pydocs/conf.pydocs/index.rsttests/test_basic.pytests/test_advanced.py Very bad1234[...]from modu import *[...]x = sqrt(4) # Is sqrt part of modu? A builtin? Defined above? Better123from modu import sqrt[...]x = sqrt(4) # sqrt may be part of modu, if not redefined in between Best123import modu[...]x = modu.sqrt(4) # sqrt is visibly part of modu&apos;s namespace DecoratorsThe Python language provides a simple yet powerful syntax called ‘decorators’. A decorator is a function or a class that wraps (or decorates) a function or a method. The ‘decorated’ function or method will replace the original ‘undecorated’ function or method. Because functions are first-class objects in Python, this can be done ‘manually’, but using the @decorator syntax is clearer and thus preferred. 1234567891011121314def foo(): # do somethingdef decorator(func): # manipulate func return funcfoo = decorator(foo) # Manually decorate@decoratordef bar(): # Do something# bar() is decorated Bad123items = &apos;a b c d&apos; # This is a string...items = items.split(&apos; &apos;) # ...becoming a listitems = set(items) # ...and then a set Good1234count = 1msg = &apos;a string&apos;def func(): pass # Do something Bad12345# create a concatenated string from 0 to 19 (e.g. &quot;012..1819&quot;)nums = &quot;&quot;for n in range(20): nums += str(n) # slow and inefficientprint nums Good12345# create a concatenated string from 0 to 19 (e.g. &quot;012..1819&quot;)nums = []for n in range(20): nums.append(str(n))print &quot;&quot;.join(nums) # much more efficient Best123# create a concatenated string from 0 to 19 (e.g. &quot;012..1819&quot;)nums = [str(n) for n in range(20)]print &quot;&quot;.join(nums)]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python学习笔记3]]></title>
    <url>%2Fblog%2Fb470e876.html</url>
    <content type="text"><![CDATA[Python网络编程TCP面向连接的通信方式，UDP与TCP不同，与虚拟电路完全相反，是数据报型的无连接套接字。 TCP通信，要先开服务器，后开客户端。12345# tcp socktcpSerSock = socket(AF_INET,SOCK_STREAM) # udp sockudpSerSock = socket(AF_INET,SOCK_DGRAM) python apply()函数apply(func [, args [, kwargs ]]) 函数用于当函数参数已经存在于一个元组或字典中时，间接地调用函数。args是一个包含将要提供给函数的按位置传递的参数的元组。如果省略了args，任 何参数都不会被传递，kwargs是一个包含关键字参数的字典。 apply()的返回值就是func()的返回值，apply()的元素参数是有序的，元素的顺序必须和func()形式参数的顺序一致 下面给几个例子来详细的说下: 1、假设是执行没有带参数的方法 def say(): print ‘say in’ apply(say) 输出的结果是’say in’ 2、函数只带元组的参数。 def say(a, b): print a, b apply(say,(“hello”, “老王python”)) 输出的结果是hello,老王python __call__函数Python中有一个有趣的语法，只要定义类型的时候，实现__call__函数，这个类型就成为可调用的。换句话说，我们可以把这个类型的对象当作函数来使用，相当于 重载了括号运算符。1234567class g_dpm(object): def __init__(self, g): self.g = g def __call__(self, t): return (self.g*t**2)/2 计算地球场景的时候，我们就可以令e_dpm = g_dpm(9.8)，s = e_dpm(t)。 123456789101112131415161718192021222324252627282930313233class Animal(object): def __init__(self, name, legs): self.name = name self.legs = legs self.stomach = [] def __call__(self,food): self.stomach.append(food) def poop(self): if len(self.stomach) &gt; 0: return self.stomach.pop(0) def __str__(self): return &apos;A animal named %s&apos; % (self.name) cow = Animal(&apos;king&apos;, 4) #We make a cow dog = Animal(&apos;flopp&apos;, 4) #We can make many animals print &apos;We have 2 animales a cow name %s and dog named %s,both have %s legs&apos; % (cow.name, dog.name, cow.legs) print cow #here __str__ metod work #We give food to cow cow(&apos;gras&apos;) print cow.stomach #We give food to dog dog(&apos;bone&apos;) dog(&apos;beef&apos;) print dog.stomach #What comes inn most come out print cow.poop() print cow.stomach #Empty stomach 12345678&apos;&apos;&apos;--&gt;output We have 2 animales a cow name king and dog named flopp,both have 4 legs A animal named king [&apos;gras&apos;] [&apos;bone&apos;, &apos;beef&apos;] gras [] &apos;&apos;&apos;]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈 Python 的 with语句]]></title>
    <url>%2Fblog%2F379f8526.html</url>
    <content type="text"><![CDATA[转自：http://www.ibm.com/developerworks/cn/opensource/os-cn-pythonwith/ 引言with 语句是从 Python 2.5 开始引入的一种与异常处理相关的功能（2.5 版本中要通过 from future import with_statement 导入后才可以使用），从 2.6 版本开始缺省可用（参考 What’s new in Python 2.6? 中 with 语句相关部分介绍）。with 语句适用于对资源进行访问的场合，确保不管使用过程中是否发生异常都会执行必要的“清理”操作，释放资源，比如文件使用后自动关闭、线程中锁的自动获取和释放等。 术语要使用 with 语句，首先要明白上下文管理器这一概念。有了上下文管理器，with 语句才能工作。 下面是一组与上下文管理器和with 语句有关的概念。 上下文管理协议（Context Management Protocol）：包含方法__enter__() 和 __exit__()，支持该协议的对象要实现这两个方法。 上下文管理器（Context Manager）：支持上下文管理协议的对象，这种对象实现了__enter__() 和 __exit__()方法。上下文管理器定义执行 with 语句时要建立的运行时上下文，负责执行 with 语句块上下文中的进入与退出操作。通常使用 with 语句调用上下文管理器，也可以通过直接调用其方法来使用。 运行时上下文（runtime context）：由上下文管理器创建，通过上下文管理器的 __enter__() 和__exit__()方法实现，__enter__()方法在语句体执行之前进入运行时上下文，__exit__() 在语句体执行完后从运行时上下文退出。with 语句支持运行时上下文这一概念。 上下文表达式（Context Expression）：with 语句中跟在关键字 with 之后的表达式，该表达式要返回一个上下文管理器对象。 语句体（with-body）：with 语句包裹起来的代码块，在执行语句体之前会调用上下文管理器的 enter() 方法，执行完语句体之后会执行 exit() 方法。 #基本语法和工作原理with 语句的语法格式如下： 清单 1. with 语句的语法格式12with context_expression [as target(s)]: with-body 这里 context_expression 要返回一个上下文管理器对象，该对象并不赋值给 as 子句中的 target(s) ，如果指定了 as 子句的话，会将上下文管理器的 enter() 方法的返回值赋值给 target(s)。target(s) 可以是单个变量，或者由“()”括起来的元组（不能是仅仅由“,”分隔的变量列表，必须加“()”）。 Python 对一些内建对象进行改进，加入了对上下文管理器的支持，可以用于 with 语句中，比如可以自动关闭文件、线程锁的自动获取和释放等。假设要对一个文件进行操作，使用 with 语句可以有如下代码： 清单 2. 使用 with 语句操作文件对象1234with open(r&apos;somefileName&apos;) as somefile: for line in somefile: print line # ...more code 这里使用了 with 语句，不管在处理文件过程中是否发生异常，都能保证 with 语句执行完毕后已经关闭了打开的文件句柄。如果使用传统的 try/finally 范式，则要使用类似如下代码： 清单 3. try/finally 方式操作文件对象1234567somefile = open(r&apos;somefileName&apos;)try: for line in somefile: print line # ...more codefinally: somefile.close() 比较起来，使用 with 语句可以减少编码量。已经加入对上下文管理协议支持的还有模块 threading、decimal 等。 PEP 0343 对 with 语句的实现进行了描述。with 语句的执行过程类似如下代码块： 清单 4. with 语句执行过程123456789101112131415161718192021context_manager = context_expressionexit = type(context_manager).__exit__ value = type(context_manager).__enter__(context_manager)exc = True # True 表示正常执行，即便有异常也忽略；False 表示重新抛出异常，需要对异常进行处理try: try: target = value # 如果使用了 as 子句 with-body # 执行 with-body except: # 执行过程中有异常发生 exc = False # 如果 __exit__ 返回 True，则异常被忽略；如果返回 False，则重新抛出异常 # 由外层代码对异常进行处理 if not exit(context_manager, *sys.exc_info()): raisefinally: # 正常退出，或者通过 statement-body 中的 break/continue/return 语句退出 # 或者忽略异常退出 if exc: exit(context_manager, None, None, None) # 缺省返回 None，None 在布尔上下文中看做是 False 1.执行 context_expression，生成上下文管理器 context_manager2.调用上下文管理器的__enter__()方法；如果使用了 as 子句，则将__enter__()方法的返回值赋值给 as 子句中的 target(s)3.执行语句体 with-body4.不管是否执行过程中是否发生了异常，执行上下文管理器的__exit__()方法，__exit__()方法负责执行“清理”工作，如释放资源等。如果执行过程中没有出现异常，或者语句体中执行了语句 break/continue/return则以 None 作为参数调用__exit__(None, None, None)；如果执行过程中出现异常，则使用sys.exc_info得到的异常信息为参数调用 __exit__(exc_type, exc_value, exc_traceback)5.出现异常时，如果 __exit__(type, value, traceback)返回 False，则会重新抛出异常，让with 之外的语句逻辑来处理异常，这也是通用做法；如果返回 True，则忽略异常，不再对异常进行处理。 自定义上下文管理器开发人员可以自定义支持上下文管理协议的类。自定义的上下文管理器要实现上下文管理协议所需要的 __enter__()和__exit__()两个方法： context_manager.__enter__()：进入上下文管理器的运行时上下文，在语句体执行前调用。with 语句将该方法的返回值赋值给 as 子句中的 target，如果指定了 as 子句的话 context_manager.__exit__(exc_type, exc_value, exc_traceback)：退出与上下文管理器相关的运行时上下文，返回一个布尔值表示是否对发生的异常进行处理。参数表示引起退出操作的异常，如果退出时没有发生异常，则3个参数都为None。如果发生异常，返回 True 表示不处理异常，否则会在退出该方法后重新抛出异常以由 with 语句之外的代码逻辑进行处理。如果该方法内部产生异常，则会取代由 statement-body 中语句产生的异常。要处理异常时，不要显示重新抛出异常，即不能重新抛出通过参数传递进来的异常，只需要将返回值设置为 False 就可以了。之后，上下文管理代码会检测是否__exit__()失败来处理异常 下面通过一个简单的示例来演示如何构建自定义的上下文管理器。注意，上下文管理器必须同时提供 __enter__()和__exit__() 方法的定义，缺少任何一个都会导致 AttributeError；with 语句会先检查是否提供了__exit__()方法，然后检查是否定义了__enter__() 方法。 假设有一个资源 DummyResource，这种资源需要在访问前先分配，使用完后再释放掉；分配操作可以放到 enter() 方法中，释放操作可以放到 exit() 方法中。简单起见，这里只通过打印语句来表明当前的操作，并没有实际的资源分配与释放。 清单 5. 自定义支持 with 语句的对象1234567891011121314class DummyResource:def __init__(self, tag): self.tag = tag print &apos;Resource [%s]&apos; % tag def __enter__(self): print &apos;[Enter %s]: Allocate resource.&apos; % self.tag return self # 可以返回不同的对象 def __exit__(self, exc_type, exc_value, exc_tb): print &apos;[Exit %s]: Free resource.&apos; % self.tag if exc_tb is None: print &apos;[Exit %s]: Exited without exception.&apos; % self.tag else: print &apos;[Exit %s]: Exited with exception raised.&apos; % self.tag return False # 可以省略，缺省的None也是被看做是False DummyResource 中的 enter() 返回的是自身的引用，这个引用可以赋值给 as 子句中的 target 变量；返回值的类型可以根据实际需要设置为不同的类型，不必是上下文管理器对象本身。 __exit__()方法中对变量 exc_tb 进行检测，如果不为 None，表示发生了异常，返回 False 表示需要由外部代码逻辑对异常进行处理；注意到如果没有发生异常，缺省的返回值为 None，在布尔环境中也是被看做 False，但是由于没有异常发生，__exit__()的三个参数都为 None，上下文管理代码可以检测这种情况，做正常处理。 下面在 with 语句中访问 DummyResource ： 清单 6. 使用自定义的支持 with 语句的对象*123456with DummyResource(&apos;Normal&apos;): print &apos;[with-body] Run without exceptions.&apos; with DummyResource(&apos;With-Exception&apos;): print &apos;[with-body] Run with exception.&apos; raise Exception print &apos;[with-body] Run with exception. Failed to finish statement-body!&apos; 第1个 with 语句的执行结果如下： 清单 7. with 语句1执行结果12345Resource [Normal][Enter Normal]: Allocate resource.[with-body] Run without exceptions.[Exit Normal]: Free resource.[Exit Normal]: Exited without exception. 可以看到，正常执行时会先执行完语句体 with-body，然后执行 __exit__() 方法释放资源。 第2个 with 语句的执行结果如下： 清单 8. with 语句2执行结果123456789Resource [With-Exception][Enter With-Exception]: Allocate resource.[with-body] Run with exception.[Exit With-Exception]: Free resource.[Exit With-Exception]: Exited with exception raised. Traceback (most recent call last): File &quot;G:/demo&quot;, line 20, in &lt;module&gt; raise ExceptionException 可以看到，with-body 中发生异常时with-body 并没有执行完，但资源会保证被释放掉，同时产生的异常由 with 语句之外的代码逻辑来捕获处理。 可以自定义上下文管理器来对软件系统中的资源进行管理，比如数据库连接、共享资源的访问控制等。Python 在线文档 Writing Context Managers 提供了一个针对数据库连接进行管理的上下文管理器的简单范例。 contextlib 模块contextlib 模块提供了3个对象：装饰器 contextmanager、函数 nested 和上下文管理器 closing。使用这些对象，可以对已有的生成器函数或者对象进行包装，加入对上下文管理协议的支持，避免了专门编写上下文管理器来支持 with 语句。 装饰器 contextmanagercontextmanager 用于对生成器函数进行装饰，生成器函数被装饰以后，返回的是一个上下文管理器，其 __enter__()和 __exit__()方法由 contextmanager 负责提供，而不再是之前的迭代子。被装饰的生成器函数只能产生一个值，否则会导致异常 RuntimeError；产生的值会赋值给 as 子句中的 target，如果使用了 as 子句的话。下面看一个简单的例子。 清单 9. 装饰器 contextmanager 使用示例12345678910from contextlib import contextmanager @contextmanagerdef demo(): print &apos;[Allocate resources]&apos; print &apos;Code before yield-statement executes in __enter__&apos; yield &apos;*** contextmanager demo ***&apos; print &apos;Code after yield-statement executes in __exit__&apos; print &apos;[Free resources]&apos; with demo() as value: print &apos;Assigned Value: %s&apos; % value 结果输出如下： 清单 10. contextmanager 使用示例执行结果12345[Allocate resources]Code before yield-statement executes in __enter__Assigned Value: *** contextmanager demo ***Code after yield-statement executes in __exit__[Free resources] 可以看到，生成器函数中 yield 之前的语句在__enter__() 方法中执行，yield 之后的语句在 __exit__() 中执行，而 yield 产生的值赋给了 as 子句中的 value 变量。需要注意的是，contextmanager 只是省略了 __enter__() / __exit__() 的编写，但并不负责实现资源的“获取”和“清理”工作；“获取”操作需要定义在 yield 语句之前，“清理”操作需要定义 yield 语句之后，这样 with 语句在执行 __enter__() / __exit__()方法时会执行这些语句以获取/释放资源，即生成器函数中需要实现必要的逻辑控制，包括资源访问出现错误时抛出适当的异常。函数 nestednested 可以将多个上下文管理器组织在一起，避免使用嵌套 with 语句。 清单 11. nested 语法12with nested(A(), B(), C()) as (X, Y, Z): # with-body code here 类似于：清单 12. nested 执行过程1234with A() as X: with B() as Y: with C() as Z: # with-body code here 需要注意的是，发生异常后，如果某个上下文管理器的 exit() 方法对异常处理返回 False，则更外层的上下文管理器不会监测到异常。上下文管理器 closingclosing 的实现如下：清单 13. 上下文管理 closing 实现12345678class closing(object): # help doc here def __init__(self, thing): self.thing = thing def __enter__(self): return self.thing def __exit__(self, *exc_info): self.thing.close() 上下文管理器会将包装的对象赋值给 as 子句的 target 变量，同时保证打开的对象在 with-body 执行完后会关闭掉。closing 上下文管理器包装起来的对象必须提供 close() 方法的定义，否则执行时会报 AttributeError 错误。 清单 14. 自定义支持 closing 的对象1234567891011class ClosingDemo(object): def __init__(self): self.acquire() def acquire(self): print &apos;Acquire resources.&apos; def free(self): print &apos;Clean up any resources acquired.&apos; def close(self): self.free() with closing(ClosingDemo()): print &apos;Using resources&apos; 结果输出如下： 清单 15. 自定义 closing 对象的输出结果123Acquire resources.Using resourcesClean up any resources acquired. closing 适用于提供了 close() 实现的对象，比如网络连接、数据库连接等，也可以在自定义类时通过接口 close() 来执行所需要的资源“清理”工作。 小结本文对 with 语句的语法和工作机理进行了介绍，并通过示例介绍了如何实现自定义的上下文管理器，最后介绍了如何使用 contextlib 模块来简化上下文管理器的编写。]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[The Twelve-Factor App]]></title>
    <url>%2Fblog%2F3781e7a0.html</url>
    <content type="text"><![CDATA[简介如今，软件通常会作为一种服务来交付，它们被称为网络应用程序，或软件即服务（SaaS）。12-Factor 为构建如下的 SaaS 应用提供了方法论： 使用标准化流程自动配置，从而使新的开发者花费最少的学习成本加入这个项目。 和操作系统之间尽可能的划清界限，在各个系统中提供最大的可移植性。 适合部署在现代的云计算平台，从而在服务器和系统管理方面节省资源。 将开发环境和生产环境的差异降至最低，并使用持续交付实施敏捷开发。 可以在工具、架构和开发流程不发生明显变化的前提下实现扩展。 这套理论适用于任意语言和后端服务（数据库、消息队列、缓存等）开发的应用程序。 背景本文的贡献者者参与过数以百计的应用程序的开发和部署，并通过 Heroku 平台间接见证了数十万应用程序的开发，运作以及扩展的过程。本文综合了我们关于 SaaS 应用几乎所有的经验和智慧，是开发此类应用的理想实践标准，并特别关注于应用程序如何保持良性成长，开发者之间如何进行有效的代码协作，以及如何 避免软件污染 。我们的初衷是分享在现代软件开发过程中发现的一些系统性问题，并加深对这些问题的认识。我们提供了讨论这些问题时所需的共享词汇，同时使用相关术语给出一套针对这些问题的广义解决方案。本文格式的灵感来自于 Martin Fowler 的书籍：Patterns of Enterprise Application Architecture ， Refactoring 。 读者应该是哪些人？任何 SaaS 应用的开发人员。部署和管理此类应用的运维工程师。 12-factorsI. 基准代码一份基准代码，多份部署II. 依赖显式声明依赖关系III. 配置在环境中存储配置IV. 后端服务把后端服务当作附加资源V. 构建，发布，运行严格分离构建和运行VI. 进程以一个或多个无状态进程运行应用VII. 端口绑定通过端口绑定提供服务VIII. 并发通过进程模型进行扩展IX. 易处理快速启动和优雅终止可最大化健壮性X. 开发环境与线上环境等价尽可能的保持开发，预发布，线上环境相同XI. 日志把日志当作事件流XII. 管理进程后台管理任务当作一次性进程运行]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[元数据基本概念]]></title>
    <url>%2Fblog%2F19a3e08c.html</url>
    <content type="text"><![CDATA[元数据（Metadata）定义元数据在数据仓库、软件开发、图书管理等各领域有着广泛的应用，其业界通用的定义为：描述数据的数据。用于承载关于数据的组织、数据域及其关系等的信息。 示例：客户信息记录 元数据 数据 客户名称 张三 证件类型 身份证 证件号码 123456789 手机号码 13913912345 行业类型 通信 地址 xx省xx市xx区xx路xx号 对于一条客户信息记录而言，其中：张三、身份证、123456789等信息就是数据，而客户名称、证件类型、证件号码等信息就是描述这些数据的数据，也就是元数据。 什么是元数据，直接参考wiki的一些定义：https://en.wikipedia.org/wiki/Metadata 元元数据：定义元数据这个对象的结构的数据。 技术元数据与业务元数据技术元数据与业务元数据的本质区别在于是否与具体的业务逻辑（套件）强相关。 技术元数据：指对应用架构进行抽象，屏蔽技术细节而定义出来的元数据。与具体业务逻辑无关，一般由平台定义。 业务元数据：指对业务框架进行抽象后，基于具体业务逻辑的那部分元数据，一般由业务侧根据平台提供的元数据定义和自生长机制生成出来。]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>架构设计</tag>
        <tag>元数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python学习笔记2]]></title>
    <url>%2Fblog%2Fc377d8e0.html</url>
    <content type="text"><![CDATA[python方法，在python语言中，任何一个方法定义中的第一个参数都是变量self，它表示调用此方法的实例对象。 self是什么：self变量用于在类实例方法中引用方法所绑定的实例。因为方法的实例在任何地方调用中总是作为第一个参数传递的，self被选中用来代表实例。你必须在方法声明中放上self（你可能已经注意到了这点），但可以在方法中不使用实例（self）。如果你的方法中没有用到self，那么请考虑创建一个常规函数，除非你有特别的原因。毕竟，你的方法代码没有使用实例，没有与类关联其功能，这使得它看起来更像一个常规函数。在其他面向对象语言中，self可能被称为this。 python调用绑定方法，即一个类实例一个对象后，通过实例对象来调用方法：123456789101112class C(object): &quot;&quot;&quot;docstring for C&quot;&quot;&quot; foo = 100 def testFun(self,name): self.name = namecObject = C()cObject.testFun(&quot;Elwin&quot;)print(&quot;C name is %s&quot; %cObject.name) python支持类的多继承，java语言不支持类的多继承。在python语言中多继承需要特别注意方法解释顺序（MRO）。经典类中，使用深度优先算法。新式类继承来自object，新的菱形类集成结构出现，问题也就接着而来，所以必须新建一个MRO. 123456789101112131415161718192021222324252627#经典类class P1: &quot;&quot;&quot;docstring for P1&quot;&quot;&quot; def foo(self): print &quot;called P1-foo()&quot;class P2: &quot;&quot;&quot;docstring for P2&quot;&quot;&quot; def foo(self): print &quot;called P2-foo()&quot;class C1(P1,P2): pass#新式类class P1(object): &quot;&quot;&quot;docstring for P1&quot;&quot;&quot; def foo(self): print &quot;called P1-foo()&quot;class P2(object): &quot;&quot;&quot;docstring for P2&quot;&quot;&quot; def foo(self): print &quot;called P2-foo()&quot;class C1(P1,P2): pass]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hive 学习笔记]]></title>
    <url>%2Fblog%2F7ed447e8.html</url>
    <content type="text"><![CDATA[【文件存储格式】在建表语句中通过” STORED AS FILE_FORMAT” 指定。 TEXTFILE：默认格式，数据不做压缩，磁盘开销大，数据解析开销大，结合Gzip/Bizp2使用，采用此种方式不支持对数据进行切分，从而无法实现数据的并行操作。 SEQUENCEFILE：Hadoop API提供的一种二进制文件，使用方便，支持数据切分与压缩。有三种压缩方式，NONE，RECORD（压缩率低）、BLOCK（推荐使用）。 RCFILE：一种行列存储相结合的方式。首先将数据按行分块，保证同一行记录在同一个块上；其次将块数据进行行列式存储，这样有利于数据压缩和快速的列存储。采用这种格式在数据加载时耗费的性能较大，但是具备较好的数据压缩比和查询响应，在一次写入多次读取的场景下推荐采用。 自定义格式：当用户的数据文件格式不能被Hive识别时，通过实行InputFormat和OutputFormat来自定义输入输出格式。]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>Hive</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[(译)Python关键字yield的解释--下篇(stackoverflow)]]></title>
    <url>%2Fblog%2F459536d7.html</url>
    <content type="text"><![CDATA[6.回到你的代码（译者注：这是回答这对问题的具体解释） 生成器：1234567891011121314151617# Here you create the method of the node object that will return the generatordef node._get_child_candidates(self, distance, min_dist, max_dist): # Here is the code that will be called each time you use the generator object : # If there is still a child of the node object on its left # AND if distance is ok, return the next child if self._leftchild and distance - max_dist &lt; self._median: yield self._leftchild # If there is still a child of the node object on its right # AND if distance is ok, return the next child if self._rightchild and distance + max_dist &gt;= self._median: yield self._rightchild # If the function arrives here, the generator will be considered empty # there is no more than two values : the left and the right children 调用者：12345678910111213141516171819# Create an empty list and a list with the current object referenceresult, candidates = list(), [self]# Loop on candidates (they contain only one element at the beginning)while candidates: # Get the last candidate and remove it from the list node = candidates.pop() # Get the distance between obj and the candidate distance = node._get_dist(obj) # If distance is ok, then you can fill the result if distance &lt;= max_dist and distance &gt;= min_dist: result.extend(node._values) # Add the children of the candidate in the candidates list # so the loop will keep running until it will have looked # at all the children of the children of the children, etc. of the candidate candidates.extend(node._get_child_candidates(distance, min_dist, max_dist))return result 这个代码包含了几个小部分： 我们对一个列表进行迭代，但是迭代中列表还在不断的扩展。它是一个迭代这些嵌套的数据的简洁方式，即使这样有点危险，因为可能导致无限迭代。candidates.extend(node._get_child_candidates(distance, min_dist, max_dist))穷尽了生成器的所有值，但 while 不断地在产生新的生成器，它们会产生和上一次不一样的值，既然没有作用到同一个节点上. extend() 是一个迭代器方法，作用于迭代器，并把参数追加到迭代器的后面。 通常我们传递它一个列表参数：12345&gt;&gt;&gt; a = [1, 2]&gt;&gt;&gt; b = [3, 4]&gt;&gt;&gt; a.extend(b)&gt;&gt;&gt; print(a)[1, 2, 3, 4] 但是在你的代码中的是一个生成器，这是不错的，因为： 你不必读两次所有的值 你可以有很多子对象，但不必叫他们都存储在内存里面。 并且这很奏效，因为Python不关心一个方法的参数是不是个列表。Python只希望它是个可以迭代的，所以这个参数可以是列表，元组，字符串，生成器… 这叫做 ducktyping,这也是为何Python如此棒的原因之一，但这已经是另外一个问题了… 你可以在这里停下，来看看生成器的一些高级用法: 7.控制生成器穷尽1234567891011121314151617181920212223242526272829303132333435363738394041&gt;&gt;&gt; class Bank(): # let&apos;s create a bank, building ATMs... crisis = False... def create_atm(self) :... while not self.crisis :... yield &quot;$100&quot;&gt;&gt;&gt; hsbc = Bank() # when everything&apos;s ok the ATM gives you as much as you want&gt;&gt;&gt; corner_street_atm = hsbc.create_atm()&gt;&gt;&gt; print(corner_street_atm.next())$100&gt;&gt;&gt; print(corner_street_atm.next())$100&gt;&gt;&gt; print([corner_street_atm.next() for cash in range(5)])[&apos;$100&apos;, &apos;$100&apos;, &apos;$100&apos;, &apos;$100&apos;, &apos;$100&apos;]&gt;&gt;&gt; hsbc.crisis = True # crisis is coming, no more money!&gt;&gt;&gt; print(corner_street_atm.next())&lt;type &apos;exceptions.StopIteration&apos;&gt;&gt;&gt;&gt; wall_street_atm = hsbc.create_atm() # it&apos;s even true for new ATMs&gt;&gt;&gt; print(wall_street_atm.next())&lt;type &apos;exceptions.StopIteration&apos;&gt;&gt;&gt;&gt; hsbc.crisis = False # trouble is, even post-crisis the ATM remains empty&gt;&gt;&gt; print(corner_street_atm.next())&lt;type &apos;exceptions.StopIteration&apos;&gt;&gt;&gt;&gt; brand_new_atm = hsbc.create_atm() # build a new one to get back in business&gt;&gt;&gt; for cash in brand_new_atm :... print cash$100$100$100$100$100$100$100$100$100... 对于控制一些资源的访问来说这很有用。 8.Itertools，你最好的朋友itertools包含了很多特殊的迭代方法。是不是曾想过复制一个迭代器?串联两个迭代器？把嵌套的列表分组？不用创造一个新的列表的 zip/map? 只要 import itertools 需要个例子？让我们看看比赛中4匹马可能到达终点的先后顺序的可能情况:123456789101112131415161718192021222324252627282930&gt;&gt;&gt; horses = [1, 2, 3, 4]&gt;&gt;&gt; races = itertools.permutations(horses)&gt;&gt;&gt; print(races)&lt;itertools.permutations object at 0xb754f1dc&gt;&gt;&gt;&gt; print(list(itertools.permutations(horses)))[(1, 2, 3, 4), (1, 2, 4, 3), (1, 3, 2, 4), (1, 3, 4, 2), (1, 4, 2, 3), (1, 4, 3, 2), (2, 1, 3, 4), (2, 1, 4, 3), (2, 3, 1, 4),(2, 3, 4, 1),(2, 4, 1, 3), (2, 4, 3, 1), (3, 1, 2, 4), (3, 1, 4, 2), (3, 2, 1, 4), (3, 2, 4, 1), (3, 4, 1, 2),(3, 4, 2, 1), (4, 1, 2, 3), (4, 1, 3, 2), (4, 2, 1, 3),(4, 2, 3, 1), (4, 3, 1, 2), (4, 3, 2, 1)] 9.了解迭代器的内部机制迭代是一个实现可迭代对象(实现的是 iter() 方法)和迭代器(实现的是next() 方法)的过程。可迭代对象是你可以从其获取到一个迭代器的任一对象。迭代器是那些允许你迭代可迭代对象的对象。 更多见这个文章 http://effbot.org/zone/python-for-statement.htm]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[(译)Python关键字yield的解释--上篇(stackoverflow)]]></title>
    <url>%2Fblog%2F9277b68f.html</url>
    <content type="text"><![CDATA[原文：http://stackoverflow.com/questions/231767/the-python-yield-keyword-explained译者：hit9译者注：这是stackoverflow上一个很热的帖子，这里是投票最高的一个答案 1.提问者的问题Python关键字yield的作用是什么？用来干什么的？比如，我正在试图理解下面的代码:12345def node._get_child_candidates(self, distance, min_dist, max_dist): if self._leftchild and distance - max_dist &lt; self._median: yield self._leftchild if self._rightchild and distance + max_dist &gt;= self._median: yield self._rightchild 下面的是调用:12345678result, candidates = list(), [self]while candidates: node = candidates.pop() distance = node._get_dist(obj) if distance &lt;= max_dist and distance &gt;= min_dist: result.extend(node._values) candidates.extend(node._get_child_candidates(distance, min_dist, max_dist))return result 当调用 _get_child_candidates的时候发生了什么？返回了一个列表？返回了一个元素？被重复调用了么？ 什么时候这个调用结束呢？ 2.回答部分为了理解什么是 yield,你必须理解什么是生成器。在理解生成器之前，让我们先走近迭代。 3.可迭代对象当你建立了一个列表，你可以逐项地读取这个列表，这叫做一个可迭代对象:123456&gt;&gt;&gt; mylist = [1, 2, 3]&gt;&gt;&gt; for i in mylist :... print(i)123 mylist是一个可迭代的对象。当你使用一个列表生成式来建立一个列表的时候，就建立了一个可迭代的对象: 123456&gt;&gt;&gt; mylist = [x*x for x in range(3)]&gt;&gt;&gt; for i in mylist :... print(i)014 所有你可以使用 for .. in .. 语法的叫做一个迭代器：列表，字符串，文件……你经常使用它们是因为你可以如你所愿的读取其中的元素，但是你把所有的值都存储到了内存中，如果你有大量数据的话这个方式并不是你想要的。 4.生成器生成器是可以迭代的，但是你 只可以读取它一次 ，因为它并不把所有的值放在内存中，它是实时地生成数据：123456&gt;&gt;&gt; mygenerator = (x*x for x in range(3))&gt;&gt;&gt; for i in mygenerator :... print(i)014 看起来除了把 [] 换成 () 外没什么不同。但是，你不可以再次使用 for i inmygenerator , 因为生成器只能被迭代一次：先计算出0，然后继续计算1，然后计算4，一个跟一个的… 5.yield关键字yield 是一个类似 return 的关键字，只是这个函数返回的是个生成器。1234567891011121314&gt;&gt;&gt; def createGenerator() :... mylist = range(3)... for i in mylist :... yield i*i...&gt;&gt;&gt; mygenerator = createGenerator() # create a generator&gt;&gt;&gt; print(mygenerator) # mygenerator is an object!&lt;generator object createGenerator at 0xb7555c34&gt;&gt;&gt;&gt; for i in mygenerator:... print(i)014 这个例子没什么用途，但是它让你知道，这个函数会返回一大批你只需要读一次的值.为了精通 yield ,你必须要理解：当你调用这个函数的时候，函数内部的代码并不立马执行 ，这个函数只是返回一个生成器对象，这有点蹊跷不是吗。 那么，函数内的代码什么时候执行呢？当你使用for进行迭代的时候. 现在到了关键点了！ 第一次迭代中你的函数会执行，从开始到达 yield 关键字，然后返回 yield 后的值作为第一次迭代的返回值. 然后，每次执行这个函数都会继续执行你在函数内部定义的那个循环的下一次，再返回那个值，直到没有可以返回的。 如果生成器内部没有定义 yield 关键字，那么这个生成器被认为成空的。这种情况可能因为是循环进行没了，或者是没有满足 if/else 条件。]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程学习]]></title>
    <url>%2Fblog%2F8f0f2355.html</url>
    <content type="text"><![CDATA[不可变对象可以在没有额外同步的情况下，安全地用于任意线程；甚至发布它们时亦不需要同步。 安全发布的模式：如果一个对象是可变的，它就必须被安全地发布，通常发布线程与消费线程都必须同步化。如何确保消费线程能够看到处于发布当时的对象状态，我们要解决对象发布后对其修改的可见性问题。 为了安全地发布对象，对象的引用以及对象的状态必须同时对其他线程可见。一个正确创建的对象可以通过下列条件安全地发布： 通过静态初始化器初始化对象的引用； 将它的引用存储到 volatile域或 AtomicReference； 将它的引用存储到正确创建的对象的final域中； 或者将它的引用存储到由锁正确保护的域中。 线程安全库中的容器提供了如下的线程安全保证： 置入Hashtable、synchronizedMap、ConcurrentMap 中的主键以及健值，会安全地发布到可以从Map获得它们的任意线程中，无论是直接获得还是通过迭代器（iterator）获得： 置入vector、CopyOnWriteArrayList、CopyOnWriteArraySet、synchronizedList或者synchronizedSet中的元素，会安全地发布到可以从容器中获得它的任意线程中。 置入BlockingQueue 或者 ConcurrentLinkedQueue 的元素，会安全地发布到可以从队列中获得它的任意线程中。 12//静态初始化器示例：public static Holder holder = new Holder(42); 发布对象的必要条件依赖于对象的可变性： 不可变对象可以通过任意机制发布； 高效不可变对象必须要安全发布； 可变对象必须要安全发布，同时必须要线程安全或者被锁保护。 安全地共享对象在并发程序中，使用共享对象的一些最有效的策略如下： 线程限制：一个线程限制的对象，通过限制在现场中，而被线程独占，且只能被占有它的线程修改。 共享只读（share read-only）：一个共享的只读对象，在没有额外同步的情况下，可以被多个线程并发地访问，但是任何线程都不能修改它。共享只读对象包括可变对象与高效不可变对象。 共享线程安全（shared thread-safe）：一个线程安全的对象在内部进行同步，所以其他线程无须额外同步，就可以通过公共接口随意地访问它。 被守护的（Guarded）：一个被守护的对象只能通过特定的锁来访问。被守护的对象包括那些被线程安全对象封装的对象，和已知被特定的锁保护起来的已发布对象。 将数据封装在对象内部，把对数据的访问限制在对象的方法上，更易确保线程在访问数据时总能获得正确的 锁。]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Java线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java线程学习]]></title>
    <url>%2Fblog%2Fb44589cd.html</url>
    <content type="text"><![CDATA[Java创建一个线程，最简单的方法就是从Thread类继承。这个类包含了创建和运行线程所需的一切东西。Tread最重要的方法是run()。但为了使用run()，必须对其进行重载或者覆盖，使其能充分按自己的吩咐形式。因此，run()属于那些会与程序中的其他线程“并发”或“同时”执行代码。1234567//simpleThread.javapublic class SimpleThread extends Thread &#123; ...... public void run()&#123; // do something ...... &#125;&#125; Thread包含一个特殊的方法 start()，它的作用是对线程进行特殊的初始化，然后调用 run() 。所以整个步骤包括：调用构建器来构建对象，然后用 start() 配置线程，再调用 run() 。如果不调用 start()，线程便永远不会启动。 Java操作共享资源时，为了保证共享资源信息数据一致性，在调用共享资源的方法使用，需要采用“同步”方式操作，即调用”synchronized”方法。调用任何synchronized方法时，对象就会被锁定，不可再调用那个对象的其它任何synchronized方法，除非第一个方法完成了自己的工作，并解除锁定。下面列出简单的synchronized的方法：1234567synchronized void f()&#123; // do something ...... &#125; synchronized void g()&#123; // do something ...... &#125; 重要规则：对于访问某个关键共享资源的所有方法，都必须把它们设为synchronized，否则就不能正常地工作。 一个线程的四个状态： 新（New）：线程对象已经创建，但尚未启动，所以不可运行。 可运行（Runnable）：意味着一旦时机分片机制有空闲的CPU周期提供给一个线程，那个线程便立即开始运行。因此，线程可能在、也可能不在运行当中，但一旦条件许可，没有什么能阻止他的运行——它既没有“死”掉，也未被“堵塞”。 死（Dead）：从自己的run()方法中返回后，一个线程便已“死”掉。亦可调用stop()令其死掉，但会产生一个违例——属于Error的一个子类（也就是说，我们通常不捕获它）。记住一个违例的“掷”出应当是一个特殊事件，而不是正常程序运行的一部分。所以不建议你使用stop()（在Java 1.2 则是坚决反对）。另外还有一个destroy()方法（它永远不会实现），应该尽可能地避免调用它，因为它非常武断，根本不会解除对象的锁定。 堵塞（Blocked）：线程可以运行，但有某种东西阻碍了它。若线程处于堵塞状态，调度机制可以简单地跳过它，不给它分配任何CPU 时间。除非线程再次进入“可运行”状态，否则不会采取任何操作。 线程为何会堵塞？堵塞状态是前述四种状态中最有趣的，值得我们作进一步的探讨。线程被堵塞可能是由下述五方面的原因造成的：1.调用sleep(毫秒数)，使线程进入“睡眠”状态。在规定的时间内，这个线程是不会运行的。2.用suspend()暂停了线程的执行。除非线程收到resume()消息，否则不会返回“可运行”状态。3.用wait()暂停了线程的执行。除非线程收到nofify()或者notifyAll()消息，否则不会变成“可运行”（是的，这看起来同原因2 非常相象，但有一个明显的区别是我们马上要揭示的）。4.线程正在等候一些IO（输入输出）操作完成。5.线程试图调用另一个对象的“同步”方法，但那个对象处于锁定状态，暂时无法使用。 亦可调用yield()（Thread 类的一个方法）自动放弃CPU，以便其他线程能够运行。 死锁由于线程可能进入堵塞状态，而且由于对象可能拥有“同步”方法——除非同步锁定被解除，否则线程不能访问那个对象——所以一个线程完全可能等候另一个对象，而另一个对象又在等候下一个对象，以此类推。这个“等候”链最可怕的情形就是进入封闭状态——最后那个对象等候的是第一个对象！此时，所有线程都会陷入无休止的相互等待状态，大家都动弹不得。我们将这种情况称为“死锁”。 为减少出现死锁的可能，Java 1.2 作出的一项贡献是“反对”使用Thread 的stop()，suspend()，resume() 以及destroy()方法。suspend()和resume() 方法天生容易发生死锁。调用suspend()的时候，目标线程会停下来，但却仍然持有在这之前获得的锁定。此时，其他任何线程都不能访问锁定的资源，除非被“挂起”的线程恢复运行。 推荐：使用wait()命其进入等待状态。若标志指出线程应当恢复，则用一个notify()重新启动线程。 线程安全性：当多个线程访问一个类时，如果不用考虑这些线程在运行时环境下的调度和交替执行，并且不需要额外的同步及在调用方代码不必做其他的协调，这个类的行为仍然是正确的，那么称这个类是线程安全的。对于线程安全类的实例进行顺序或并发的一系列操作，都不会导致实例处于无效状态。 无状态对象永远是现场安全的。 原子变量线程安全性定义要求无论是多线程中的时序或交替操作，都要保证不破坏那些不变约束。当一个不变约束涉及多个变量时，变量间不是彼此独立的：某个变量的值会制约其他几个变量的值。因此，更新一个变量的时候，要在同一原子操作中更新其他几个。 为了保护状态的一致性，要在单一的原子操作中更新相互关联的状态变量。 加锁]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发注解Annotation]]></title>
    <url>%2Fblog%2F7e897a5b.html</url>
    <content type="text"><![CDATA[Java并发编程中，用到了一些专门为并发编程准备的 Annotation。主要包括三类：1、类 Annotation（注解）就像名字一样，这些注解是针对类的。主有要以下三个：@Immutable@ThreadSafe@NotThreadSafe @ThreadSafe 是表示这个类是线程安全的。具体是否真安全，那要看实现者怎么实现的了，反正打上这个标签只是表示一下。不线程安全的类打上这个注解也没事儿。@Immutable 表示，类是不可变的，包含了 @ThreadSafe 的意思。 @NotThreadSafe 表示这个类不是线程安全的。如果是线程安全的非要打上这个注解，那也不会报错。 这三个注解，对用户和维护者是有益的，用户可以立即看出来这个类是否是线程安全的，维护者则是可以根据这个注解，重点检查线程安全方面。另外，代码分析工具可能会利用这个注解。 2、域 Annotation（注解）域注解是对类里面成员变量加的注解。 3、方法 Annotation（注解）方法注解是对类里面方法加的注解。 域注解和方法注解都是用@GuardedBy( lock )来标识。里面的Lock是告诉维护者：这个状态变量，这个方法被哪个锁保护着。这样可以强烈的提示类的维护者注意这里。@GuardedBy( lock )有以下几种使用形式：1、@GuardedBy( “this” ) 受对象内部锁保护2、@GuardedBy( “fieldName” ) 受 与fieldName引用相关联的锁 保护。3、@GuardedBy( “ClassName.fieldName” ) 受 一个类的静态field的锁 保存。4、@GuardedBy( “methodName()” ) 锁对象是 methodName() 方法的返值，受这个锁保护。5、@GuardedBy( “ClassName.class” ) 受 ClassName类的直接锁对象保护。而不是这个类的某个实例的锁对象。]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 容器学习]]></title>
    <url>%2Fblog%2F6956966a.html</url>
    <content type="text"><![CDATA[Set实现Set接口包括 HashSet, TreeSet, LinkedHashSet 。在没有其它限制的情况下，建议使用HashSet，因为它对速度/效率进行了优化。 Set (interface) ： 存入Set的每个元素都必须是唯一性，因为Set不保存重复元素。加入Set的元素必须定义equals()方法以确保对象的唯一性。Set与Collection有完全一样的接口。Set接口不保证维护元素的次序。 HashSet * ： 为了快速查找而设计的Set。 存入HashSet的元素必须定义hashCode()方法。 TreeSet ： 保持次序的Set，底层为树结构。使用它可以从Set中提取有序的序列。元素必须实现Comparable接口。 LinkedHashSet： 具有HashSet的查询速度，且内部使用链表维护元素的的顺序（插入的次序）。于是在使用迭代器遍历Set时，结果会按元素插入的次序显示。元素必须定义hashCode()方法。 对于良好的编程风格而言，你应该覆盖equals()方法时，总是覆盖hashCode()方法。 队列 Queue除了并发应用，Queue在Java SE5中仅有的两个实现是LinkedList和PriorityQueue，它们的差异在于排序行为而不是性能。 LinkedList双向队列（双端队列），就像是一个队列，但是你可以在任何一端添加和移除元素。在LinkedList 中包含支持双向队列的方法。 Map HashMap * ： Map基于散列表的实现（它取代了Hashtable）。插入和查询“键值对”的开销是固定的。可以通过构造器设置容量和负载因子，以调整容器的性能。 LinkedHashMap ： 类似于HashMap，但是迭代遍历它时，取得“键值对”的顺序是其插入次序，或者是最近少使用（LRU）的次序。只比HashMap慢一点；而在迭代访问时反而速度更快，因为它使用链表维护内部次序。 TreeMap ： 基于红黑树的实现。查看“键”或“键值对”时，它们会被排序（次序由Comparable或Comparator决定）。TreeMap的特定在于，所得到的结果是经过排序的。TreeMap是唯一的带有subMap()方法的Map，它可以返回一个子树。 WeakHashMap： 弱键（weak key）映射，允许释放映射所指向的对象；这是为解决某些特殊问题而设计的。如果映射之外没有引用指向某个“键”，则此“键”可以被垃圾收集器回收。 ConcurrentHashMap： 一种线程安全的Map，它不涉及同步加锁。 IdentityHashMap： 使用==代替equals()对“键”进行比较的散列映射。专为解决特殊问题而设计的。 对Map中使用的键值要求与Set中的元素要求一致。任何键都必须具有一个equals()方法，如果键被用于散列Map，那么它必须还具有恰当的hashCode()方法；如果键被用于TreeMap，那么它必须实现Comparable。 Java 数组的效率比ArrayList效率高]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Comparable 和 Comparator比较]]></title>
    <url>%2Fblog%2Fae6b923.html</url>
    <content type="text"><![CDATA[对集合或数组进行排序有两种方法：1.集合中的对象所属的类实现了java.lang.Comparable 接口，然后调用Collections.sort()或者Arrays.sort()2.实现java.lang.Comparator接口，把这个实现接口的类作为参数传递给上述的sort()方法。 1、Comparable java.lang Interface Comparable属于Java集合框架下的一个接口。它只有一个方法 int compareTo(T o) 用于提供排序所需要的比较逻辑。实现这个接口的类，其对象都可以通过调用Collections.sort()或者Arrays.sort()进行排序，根据compareTo的逻辑升序排列。1234567891011121314151617class Person implements Comparable&lt;Person&gt;&#123; String name; public Person(String name) &#123; this.name = name; &#125; public int compareTo(Person other) &#123; //按名字的字母顺序从z~a排 if(name.compareTo(other.name) &lt; 0) //当前的字符串，在比较字符串之前，那就返回1 return 1; else if(name.compareTo(other.name) &gt; 0) return -1; else return 0; &#125;&#125; 2、再来看Comparator java.util Interface Comparator简单来说，Comparator是策略模式的一种实现，体现了将类和排序算法相分离的原则。12345678class ComparatorImp implements Comparator&lt;Person&gt;&#123; public int compare(Person p1, Person p2) &#123; if(p1.name.compareTo(p2.name) &lt; 0) return -1; else return (p1.name.compareTo(p2.name) &gt; 0) ? 1 : 0; &#125;&#125; 测试12345678910111213141516171819202122232425262728293031public class TestComparable &#123; public static void main(String[] args) &#123; Person[] aPersons = new Person[4]; aPersons[0] = new Person(&quot;Jony&quot;); aPersons[1] = new Person(&quot;Pun&quot;); aPersons[2] = new Person(&quot;HelloKitty&quot;); aPersons[3] = new Person(&quot;Brown&quot;); Arrays.sort(aPersons); for(Person p: aPersons ) &#123; System.out.print(p.name + &quot; &quot;); &#125; System.out.println(); Arrays.sort(aPersons, new ComparatorImp()); for(Person p: aPersons ) &#123; System.out.print(p.name + &quot; &quot;); &#125; System.out.println(); List&lt;Person&gt; lperson = new LinkedList&lt;Person&gt;(); for(Person p : aPersons) &#123; lperson.add(p); &#125; Collections.sort(lperson); for(int i = 0 ; i &lt; lperson.size(); i++) &#123; System.out.print(lperson.get(i).name+ &quot; &quot;); &#125; &#125;&#125;]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>http协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python学习笔记]]></title>
    <url>%2Fblog%2F743c31e9.html</url>
    <content type="text"><![CDATA[python类支持多重继承，当使用多重继承时，需要注意： 如果一个方法从多个超类继承（也就是说你有两个具有相同名字的不同方法），那么必须要注意一下超类的顺序（在class语句中）：先继承的类中的方法会重写后继承的类中的方法。 python魔法方法，就是在方法名前后加双下划线“__”，例如:123class FooBar: def __init__(self, value = 42): self.somevar = value 注意：Python中有一个魔法方法叫做”__del“，也就是析构方法。它在对象就要被垃圾回收之前调用。但发生调用的具体时间是不可知的。所以建议读者尽力避免使用”\del__”函数。 Python中类的继承，如果一个子类直接重写了构造器的方法，这将恢复完全覆盖了在超类中构造器方法的作用。如果要想保留超类构造器方法的作用：调用超类构造方法的未绑定版本，或者使用 super函数。__init__ 方法为一个类创建后第一个执行的方法。什么是self ？ 它是类实例自身的引用。其它面向对象语言通常使用一个名为 this 的标识符。12345678910111213141516class SongBird(Bird): def __init__(self): Bird.__init__(self) # 调用超类构造器方法 self.sound = &apos;Squawk !&apos; def sing(self): print self.sound__metaclass__ = type class SongBird(Bird): def __init__(self): super(SongBird.self).__init__() # super函数只在新式类中起作用 self.sound = &apos;Squawk !&apos; def sing(self): print self.sound 解决python文件显示中文build错误问题： 需要在程序的第一行或者第二行声明编码，就可以解决问题。1# coding =encoding name 或者 # -*- coding: -*- 下面的链接是原文地址 http://www.python.org/dev/peps/pep-0263/ raw_input ，python3.0版本后用input替换了raw_input python编程时，每一行语句结束时直接换行，不需要像C，Java那样用“；”结尾；但是同一行书写多个预计时，可以用“ ; “分割 注意：在python语言中，赋值并不是直接将一个值赋给一个变量，对象是通过引用传递的。 python不支持类似 x++ 或 –x 这样的前置/后置自增/自减运算。 专用下划线标识符：123_xxx #不用 &apos; from module import * &apos; 导入_xxx_ #系统定义名字_xxx #类中的私有变量名 核心风格建议：避免用下划线作为变量名的开始，因为下划线对解释器有特殊的意义，而且是内建标识符所使用的符号，我们建议程序员避免用下划线作为变量名的开始。一般来讲，变量名 _xxx 被看做是“私有的”，在模块或类外都不可以使用。当变量是私有的时候，用_xxx来表示变量是很好的习惯。因为变量或类外不可以使用。当变量是私有的时候，用_xxx来表示变量是很好的习惯。因为变量名__xxx__对python来说有特殊含义，对于普通的变量应当避免这种命名风格。 python 变量量无需事先声明，也无需声明类型。 提醒：print语句默认在输出内容末尾后加一个换行符，而在语句后加一个“逗号”可以避免这个新闻。]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Effective Java 随笔（异常）]]></title>
    <url>%2Fblog%2Fbeb8e864.html</url>
    <content type="text"><![CDATA[异常第57条：只针对异常的情况使用异常 Java程序设计的时候，只针对有异常的情况，才考了使用异常。实际上，基于异常的模式比标准模式要慢很多。异常是为了在异常情况下使用而设计的，不要将它们用于普通的控制流。123456try&#123; //do someting ......&#125;catch(Exception ex)&#123; ......&#125; 第58条：对可恢复的情况使用受检异常，对变成错误使用允许时异常 Java程序设计语言提供了三种可抛出结构（throwable）：受检异常（checked exception）、运行时异常（run-time exception）和错误（error）。使用原则：如果期望调用者能够适当地恢复，对于这种情况就应该使用受检的异常通过抛出受检的异常，强迫调用者在一个catch子句中处理异常，或者将它传播出去。因此，方法中声明要抛出的每个受检的异常，都是对API用户的一种潜在提示：与异常相关的条件是调用这个方法的一种可能的结果。 并发第66条：同步访问共享的可变数据 当多个线程共享可变数据的时候，每个读或者写数据的线程都必须执行同步。]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Effective Java 随笔（内部类、泛型、方法……）]]></title>
    <url>%2Fblog%2F9c616f22.html</url>
    <content type="text"><![CDATA[第22条：优先考虑静态成员类 Java程序中共有四种不同的嵌套类，每一种都有自己的用途。如果一个嵌套类需要在单个方法之外仍然是可见的，或者它太长了，不适合于放在方法内部，就应该使用成员类。如果成员类的每个实例都需要一个指向其外围实例的引用，就要把成员类做成非静态的；否则，就做成静态的。假设这个嵌套类属于一个方法的内部，如果你只需要在一个地方创建实例，并且已经有了一个预置的类似可以说吗这个类的特征，就要把它做成匿名类；否则，就做成局部类。 泛型第23条：请不要在新代码中使用原生态类型 Java 1.5之后支持泛型，建议在代码中不要使用原生态类型。如果使用原生态类型，就失掉了泛型在安全性和表述性方面的所有优势。，例如：12345//不建议这样定义Listprivate List list ;//支持泛型的对象，建议如下定义private List&lt;String&gt; list; 第30条：用enum代替int常量 在编程语言中还没有引入枚举类型之前，表示枚举类型的常用模式是声明一组具名的int常量，每个类型成员一个常量：12345678// The int enum pattern - severely dificient !public static final int APPLE_FUJI = 0;public static final int APPLE_PIPPIN =1......public static final int ORANGE_NAVEL = 0;public static final int ORANGE_TEMPLE =1;...... 这种方法称作int枚举模式，存在诸多不足。它在类型安全性和使用方便性方面没有任何帮组。如果将apple传到想要的orange的方法中，编译器也不会出现警告。建议在诸如类似常量定义时，考虑使用 enum type。 方法**第38条：检查参数的有效性 每当编写方法或者构造器的时候，应该考虑它的参数有哪些限制。应该把这些限制写到文档中，并且在方法体的开头处，通过显示的简称来实施这些限制。例如：123456789101112131415/** * Returns a BigInteger whose value is (this mod m). This method * differs form the remainder method in that it always returns a * non-negative BigInteger * * @param m the modeulus, thich must be positive * @return this mod m * @throws ArithmeticException if m is less than or equal to 0 */public BigInteger mod(BigInteger m)&#123; if(m.signum() &lt;= 0) throw new ArithmeticException(&quot;Modulus &lt;= 0 : &quot; + m ); ...... // Do the computation&#125; 通用程序设计第49条：基本类型优先于装箱基本类型（基本类型的包装类）1.什么时候应该使用装箱基本类型呢？ 第一是作为集合中的元素、健和值。你不能将基本类型放在集合中，因此必须使用装箱基本类型。这是一种更通用的特例。在参数化类型中，必须使用装箱基本类型作为类型参数，因为Java不能运行使用基本类型。 基本类型性能优于装箱基本类型，总之，当可以选择的时候，基本类型要优先于装箱基本类型。 第52条：通过接口引用对象 应该优先使用接口而不是类的引用对象。如果有合适的接口类型存在，那么对于参数、返回值、变量或域来说，就都应该使用接口类型进行声明。例如：12345//Good - user interface as typeList&lt;Subscriber&gt; subscribers = new ArrayList&lt;Subscriber&gt;();//Bad - user class as typeArrayList&lt;Subscriber&gt; subscribers = new ArrayList&lt;Subscriber&gt;(); 如果没有合适的接口存在，完全可以用类而不是接口来引用对象。（建议使用类层次接口中提供了必要功能的最基础的类）]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Effective Java 随笔：复合优于继承]]></title>
    <url>%2Fblog%2F84d15982.html</url>
    <content type="text"><![CDATA[第16条：复合优于继承 只有当子类真正是超类的子类型（subtype）时，才适合用继承。换句话说，对于两个类A和B，只有当两者之间确实存在“is-a”关系的时候，类B才应该扩展类A。如果你打算让类B扩展类A，就应该问问之间：每个B确实也是A吗？如果你不能确定这个问题的答案是肯定的，那么B就不应该扩展A。如果答案是否定的，通常情况下，B应该包含A的一个私有实例，并且暴露一个较小的、较简单的API：A本质上不是B的一部分，只是它的实现细节而已。 第17条：要么为继承而设计，并提供文档说明，要么就禁止继承 专门为继承而设计，就需要具有良好的文档说明。该类的文档必须精确地描述覆盖每个方法所带来的影响，换句话说，该类必须有文档说明它可覆盖（overridable）的方法的自用性（self-use）。 为了允许继承，类还必须遵守其他一些约束。构造器决不能调用可被覆盖的方法，无论是直接调用还是间接调用。如果违反了这条规则，很有可能导致程序失败。 如果你决定在一个为了继承而设计的类中实现了Cloneable或者Serializable接口，就应该意识到，因为clone和readObject方法在行为非常类似于构造器，所以类似的限制规则也是适合用的：无论是clone还是readObject，都不可以调用覆盖的方法，不管是以直接还是间接的方式。对于readObject方法，覆盖版本的方法将在子类的状态被反序列化之前被允许；而对于clone方法，覆盖版本的方法则是在子类的clone方法有机会修正被克隆对象中的状态之前被允许。无论哪种情形，都不可避免将导致程序失败。]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[虚拟机中 suse linux 11配置静态IP]]></title>
    <url>%2Fblog%2Fdec0d98a.html</url>
    <content type="text"><![CDATA[环境：VMware Workstation Pro 12 + Suse linux 11 SP1 第一步：配置虚拟机网络适配器，这里我采用 NAT 方式 第二步：在VMware虚拟网络编辑器中，配置NAT模式下的子网IP 第三步：在Suse linux 中通过界面配置静态IP 1、全局设置 2、IP设置 注意：配置静态IP是，IP网段要与网络虚拟机配置的网段一致。 3、配置DNS 4、配置网关（网关配置需要与虚拟机的虚拟网络配置的网关一致）]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>虚拟机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【转】应用性能监控方法一览]]></title>
    <url>%2Fblog%2Ffbaf30a5.html</url>
    <content type="text"><![CDATA[转自http://www.infoq.com/cn/news/2015/08/monitoring-applications-category 在基于云的服务中，正常运行时间应该是最为重要的运维指标之一。服务如果频繁地中断，不仅会导致正常使用的中断，还会对品牌带来负面影响。99.9%或99.99%已经算不上高水准的高可用性了，用户期望的是100%的可用性。为了达到这一点，我们不仅需要遵循良好的设计模式并保持服务的可扩展性，同时还要保证硬件、应用服务器以及数据库服务器的健康运行。近日，来自Zephyr的CTO Shailesh Mangal撰文总结了各种监控类型以及所需的工具。Zephyr致力于为开发和QA团队提供解决方案，帮助交付高质量的软件，他们所提供的企业级测试管理产品能够与各种工具集成，实现测试的实时管理。在Shailesh Mangal的文章中，他总结了核心基础设施监控、应用级别监控、微服务监控以及多租户日志监控的工具以及各自的指标，为我们进行应用的全方位监控提供了指导。 核心基础设施监控（Core Infrastructure Monitoring**，CIM**） 在目前的云基础设施中，出现硬件故障是难以避免的。核心基础设施监控会探测硬件瓶颈相关的早期迹象并捕获硬件故障信号，在出现更大的问题之前对其进行应对。基础设施监控的范围包括机器的健康状况、CPU使用、内存消耗以及网络带宽，基于这些监控信息，能够判断基础设施的当前状态，从而进行必要的扩展。有众多的工具都能帮助我们获取硬件的健康状态。在大多数情况下，托管提供商（如Amazon AWS、Heroku）的工具基本上就能满足这种监控的需要。 CIM的指标包括： CPU的平均使用率 CPU峰值的持续时间 内存的平均使用情况 带宽的输入输出情况 应用级别监控（Application Level Monitoring**，ALM**） 应用级别的监控涉及到监控各种服务器的状态，如数据库服务器、应用服务器、分析服务器以及Hadoop集群，而要监控的参数则是与应用或工具相关的。应用监控方面有不少伟大的工具，如Datadog和New Relic。 应用监控的指标包括： JVM进程的内存 内部线程的数量 磁盘IO 索引的读取/写入操作 微服务监控（Micro Service Monitoring**，MSM**） 微服务是现代云架构的组成部分，是实现水平扩展的关键。不管你运行的是传统的单块系统还是设计良好且组织精密的微服务，这些系统都会有不同的API端点，遵循不同的协议，满足不同的SLA需求。微服务监控就是要监控每个服务的吞吐量和性能，进而确保在任何时间都能满足SLA的需求。这种类型的监控一般都需要对应用进行instrument操作，让instrumentation是可配置的，通过收集器（collector）收集应用的状态，并阶段性地将这些状态发送到永久存储、分析器和预警系统中。此类监控往往会产生大量的数据，因此有可能会影响到性能，因此需要仔细设计。微服务监控的工具方面，存储引擎可以选择GraphiteDB或InfluxDB，可视化工具可以选择Kibana或Grafana。 微服务监控的指标包括： 请求所需的最大时间 请求所需的平均时间 每分钟请求的平均速度 每天峰值的请求速度 多租户日志监控（Multitenant Log Monitoring**，MLM**） 对于多租户部署的系统来讲，很大的一个挑战就是监控日志并推断系统的内部情况，或者当出现问题时识别出根本的原因。无数的客户端会产生大量的日志，因此对于日志隔离来说，有唯一的标识（如tenantId）是第一步。除此之外，日志还需要根据请求分组，如果请求要跨多个服务时，这一点尤为重要，每个服务都产生一些日志信息将会有助于识别问题。多租户日志监控中有非常经典的工具，也就是ELK（Elasticsearch, Logstash, Kibana）技术栈。 多租户日志监控的指标包括： 每个租户的日志 每个请求的日志 每天总的错误数量 总而言之，好的监控要涉及到系统各个方面，从硬件、应用再到服务。如果需要构建多租户应用的话，使用配置恰当的ELK技术栈也有助于快速诊断问题。目前，随着云服务和移动应用的发展，在国内外APM（Application Performance Management）相关的服务得到了空前的关注，希望Shailesh Mangal的这篇文章能够帮助读者对该领域有一个宏观的了解和掌握。]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>运维</tag>
        <tag>运维监控</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java.lang.OutOfMemory总结分析]]></title>
    <url>%2Fblog%2F5018d17f.html</url>
    <content type="text"><![CDATA[在解决java内存溢出问题之前，需要对jvm（java虚拟机）的内存管理有一定的认识。jvm管理的内存大致包括三种不同类型的内存区域： Permanent Generation space（永久保存区域）：永久保存区域主要存放Class（类）和Meta的信息，Class第一次被Load的时候被放入PermGen space区域，Class需要存储的内容主要包括方法和静态属性 Heap space(堆区域)：堆区域用来存放Class的实例（即对象），对象需要存储的内容主要是非静态属性。每次用new创建一个对象实例后，对象实例存储在堆区域中，这部分空间也被jvm的垃圾回收机制管理。 Java Stacks(Java栈）：Java栈跟大多数编程语言包括汇编语言的栈功能相似，主要基本类型变量以及方法的输入输出参数。Java程序的每个线程中都有一个独立的堆栈。 容易发生内存溢出问题的内存空间包括：Permanent Generation space和Heap space。 第一种OutOfMemoryError： PermGen space 发生这种问题的原意是程序中使用了大量的jar或class，使java虚拟机装载类的空间不够，与Permanent Generation space有关。解决这类问题有以下两种办法：1. 增加Java虚拟机中的XX:PermSize和XX:MaxPermSize参数的大小，其中XX:PermSize是初始永久保存区域大小，XX:MaxPermSize是最大永久保存区域大小。 如针对tomcat6.0，在catalina.sh 或catalina.bat文件中一系列环境变量名说明结束处（大约在70行左右） 增加一行：1JAVA_OPTS=&quot; -XX:PermSize=64M -XX:MaxPermSize=128m&quot; 如果是windows服务器还可以在系统环境变量中设置。感觉用tomcat发布sprint+struts+hibernate架构的程序时很容易发生这种内存溢出错误。使用上述方法，我成功解决了部署ssh项目的tomcat服务器经常宕机的问题。 2. 清理应用程序中web-inf/lib下的jar。 如果tomcat部署了多个应用，很多应用都使用了相同的jar，可以将共同的jar移到tomcat共同的lib下，减少类的重复加载。这种方法是网上部分人推荐的，我没试过，但感觉减少不了太大的空间，最靠谱的还是第一种方法。 第二种OutOfMemoryError： Java heap space 发生这种问题的原因是java虚拟机创建的对象太多，在进行垃圾回收之间，虚拟机分配的到堆内存空间已经用满了，与Heap space有关。解决这类问题有两种思路：1. 检查程序，看是否有死循环或不必要地重复创建大量对象。找到原因后，修改程序和算法。2. 增加Java虚拟机中Xms（初始堆大小）和Xmx（最大堆大小）参数的大小。如：1set JAVA_OPTS= -Xms256m -Xmx1024m 第三种OutOfMemoryError：unable to create new native thread 这种错误在Java线程个数很多的情况下容易发生，我暂时还没遇到过，发生原意和解决办法可以参考： 从JVM层面去解决：减小thread stack的大小，JVM默认thread stack的大小为1024，这样当线程多时导致Native virtual memory被耗尽，实际上当thread stack的大小为128K 或 256K时是足够的，所以我们如果明确指定thread stack为128K 或 256K即可，具体使用-Xss，例如在JVM启动的JVM_OPT中添加如下配置：1-Xss128k 减小heap或permgen初始分配的大小：如果JVM启动的JVM_OPT中有如下配置 1-Xms1303m -Xmx1303m -XX:PermSize=256m -XX:MaxPermSize=256m 我们可以删除或减小初始化最小值的配置，如下12-Xms256m -Xmx1303m -XX:PermSize=64m -XX:MaxPermSize=256m -Xmx1303m -XX:MaxPermSize=256m 升级JVM到最新的版本：最新版本的JVM一般在内存优化方面做的更好，升级JVM到最新的版本可能会缓解测问题。 从操作系统层面去解决：使用64位操作系统，如果使用32位操作系统遇到unable to create new native thread，建议使用64位操作系统。 增大OS对线程的限制：在Linux操作系统设定nofile和nproc，具体编辑/etc/security/limits.conf添加如下：12soft nofile 2048 hard nofile 8192 12soft nproc 2048 hard nproc 8192 如果使用Red Hat Enterprise Linux 6，编辑/etc/security/limits.d/90-nproc.conf，添加如下配置：12345# cat /etc/security/limits.d/90-nproc.conf * soft nproc 1024 root soft nproc unlimited user - nproc 2048]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu下apt-get命令详解]]></title>
    <url>%2Fblog%2F90cf494a.html</url>
    <content type="text"><![CDATA[在Ubuntu下，apt-get近乎是最常用的shell命令之一了，因为他是Ubuntu通过新立得安装软件的常用工具命令。本文列举了常用的APT命令参数：apt-cache search package 搜索软件包 apt-cache show package 获取包的相关信息，如说明、大小、版本等 sudo apt-get install package 安装包 sudo apt-get install package –reinstall 重新安装包 sudo apt-get -f install 修复安装 sudo apt-get remove package 删除包 sudo apt-get remove package –purge 删除包，包括配置文件等 sudo apt-get update 更新源 sudo apt-get upgrade 更新已安装的包 sudo apt-get dist-upgrade 升级系统 apt-cache depends package 了解使用该包依赖那些包 apt-cache rdepends package 查看该包被哪些包依赖 sudo apt-get build-dep package 安装相关的编译环境 apt-get source package 下载该包的源代码 sudo apt-get clean &amp;&amp; sudo apt-get autoclean 清理无用的包 sudo apt-get check 检查是否有损坏的依赖]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux modprobe命令]]></title>
    <url>%2Fblog%2Fd6fabb9e.html</url>
    <content type="text"><![CDATA[Linux modprobe命令用于自动处理可载入模块。modprobe可载入指定的个别模块，或是载入一组相依的模块。modprobe会根据depmod所产生的相依关系，决定要载入哪些模块。若在载入过程中发生错误，在modprobe会卸载整组的模块。 语法1modprobe [-acdlrtvV][--help][模块文件][符号名称 = 符号值] 参数： -a或–all 载入全部的模块。 -c或–show-conf 显示所有模块的设置信息。 -d或–debug 使用排错模式。 -l或–list 显示可用的模块。 -r或–remove 模块闲置不用时，即自动卸载模块。 -t或–type 指定模块类型。 -v或–verbose 执行时显示详细的信息。 -V或–version 显示版本信息。 -help 显示帮助。 实例安装软驱模块：1[root@w3cschool.cc ~]# modprobe -v floppy 卸载软驱模块：1[root@w3cschool.cc ~]# modprobe -v -r floppy]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[索引失效]]></title>
    <url>%2Fblog%2F6df5e6f5.html</url>
    <content type="text"><![CDATA[在编写sql语句时，一般都会用到索引来提升sql性能，但是有些sql语句使用索引是不生效的。 is null 和 is not null： 在sql语句的条件中用上述表达式来作为条件执行sql时，条件中即便字段是创建索引了亦不会被使用而是用全表扫描。 连接符||： 在sql语句中使用连接符||来作为条件表达式时，如果连接连边有一个字段没有创建索引那么整个表达式将不会使用索引而是全表扫描。 使用like通配符%： 使用like时如果用“%xxx%”这种使用方式也会造成全变扫描，所建的索引字段也会被废弃。 orderby： 使用orderby时一定要注意后面所需排序的字段要是建了索引的，否则会大大降低sql执行效率。 not 和 &lt;&gt;： 在使用不等于时所创建的索引也将不会使用而是用全表扫描 对索引列进行运算.需要建立函数索引。 当变量采用的是times变量，而表的字段采用的是date变量时.或相反情况。 sql的书写规范也会影响sql语句执行效率： 要确保所写的sql语句格式统一，这样在调用的时候才会避免不必要的资源浪费。]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>索引</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[转]lombok 介绍及基本使用方法]]></title>
    <url>%2Fblog%2Fb4c12e03.html</url>
    <content type="text"><![CDATA[转自http://www.blogjava.net/fancydeepin/archive/2012/07/12/lombok.html 前言： 逛开源社区的时候无意发现的，用了一段时间，觉得还可以，特此推荐一下。 lombok 提供了简单的注解的形式来帮助我们简化消除一些必须有但显得很臃肿的 java 代码。特别是相对于 POJO，光说不做不是我的风格，先来看看吧。 lombok 的官方网址：http://projectlombok.org/ lombok 其实到这里我就介绍完了，开个玩笑，其实官网上有 lombok 三分四十九秒的视频讲解，里面讲的也很清楚了，而且还有文档可以参考。在这里我就不扯太多，先来看一下lombok 的安装，其实这个官网视频上也有讲到啦 lombok 安装 使用 lombok 是需要安装的，如果不安装，IDE 则无法解析 lombok 注解。先在官网下载最新版本的 JAR 包，现在是 0.11.2 版本，我用的是 0.11.0 第一次使用的时候我下载的是最新版本的，也就是我现在用的 0.11.0，到现在已经更新了两个版本，更新的好快啊 … … 1. 双击下载下来的 JAR 包安装 lombok 我选择这种方式安装的时候提示没有发现任何 IDE，所以我没安装成功，我是手动安装的。如果你想以这种方式安装，请参考官网的视频。 2.eclipse / myeclipse 手动安装 lombok 1. 将 lombok.jar 复制到 myeclipse.ini / eclipse.ini 所在的文件夹目录下 2. 打开 eclipse.ini / myeclipse.ini，在最后面插入以下两行并保存：12-Xbootclasspath/a:lombok.jar -javaagent:lombok.jar 3.重启 eclipse / myeclipse lombok 注解： lombok 提供的注解不多，可以参考官方视频的讲解和官方文档。 Lombok 注解在线帮助文档：http://projectlombok.org/features/index. 下面介绍几个我常用的 lombok 注解： @Data：注解在类上；提供类所有属性的 getting 和 setting 方法，此外还提供了equals、canEqual、hashCode、toString 方法@Setter：注解在属性上；为属性提供 setting 方法@Getter：注解在属性上；为属性提供 getting 方法@Log4j ：注解在类上；为类提供一个 属性名为log 的 log4j 日志对象@NoArgsConstructor：注解在类上；为类提供一个无参的构造方法@AllArgsConstructor：注解在类上；为类提供一个全参的构造方法 下面是简单示例：123456789@Data@Log4j@NoArgsConstructor@AllArgsConstructorpublic class Person &#123; private String id; private String name; private String identity; &#125;]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>lombok</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【转】谈谈我对服务熔断、服务降级的理解]]></title>
    <url>%2Fblog%2F246b112b.html</url>
    <content type="text"><![CDATA[本文摘自http://blog.csdn.net/guwei9111986/article/details/51649240 伴随着微服务架构被宣传得如火如荼，一些概念也被推到了我们面前（管你接受不接受），其实大多数概念以前就有，但很少被提的这么频繁（现在好像不提及都不好意思交流了）。想起有人总结的一句话，微服务架构的特点就是：“一解释就懂，一问就不知，一讨论就吵架”。 其实对老外的总结能力一直特别崇拜，Kevin Kelly、Martin Fowler、Werner Vogels……，都是著名的“演讲家”。正好这段时间看了些微服务、容器的相关资料，也在我们新一代产品中进行了部分实践，回过头来，再来谈谈对一些概念的理解。 今天先来说说“服务熔断”和“服务降级”。为什么要说这个呢，因为我很长时间里都把这两个概念同质化了，不知道这两个词大家怎么理解，一个意思or有所不同？现在的我是这么来看的： 在股票市场，熔断这个词大家都不陌生，是指当股指波幅达到某个点后，交易所为控制风险采取的暂停交易措施。相应的，服务熔断一般是指软件系统中，由于某些原因使得服务出现了过载现象，为防止造成整个系统故障，从而采用的一种保护措施，所以很多地方把熔断亦称为过载保护。 大家都见过女生旅行吧，大号的旅行箱是必备物，平常走走近处绰绰有余，但一旦出个远门，再大的箱子都白搭了，怎么办呢？常见的情景就是把物品拿出来分分堆，比了又比，最后一些非必需品的就忍痛放下了，等到下次箱子够用了，再带上用一用。而服务降级，就是这么回事，整体资源快不够了，忍痛将某些服务先关掉，待渡过难关，再开启回来。 所以从上述分析来看，两者其实从有些角度看是有一定的类似性的： 目的很一致，都是从可用性可靠性着想，为防止系统的整体缓慢甚至崩溃，采用的技术手段； 最终表现类似，对于两者来说，最终让用户体验到的是某些功能暂时不可达或不可用； 粒度一般都是服务级别，当然，业界也有不少更细粒度的做法，比如做到数据持久层（允许查询，不允许增删改）； 自治性要求很高，熔断模式一般都是服务基于策略的自动触发，降级虽说可人工干预，但在微服务架构下，完全靠人显然不可能，开关预置、配置中心都是必要手段； 而两者的区别也是明显的： 触发原因不太一样，服务熔断一般是某个服务（下游服务）故障引起，而服务降级一般是从整体负荷考虑； 管理目标的层次不太一样，熔断其实是一个框架级的处理，每个微服务都需要（无层级之分），而降级一般需要对业务有层级之分（比如降级一般是从最外围服务开始） 实现方式不太一样，这个区别后面会单独来说； 当然这只是我个人对两者的理解，外面把两者归为完全一致的也不在少数，或者把熔断机制理解为应对降级目标的一种实现也说的过去，可能“一讨论就吵架”也正是这个原因吧！概念算是说完了，避免空谈，我再总结下对常用的实现方法的理解。对于这两个概念，号称支持的框架可不少，Hystrix当属其中的佼佼者。先说说最裸的熔断器的设计思路，下面这张图大家应该不陌生（我只是参考着又画了画），简明扼要的给出了好的熔断器实现的三个状态机： Closed：熔断器关闭状态，调用失败次数积累，到了阈值（或一定比例）则启动熔断机制； Open：熔断器打开状态，此时对下游的调用都内部直接返回错误，不走网络，但设计了一个时钟选项，默认的时钟达到了一定时间（这个时间一般设置成平均故障处理时间，也就是MTTR），到了这个时间，进入半熔断状态； Half-Open：半熔断状态，允许定量的服务请求，如果调用都成功（或一定比例）则认为恢复了，关闭熔断器，否则认为还没好，又回到熔断器打开状态； 那Hystrix，作为Netflix开源框架中的最受喜爱组件之一，是怎么处理依赖隔离，实现熔断机制的呢，他的处理远比我上面说个实现机制复杂的多，一起来看看核心代码吧，我只保留了代码片段的关键部分： 12]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>服务熔断</tag>
        <tag>服务降级</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Effective Java 随笔——第2条：遇到多个构造器参数时要考虑用构建器]]></title>
    <url>%2Fblog%2Fb3a294b7.html</url>
    <content type="text"><![CDATA[静态工厂和构造器有一个共同的局限性：它们都不能很好地扩展到大量的可选参数。如果一个构造器的参数有10,11,12，…或更多时。一长串类型相同的参数会导致一些微妙的错误，如果不小心颠倒了其中两个参数的顺序，编译器也不会出错，但是程序在运行时会出现错误的行为。 遇到许多构造参数的时候，还有第二种代替办法，及JavaBean模式，在这种模式下调用一个无惨构造器来创建对象，调用setter方法来设置每个必要的参数，以及每个相关的可选参数。 Effective Java一书中提到：JavaBean模式自身有着很严重的缺点，因为构造过程分到了几个调用中，在构造过程中JavaBean可能处于不一致的状态。类无法仅仅通过检验构造器参数的有效性来保证一致性。视图使用处于不一致的对象，将会导致失败。这种失败与包含错误的代码大相径庭。与此相关的另一点不足在于，JavaBean模式阻止了把类做成不可变的可能，这就需要程序员付出额外的努力来确保它的线程是安全的。 附注：个人在使用中，还没有发现这个问题，如有了解的大神，还请不吝赐教。 最佳替代方法Builder模式，既能保证像重叠构造器模式那样的安全性，也能保证像JavaBean模式那么好的可读性。Builder模式，不直接生成想要的对象，而是让客户端在builder对象上调用类似于setter的方法，来深圳每个相关的可选参数。最后，客户端调用无参的builder方法生成不可变的对象。这个builder是它构建的类的静态成员类。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class NutritionFacts &#123; private final int servingSize; private final int servings; private final int calories; private final int fat; private final int sodium; private final int carbohydrate; public static class Builder &#123; // Required parameters private final int servingSize; private final int servings; // Optional parameters - initialized to default values private int calories = 0; private int fat = 0; private int carbohydrate = 0; private int sodium = 0; public Builder(int servingSize, int servings) &#123; this.servingSize = servingSize; this.servings = servings; &#125; public Builder calories(int val) &#123; calories = val; return this; &#125; public Builder fat(int val) &#123; fat = val; return this; &#125; public Builder carbohydrate(int val) &#123; carbohydrate = val; return this; &#125; public Builder sodium(int val) &#123; sodium = val; return this; &#125; public NutritionFacts build() &#123; return new NutritionFacts(this); &#125; &#125; private NutritionFacts(Builder builder) &#123; servingSize = builder.servingSize; servings = builder.servings; calories = builder.calories; fat = builder.fat; sodium = builder.sodium; carbohydrate = builder.carbohydrate; &#125; public static void main(String[] args) &#123; NutritionFacts cocaCola = new NutritionFacts.Builder(240, 8). calories(100).sodium(35).carbohydrate(27).build(); &#125;&#125; 此处Builder类作为一个静态内部类。我们最终要获得的是NutritionFacts对象，从他的构造函数可以看出，是通过builder对象来对他的属性进行初始化的。而builder对象的属性是通过多个setter方法设置的。]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Effective Java 随笔——第1条：使用静态工厂方法替代构造函数]]></title>
    <url>%2Fblog%2F1bb33093.html</url>
    <content type="text"><![CDATA[第1条：使用静态工厂方法替代构造函数 对于类而言，为了让客户端获取它自身的一个实例，最常用的方法就是提供一个公有的构造器，还有一种就是方法。类可以提供一个公有的静态工程方法(static factory method)，它只是一个返回类的实例的静态方法。1234567891011121314151617181920212223// 通过isMale字段标识性别class Person &#123; private bool isMale; // 不容易理解参数的含义 public Person(bool _isMale) &#123; this.isMale = isMale; &#125; &#125;// 采用静态工厂方法替代构造函数class Person &#123; private bool isMale; // 一目了然 public static Man() &#123; Persion p = new Persion(); p.isMale = true; return p; &#125; public static Woman() &#123; Persion p = new Persion(); p.isMale = false; return p; &#125;&#125; 静态工厂方法的优势： 静态工厂方法与构造器不同的第一大优势在于，它们有名称。 如果构造器的参数本身没有确切的描述正被返回的对象，那么具有适当名称的静态工厂会更容易使用，更易于阅读。 静态工厂方法与构造器不同的第二大优势在于，不必在每次调用它们的时候创建一个新的对象。 这使得不可变类可以使用预先构建好的实例，或者将构建好的实例缓存起来，进行重复利用，从而避免创建不必要的重复对象。（如果程序经常请求创建相同的对象，并且创建对象的代价很高，则这项技术可以极大地提升性能。） 静态工厂方法与构造器不同的第三大优势在于，它们可以返回原返回类型的任何子类型的对象。 这样我们在选择返回对象的类时就有了更大的灵活性。 静态工厂方法的第四大优势在于，在创建参数化类型实例的时候，它们使代码变得更加简洁。 静态工厂方法的缺点： 缺点1：类如果不含公有的或者受保护的构造器，就不能被子类化。 缺点2：它们与其他的静态方法实际上没有任何区别。]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【转】如何理解HTTP协议的“无连接，无状态”]]></title>
    <url>%2Fblog%2F9f001a67.html</url>
    <content type="text"><![CDATA[原文摘自：http://blog.csdn.net/tennysonsky/article/details/44562435 HTTP 是一个属于应用层的面向对象的协议，HTTP 协议一共有五大特点：1、支持客户/服务器模式；2、简单快速；3、灵活；4、无连接；5、无状态。 无连接无连接的含义是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。采用这种方式可以节省传输时间。 早期这么做的原因是 HTTP 协议产生于互联网，因此服务器需要处理同时面向全世界数十万、上百万客户端的网页访问，但每个客户端（即浏览器）与服务器之间交换数据的间歇性较大（即传输具有突发性、瞬时性），并且网页浏览的联想性、发散性导致两次传送的数据关联性很低，大部分通道实际上会很空闲、无端占用资源。因此 HTTP 的设计者有意利用这种特点将协议设计为请求时建连接、请求完释放连接，以尽快将资源释放出来服务其他客户端。 随着时间的推移，网页变得越来越复杂，里面可能嵌入了很多图片，这时候每次访问图片都需要建立一次 TCP 连接就显得很低效。后来，Keep-Alive 被提出用来解决这效率低的问题。 Keep-Alive 功能使客户端到服务器端的连接持续有效，当出现对服务器的后继请求时，Keep-Alive 功能避免了建立或者重新建立连接。市场上的大部分 Web 服务器，包括 iPlanet、IIS 和 Apache，都支持 HTTP Keep-Alive。对于提供静态内容的网站来说，这个功能通常很有用。但是，对于负担较重的网站来说，这里存在另外一个问题：虽然为客户保留打开的连接有一定的好处，但它同样影响了性能，因为在处理暂停期间，本来可以释放的资源仍旧被占用。当Web服务器和应用服务器在同一台机器上运行时，Keep-Alive 功能对资源利用的影响尤其突出。 这样一来，客户端和服务器之间的 HTTP 连接就会被保持，不会断开（超过 Keep-Alive 规定的时间，意外断电等情况除外），当客户端发送另外一个请求时，就使用这条已经建立的连接。 无状态无状态是指协议对于事务处理没有记忆能力，服务器不知道客户端是什么状态。即我们给服务器发送 HTTP 请求之后，服务器根据请求，会给我们发送数据过来，但是，发送完，不会记录任何信息。HTTP 是一个无状态协议，这意味着每个请求都是独立的，Keep-Alive 没能改变这个结果。缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次连接传送的数据量增大。另一方面，在服务器不需要先前信息时它的应答就较快。HTTP 协议这种特性有优点也有缺点，优点在于解放了服务器，每一次请求“点到为止”不会造成不必要连接占用，缺点在于每次请求会传输大量重复的内容信息。客户端与服务器进行动态交互的 Web 应用程序出现之后，HTTP 无状态的特性严重阻碍了这些应用程序的实现，毕竟交互是需要承前启后的，简单的购物车程序也要知道用户到底在之前选择了什么商品。于是，两种用于保持 HTTP 连接状态的技术就应运而生了，一个是 Cookie，而另一个则是 Session。 Cookie可以保持登录信息到用户下次与服务器的会话，换句话说，下次访问同一网站时，用户会发现不必输入用户名和密码就已经登录了（当然，不排除用户手工删除Cookie）。而还有一些Cookie在用户退出会话的时候就被删除了，这样可以有效保护个人隐私。Cookies 最典型的应用是判定注册用户是否已经登录网站，用户可能会得到提示，是否在下一次进入此网站时保留用户信息以便简化登录手续，这些都是 Cookies 的功用。另一个重要应用场合是“购物车”之类处理。用户可能会在一段时间内在同一家网站的不同页面中选择不同的商品，这些信息都会写入 Cookies，以便在最后付款时提取信息。 与 Cookie 相对的一个解决方案是 Session，它是通过服务器来保持状态的。当客户端访问服务器时，服务器根据需求设置 Session，将会话信息保存在服务器上，同时将标示 Session 的 SessionId 传递给客户端浏览器，浏览器将这个 SessionId 保存在内存中，我们称之为无过期时间的 Cookie。浏览器关闭后，这个 Cookie 就会被清掉，它不会存在于用户的 Cookie 临时文件。以后浏览器每次请求都会额外加上这个参数值，服务器会根据这个 SessionId，就能取得客户端的数据信息。如果客户端浏览器意外关闭，服务器保存的 Session 数据不是立即释放，此时数据还会存在，只要我们知道那个 SessionId，就可以继续通过请求获得此 Session 的信息，因为此时后台的 Session 还存在，当然我们可以设置一个 Session 超时时间，一旦超过规定时间没有客户端请求时，服务器就会清除对应 SessionId 的 Session 信息。]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>http协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[postgreSQL常用命令]]></title>
    <url>%2Fblog%2F7e4cc69e.html</url>
    <content type="text"><![CDATA[安装CentOS系统时，由于最开始没有选择安装Telnet服务，现在想从Windows上通过Telnet连接Linux。于是便只能重新安装，这里介绍从光盘中进行安装。1、首先进入mnt目录创建一个文件夹，用于挂载光驱；1234[root@localhost ~]# cd /mnt[root@localhost ~]# mkdir cdrom[root@localhost ~]# mount /dev/cdrom /mnt/cdrom (或者 mount -t ext3 /dev/cdrom /mnt/cdrom)[root@localhost ~]# cd /mnt/cdrom 2、安装Telnet需要安装xinetd服务12[root@localhost cdrom]# find -name xinetd*./Packages/xinetd-2.3.14-29.el6.x86_64.rpm[root@localhost cdrom]# rpm -ivh ./Packages/xinetd-2.3.14-29.el6.x86_64.rpm 3、安装Telnet服务123[root@localhost cdrom]# find -name telnet*./Packages/telnet-0.17-46.el6.x86_64.rpm./Packages/telnet-server-0.17-46.el6.x86_64.rpm[root@localhost cdrom]# rpm -ivh ./Packages/telnet-0.17-46.el6.x86_64.rpm[root@localhost cdrom]# rpm -ivh ./Packages/telnet-server-0.17-46.el6.x86_64.rpm 4、修改Telnet服务配置1[root@localhost cdrom]#vi /etc/xinetd.d 将disable = yes 更改 no，或者注释掉5.开放Telnet对外端口23。 6、重启xinetd服务1[root@localhost cdrom]#service xinetd restart OK，于是在windows中，便可以通过telnet方式连接 Linux系统]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>PostgreSQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JBoss 的端口设置修改(备忘)]]></title>
    <url>%2Fblog%2F3f166a67.html</url>
    <content type="text"><![CDATA[JBOSS默认的各种设置文件中通常定义了以下几个端口:1: The ports found in the default configuration Port Type Service123456789101112131415。1099 TCP org.jboss.naming.NamingService。1098 TCP org.jboss.naming.NamingService。1162 UDP org.jboss.jmx.adaptor.snmp.trapd.TrapdService。4444 TCP org.jboss.invocation.jrmp.server.JRMPInvoker。4445 TCP org.jboss.invocation.pooled.server.PooledInvoker。8009 TCP org.jboss.web.tomcat.tc4.EmbeddedTomcatService。8009 TCP org.jboss.web.tomcat.tc4.EmbeddedTomcatService。8083 TCP org.jboss.web.WebService。8090 TCP org.jboss.web.OILServerILService。8092 TCP org.jboss.mq.il.oil2.OIL2ServerILService。8093 TCP org.jboss.mq.il.uil2.UILServerILService。0a TCP org.jboss.mq.il.rmi.RMIServerILService。0b UDP org.jboss.jmx.adaptor.snmp.agent.SnmpAgentServicea, This service binds to an anonymous TCP port and does not support configuration of the port or bind interface currently(3.2.2).b, This service binds to an anonymous UDP port and does not support configuration of the port or bind interface.(3.2.2). 2: Additional ports found in the all configuration Port Type Service12345678。1100 TCP org.jboss.ha.jndi.HANamingService。0a TCP org.jboss.ha.jndi.HANamingService。1102 UDP org.jboss.ha.jndi.HANamingService。3528 TCP org.jboss.invocation.iiop.IIOPInvoker。45566b TCP org.jboss.ha.framework.server.ClusterPartitiona, Currently anonymous but can be set via the RmiPort attributeb, Plus two additional anonymous UDP ports, one can be set using the rcv_port, and the other cannot be seen。]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>Jboss</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AD用户帐户属性对照表]]></title>
    <url>%2Fblog%2Fd05e3939.html</url>
    <content type="text"><![CDATA[用户帐户属性对照表,一部分经常用到,免得到处找,列在下面参考参考:“常规”标签 姓 Sn名 Givename英文缩写 Initials显示名称 displayName描述 Description办公室 physicalDeliveryOfficeName电话号码 telephoneNumber电话号码：其它 otherTelephone 多个以英文分号分隔电子邮件 Mail网页 wWWHomePage网页：其它 url 多个以英文分号分隔 “地址”标签 国家/地区 C 如：中国CN，英国GB省/自治区 St市/县 L街道 streetAddress邮政信箱 postOfficeBox邮政编码 postalCode “帐户”标签 用户登录名 userPrincipalName 形如：pccai1983@hotmail.com用户登录名（以前版本） sAMAccountName 形如：S1登录时间 logonHours登录到 userWorkstations 多个以英文逗号分隔用户帐户控制 userAccountControl (启用：512，禁用：514， 密码永不过期：66048)帐户过期 accountExpires “配置文件”标签 配置文件路径 profilePath登录脚本 scriptPath主文件夹：本地路径 homeDirectory连接 homeDrive到 homeDirectory “电话”标签 家庭电话 homePhone (若是其它，在前面加other。)寻呼机 Pager 如：otherhomePhone。移动电话 mobile 若多个以英文分号分隔。传真 FacsimileTelephoneNumberIP电话 ipPhone注释 Info “单位”标签 职务 Title部门 Department公司 Company “隶属于”标签 隶属于 memberOf 用户组的DN不需使用引号， 多个用分号分隔“拨入”标签 远程访问权限（拨入或VPN） msNPAllowDialin允许访问 值：TRUE拒绝访问 值：FALSE回拨选项 msRADIUSServiceType由呼叫方设置或回拨到 值：4总是回拨到 msRADIUSCallbackNumber“环境”、“会话”、“远程控制”、“终端服务配置文件”、“COM+”标签 属性 显示名称 属性名称 First Name giveName last Name sn Initials initials Description description Office physicalDeliveryOfficeName Telephone Number telephoneNumber Telephone: Other otherTelephone E-Mail mail Web Page wwwHomePage Web Page : Other url]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>windows AD</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PostgreSQL在2003系统和Win7系统启动注意事项]]></title>
    <url>%2Fblog%2Fe09fa2d0.html</url>
    <content type="text"><![CDATA[PostgreSQL在2003和Win7系统注册成功后，但是无法启动数据库。解决办法是，修改修改pgsql\data目录下pg_hba.conf文件。 win2003 修改如下：12345# IPv4 local connections:host all all 127.0.0.1/32 trust#host all all ::1/128 trust# IPv6 local connections:#host all all ::1/128 trust win7修改如下：12345# IPv4 local connections:host all all 127.0.0.1/32 trusthost all all ::1/128 trust# IPv6 local connections:#host all all ::1/128 trust]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>PostgreSQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Oracle 11G在用EXP 导出时，空表不能导出问题解决]]></title>
    <url>%2Fblog%2Fee36d2a5.html</url>
    <content type="text"><![CDATA[11G中有个新特性，当表无数据时，不分配segment，以节省空间 解决方法：1、insert一行，再rollback就产生segment了。该方法是在在空表中插入数据，再删除，则产生segment。导出时则可导出空表。2、设置deferred_segment_creation 参数123456789101112show parameter deferred_segment_creationNAME TYPE VALUE---------------------------- ----------- ---------deferred_segment_creation boolean TRUESQL&gt; alter system set deferred_segment_creation=false;系统已更改。 SQL&gt; show parameter deferred_segment_creationNAME TYPE VALUE--------------------------------- ------------ ---------deferred_segment_creation boolean FALSE 该参数值默认是TRUE，当改为FALSE时，无论是空表还是非空表，都分配segment。 需注意的是：该值设置后对以前导入的空表不产生作用，仍不能导出，只能对后面新增的表产生作用。如需导出之前的空表，只能用第一种方法。搞了我好久，最后查到这个方法。先查询一下当前用户下的所有空表1select table_name from user_tables where NUM_ROWS=0; 用以下这句查找空表1select &apos;alter table &apos;||table_name||&apos; allocate extent;&apos; from user_tables where num_rows=0 把查询结果导出，执行导出的语句12345678910111213141516171819&apos;ALTERTABLE&apos;||TABLE_NAME||&apos;ALLOCATEEXTENT;&apos;-----------------------------------------------------------alter table AQ$_AQ$_MEM_MC_H allocate extent;alter table AQ$_AQ$_MEM_MC_G allocate extent;alter table AQ$_AQ$_MEM_MC_I allocate extent;alter table AQ$_AQ_PROP_TABLE_T allocate extent;alter table AQ$_AQ_PROP_TABLE_H allocate extent;alter table AQ$_AQ_PROP_TABLE_G allocate extent;alter table AQ$_AQ_PROP_TABLE_I allocate extent;alter table AQ$_KUPC$DATAPUMP_QUETAB_T allocate extent;alter table AQ$_KUPC$DATAPUMP_QUETAB_H allocate extent;alter table AQ$_KUPC$DATAPUMP_QUETAB_G allocate extent;alter table AQ$_KUPC$DATAPUMP_QUETAB_I allocate extent;&apos;ALTERTABLE&apos;||TABLE_NAME||&apos;ALLOCATEEXTENT;&apos;-----------------------------------------------------------alter table AQ$_SYS$SERVICE_METRICS_TAB_T allocate extent;alter table AQ$_SYS$SERVICE_METRICS_TAB_H allocate extent;alter table AQ$_SYS$SERVICE_METRICS_TAB_G allocate extent;alter table AQ$_SYS$SERVICE_METRICS_TAB_I allocate extent; 然后再执行1exp 用户名/密码@数据库名 file=/home/oracle/exp.dmp log=/home/oracle/exp_smsrun.log 成功！]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我的异常]]></title>
    <url>%2Fblog%2F3119c141.html</url>
    <content type="text"><![CDATA[#####1、Linux vsftp “上传 553 Could not create file” 问题： 解决这个问题步骤：121. setsebool -P ftpd_disable_trans 12. service vsftpd restart 2、Java OOM (java.lang.OutOfMemory)常见错误原因分析：1.程序死循环，导致内存泄露，造成OOM。2.读取大量信息（读文件内容，查询海量数据信息，构建对象加载大量信息，……等），堆内存空间分配不足造成OOM。]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Linux Telnet安装及配置]]></title>
    <url>%2Fblog%2Fc96b77c6.html</url>
    <content type="text"><![CDATA[安装CentOS系统时，由于最开始没有选择安装Telnet服务，现在想从Windows上通过Telnet连接Linux。于是便只能重新安装，这里介绍从光盘中进行安装。1、首先进入mnt目录创建一个文件夹，用于挂载光驱；1234[root@localhost ~]# cd /mnt[root@localhost ~]# mkdir cdrom[root@localhost ~]# mount /dev/cdrom /mnt/cdrom (或者 mount -t ext3 /dev/cdrom /mnt/cdrom)[root@localhost ~]# cd /mnt/cdrom 2、安装Telnet需要安装xinetd服务12[root@localhost cdrom]# find -name xinetd*./Packages/xinetd-2.3.14-29.el6.x86_64.rpm[root@localhost cdrom]# rpm -ivh ./Packages/xinetd-2.3.14-29.el6.x86_64.rpm 3、安装Telnet服务123[root@localhost cdrom]# find -name telnet*./Packages/telnet-0.17-46.el6.x86_64.rpm./Packages/telnet-server-0.17-46.el6.x86_64.rpm[root@localhost cdrom]# rpm -ivh ./Packages/telnet-0.17-46.el6.x86_64.rpm[root@localhost cdrom]# rpm -ivh ./Packages/telnet-server-0.17-46.el6.x86_64.rpm 4、修改Telnet服务配置1[root@localhost cdrom]#vi /etc/xinetd.d 将disable = yes 更改 no，或者注释掉5.开放Telnet对外端口23。 6、重启xinetd服务1[root@localhost cdrom]#service xinetd restart OK，于是在windows中，便可以通过telnet方式连接 Linux系统]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lombok 安装，JavaBean中消除冗长的get/set方法]]></title>
    <url>%2Fblog%2Fbc1da2d6.html</url>
    <content type="text"><![CDATA[在项目中引用Lombok lib，如果是通过Maven构建项目的，可以在pom.xml中增加对lib的依赖。 &lt;!-- 简化JavaBean get/set 方法 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.10&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; 如果你使用eclipse/myeclipse进行开发，在项目中引用了对lombok的依赖，然后发现代码编译的时候，还是没有生成get/set方法。这个时候还需要在eclipse/myeclipse中安装lombok，安装步骤如下：1、 将 lombok.jar 复制到 myeclipse.ini / eclipse.ini 所在的文件夹目录下；2.、打开 eclipse.ini / myeclipse.ini，在最后面插入以下两行并保存： -Xbootclasspath/a:lombok.jar -javaagent:lombok.jar 3、重启 eclipse / myeclipse 最后在JavaBean中如何使用，请参考Lombok 注解在线帮助文档：http://projectlombok.org/features/index.]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Lombok</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CXF 开发和部署 webservice 客户端注意事项]]></title>
    <url>%2Fblog%2Fa2040dea.html</url>
    <content type="text"><![CDATA[在做招商银行项目时，需要我们的系统集成招商银行的邮件服务器。招商银行邮件服务器采用webservice方式进行集成。经过多方面的考虑后，决定采用第三方开源框架Apache CXF进行webservice客户端开发。 该项目采用Apache CXF最新版本2.5.2版本，在使用该版本cxf开发时依赖的第三方包中与jaee.jar包有冲突；需要把jaee.jar中同名包下的文件进行删除。 另外采用jboss部署web应用程序时，需要注意以下两点： 1.将jaxb-api-2.2.3.jar,jaxws-api-2.1.jar包拷贝到jboss\lib\endorsed目录下；2.将jaxb-api-2.2.3.jar,jaxws-api-2.1.jar包拷贝到jdk1.5\jre\lib\endorsed目录下。 这里采用通过命令生成客户端代码进行调用： wsdl2java -d src -frontendjaxws21 -p com.easytrack.customization.cmb.integration.email -client http://99.1.101.169/coreservice/svc/coreservice.asmx?wsdl 最后根据生成的客户端代码适当的修改即可。 在开发和部署时注意以上两点，同时注意引用的CXF第三方包与自己本项目包的冲突。]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>CXF</tag>
        <tag>webservice</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Funsion Charts 参数大全]]></title>
    <url>%2Fblog%2Fd2f90363.html</url>
    <content type="text"><![CDATA[基础参数 animation 是否动画显示数据，默认为1(True)showNames 是否显示横向坐标轴(x轴)标签名称rotateNames 是否旋转显示标签，默认为0(False):横向显示showValues 是否在图表显示对应的数据值，默认为1(True)yAxisMinValue 指定纵轴(y轴)最小值，数字yAxisMaxValue 指定纵轴(y轴)最小值，数字showLimits 是否显示图表限值(y轴最大、最小值)，默认为1(True) 图表标题和轴名称 caption 图表主标题subCaption 图表副标题xAxisName 横向坐标轴(x轴)名称yAxisName 纵向坐标轴(y轴)名称 图表和画布的样式 bgColor 图表背景色，6位16进制颜色值canvasBgColor 画布背景色，6位16进制颜色值canvasBgAlpha 画布透明度，[0-100]canvasBorderColor 画布边框颜色，6位16进制颜色值canvasBorderThickness 画布边框厚度，[0-100]shadowAlpha 投影透明度，[0-100]showLegend 是否显示系列名，默认为1(True) 字体属性 baseFont 图表字体样式baseFontSize 图表字体大小baseFontColor 图表字体颜色，6位16进制颜色值outCnvBaseFont 图表画布以外的字体样式outCnvBaseFontSize 图表画布以外的字体大小outCnvBaseFontColor 图表画布以外的字体颜色，6位16进制颜色值 分区线和网格 numDivLines 画布内部水平分区线条数，数字divLineColor 水平分区线颜色，6位16进制颜色值divLineThickness 水平分区线厚度，[1-5]divLineAlpha 水平分区线透明度，[0-100]showAlternateHGridColor 是否在横向网格带交替的颜色，默认为0(False)alternateHGridColor 横向网格带交替的颜色，6位16进制颜色值alternateHGridAlpha 横向网格带的透明度，[0-100]showDivLinues 是否显示Div行的值，默认？？numVDivLines 画布内部垂直分区线条数，数字vDivLineColor 垂直分区线颜色，6位16进制颜色值vDivLineThickness 垂直分区线厚度，[1-5]vDivLineAlpha 垂直分区线透明度，[0-100]showAlternateVGridColor 是否在纵向网格带交替的颜色，默认为0(False)alternateVGridColor 纵向网格带交替的颜色，6位16进制颜色值alternateVGridAlpha 纵向网格带的透明度，[0-100] 数字格式 numberPrefix 增加数字前缀numberSuffix 增加数字后缀%为’%’formatNumberScale 是否格式化数字,默认为1(True),自动的给你的数字加上K（千）或M（百万）；若取0,则不加K或MdecimalPrecision 指定小数位的位数，[0-10]例如：=’0’取整divLineDecimalPrecision 指定水平分区线的值小数位的位数，[0-10]limitsDecimalPrecision 指定y轴最大、最小值的小数位的位数，[0-10]formatNumber 逗号来分隔数字(千位，百万位),默认为1(True)；若取0,则不加分隔符decimalSeparator 指定小数分隔符,默认为’.’thousandSeparato r指定千分位分隔符,默认为’,’Tool-tip/Hover 标题showhovercap 是否显示悬停说明框，默认为1(True)hoverCapBgColor 悬停说明框背景色，6位16进制颜色值hoverCapBorderColor 悬停说明框边框颜色，6位16进制颜色值hoverCapSepChar 指定悬停说明框内值与值之间分隔符,默认为’,’ 折线图的参数 lineThickness 折线的厚度anchorRadius 折线节点半径，数字anchorBgAlpha 折线节点透明度，[0-100]anchorBgColor 折线节点填充颜色，6位16进制颜色值anchorBorderColor 折线节点边框颜色，6位16进制颜色值Set 标签使用的参数value 数据值color 颜色link 链接（本窗口打开[Url]，新窗口打开[n-Url]，调用JS函数[JavaScript:函数]）name 横向坐标轴标签名称]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Funsion Charts</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 高频命令]]></title>
    <url>%2Fblog%2F4aa4f0f0.html</url>
    <content type="text"><![CDATA[1. halt 命令 关闭系统1$ halt -p 关闭系统后关闭电源； 2. reboot 重新启动系统1$ reboot 3. shutdown 关闭并重启系统1$ shutdown 4. service 管理系统服务12345$ service smb start$ service smb stop$ service smb restart]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Effective Java 随笔——第3、4条]]></title>
    <url>%2Fblog%2F49d3cb47.html</url>
    <content type="text"><![CDATA[第3条：用私有构造器或者枚举类型强化Singleton属性 Singleton指仅仅被实例化一次的类，通常被用来代表那些本质上唯一的系统组件。如果项目通过Spring构建，可以通过Spring来管理Bean，默认情况下在Bean的为单例模式。 第4条：通过私有构造器强化不可实例化的能力 有的类只有静态方法和静态域时，就可以定义私有构造器来明确说明该类不可实例化，一般多用于工具类。 第14条：在公有类中使用访问方法而非公有域 简书面向对象设计的思想，对于可变类来说，应该用包含私有域的公有设值方法（setter）类代替。例如：1234567891011121314151617181920public class Point &#123; private double x; private double y; public double getX()&#123; return x; &#125; public double getY()&#123; return y; &#125; public void setX(double x)&#123; this.x = x; &#125; public void setY(double y)&#123; this.y = y; &#125;&#125; 如果类可以在它所在的包外部进行访问，就提供访问方法 ，避免直接访问类的域。如果类是包级私有的，或者是私有的嵌套类，直接暴露它的数据域并没有本质的错误。]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis学习笔记--sets类型及操作1]]></title>
    <url>%2Fblog%2F354edc91.html</url>
    <content type="text"><![CDATA[set 是集合，和我们数学中的集合概念相似，对集合的操作有添加删除元素，有对多个集合求交并差等操作，操作中key 理解为集合的名字。 Redis 的set 是string 类型的无序集合。set 元素最大可以包含(2 的32 次方)个元素。 set 的是通过hash table 实现的，所以添加、删除和查找的复杂度都是O(1)。hash table 会随着添加或者删除自动的调整大小。需要注意的是调整hash table 大小时候需要同步（获取写锁）会阻塞其他读写操作，可能不久后就会改用跳表（skip list）来实现，跳表已经在sortedset 中使用了。关于set 集合类型除了基本的添加删除操作，其他有用的操作还包含集合的取并集(union)，交集(intersection)，差集(difference)。通过这些操作可以很容易的实现sns中的好友推荐和blog 的tag 功能。下面详细介绍set 相关命令： sadd向名称为key的set中添加元素12345678910111213redis 127.0.0.1:6379&gt; sadd myset &quot;hello&quot;(integer) 1redis 127.0.0.1:6379&gt; sadd myset &quot;world&quot;(integer) 1 #向set中添加重复的数据，添加将失败，并返回0redis 127.0.0.1:6379&gt; sadd myset &quot;world&quot; (integer) 0 redis 127.0.0.1:6379&gt; smembers myset1) &quot;world&quot;2) &quot;hello&quot;redis 127.0.0.1:6379&gt; 本例中，我们向myset 中添加了三个元素，但由于第三个元素跟第二个元素是相同的，所以第三个元素没有添加成功，最后我们用smembers 来查看myset 中的所有元素。 srem删除名称为key的set中的元素member12345678910111213141516redis 127.0.0.1:6379&gt; sadd myset2 &quot;one&quot;(integer) 1redis 127.0.0.1:6379&gt; sadd myset2 &quot;two&quot;(integer) 1redis 127.0.0.1:6379&gt; sadd myset2 &quot;three&quot;(integer) 1#本例中，我们向myset2 中添加了三个元素后，再调用srem 来删除one 和four，但由于元素中没有four 所以，此条srem 命令执行失败。redis 127.0.0.1:6379&gt; srem myset2 &quot;one&quot;(integer) 1redis 127.0.0.1:6379&gt; srem myset2 &quot;four&quot;(integer) 0redis 127.0.0.1:6379&gt; smembers myset21) &quot;three&quot;2) &quot;two&quot;redis 127.0.0.1:6379&gt; spop随机返回并删除名称为key的set中的一个元素123456789101112redis 127.0.0.1:6379&gt; sadd myset3 &quot;one&quot;(integer) 1redis 127.0.0.1:6379&gt; sadd myset3 &quot;two&quot;(integer) 1redis 127.0.0.1:6379&gt; sadd myset3 &quot;three&quot;(integer) 1redis 127.0.0.1:6379&gt; spop myset3&quot;three&quot;redis 127.0.0.1:6379&gt; smembers myset31) &quot;two&quot;2) &quot;one&quot;redis 127.0.0.1:6379&gt; 本例中，我们向myset3 中添加了三个元素后，再调用spop 来随机删除一个元素，可以看到three 元素被删除了。 sdiff返回所有给定key与第一个key的差集。1234567891011121314redis 127.0.0.1:6379&gt; smembers myset21) &quot;three&quot;2) &quot;two&quot;redis 127.0.0.1:6379&gt; smembers myset31) &quot;two&quot;2) &quot;one&quot;redis 127.0.0.1:6379&gt; sdiff myset2 myset31) &quot;three&quot;redis 127.0.0.1:6379&gt;#我们也可以将myset2 和myset3 换个顺序来看一下结果:redis 127.0.0.1:6379&gt; sdiff myset3 myset21) &quot;one&quot;redis 127.0.0.1:6379&gt; sdiffstore返回所有给定key与第一个key的差集，并将结果存为另一个key1234567891011redis 127.0.0.1:6379&gt; smembers myset21) &quot;three&quot;2) &quot;two&quot;redis 127.0.0.1:6379&gt; smembers myset31) &quot;two&quot;2) &quot;one&quot;redis 127.0.0.1:6379&gt; sdiffstore myset4 myset2 myset3(integer) 1redis 127.0.0.1:6379&gt; smembers myset41) &quot;three&quot;redis 127.0.0.1:6379&gt; sinterstore返回所有给定key的交集，并将结果存为另一个key1234567891011redis 127.0.0.1:6379&gt; smembers myset21) &quot;three&quot;2) &quot;two&quot;redis 127.0.0.1:6379&gt; smembers myset31) &quot;two&quot;2) &quot;one&quot;redis 127.0.0.1:6379&gt; sinterstore myset5 myset2 myset3(integer) 1redis 127.0.0.1:6379&gt; smembers myset51) &quot;two&quot;redis 127.0.0.1:6379&gt; 通过本例的结果可以看出, myset2 和myset3 的交集被保存到myset5 中了 sunion返回所有给定key 的并集1234567891011redis 127.0.0.1:6379&gt; smembers myset21) &quot;three&quot;2) &quot;two&quot;redis 127.0.0.1:6379&gt; smembers myset31) &quot;two&quot;2) &quot;one&quot;redis 127.0.0.1:6379&gt; sunion myset2 myset31) &quot;three&quot;2) &quot;one&quot;3) &quot;two&quot;redis 127.0.0.1:6379&gt; 通过本例的结果可以看出, myset2 和myset3 的并集被查出来了 sunionstore返回所有给定key 的并集，并将结果存为另一个key12345678910111213redis 127.0.0.1:6379&gt; smembers myset21) &quot;three&quot;2) &quot;two&quot;redis 127.0.0.1:6379&gt; smembers myset31) &quot;two&quot;2) &quot;one&quot;redis 127.0.0.1:6379&gt; sunionstore myset6 myset2 myset3(integer) 3redis 127.0.0.1:6379&gt; smembers myset61) &quot;three&quot;2) &quot;one&quot;3) &quot;two&quot;redis 127.0.0.1:6379&gt; 通过本例的结果可以看出, myset2 和myset3 的并集被保存到myset6 中了。]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis学习笔记--sets类型及操作2]]></title>
    <url>%2Fblog%2Fac478d2b.html</url>
    <content type="text"><![CDATA[smove从第一个key 对应的set 中移除member 并添加到第二个对应set 中1234567891011redis 127.0.0.1:6379&gt; smembers myset21) &quot;three&quot;2) &quot;two&quot;redis 127.0.0.1:6379&gt; smembers myset31) &quot;two&quot;2) &quot;one&quot;redis 127.0.0.1:6379&gt; smove myset2 myset7 three(integer) 1redis 127.0.0.1:6379&gt; smembers myset71) &quot;three&quot;redis 127.0.0.1:6379&gt; 通过本例可以看到，myset2 的three 被移到myset7 中了 scard返回名称为key的set的元素个数。123redis 127.0.0.1:6379&gt; scard myset2(integer) 1redis 127.0.0.1:6379&gt; 通过本例可以看到，myset2 的成员数量为1 sismember测试member 是否是名称为key 的set 的元素1234567redis 127.0.0.1:6379&gt; smembers myset21) &quot;two&quot;redis 127.0.0.1:6379&gt; sismember myset2 two(integer) 1redis 127.0.0.1:6379&gt; sismember myset2 one(integer) 0redis 127.0.0.1:6379&gt; 通过本例可以看到，two 是myset2 的成员，而one 不是。 srandmember随机返回名称为key 的set 的一个元素，但是不删除元素12345678redis 127.0.0.1:6379&gt; smembers myset31) &quot;two&quot;2) &quot;one&quot;redis 127.0.0.1:6379&gt; srandmember myset3&quot;two&quot;redis 127.0.0.1:6379&gt; srandmember myset3&quot;one&quot;redis 127.0.0.1:6379&gt;]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[决策树学习]]></title>
    <url>%2Fblog%2F20ed6df.html</url>
    <content type="text"><![CDATA[决策树学习的适用问题通常决策树学习最适合具有以下特征的问题： 实例是由“属性-值”对（pair）表示的。实例是用一系列固定的属性（例如，Temperature）和它们的值（例如，Hot）来描述的。最简单的决策树学习中，每一个属性取少数的分离的值（例如，Hot、Mild、Cold）。然而，扩展的算法也运行处理值域为实数的属性（利润，数字表示的温度）。 目标函数具有离散的输出值。决策树给每个实例赋予一个布尔型的分类（例如，yes或no）。决策树方法很容易扩展到学习有两个以上输出值的函数。一种更强有力的扩展算法运行学习具有实数值输出的函数，尽管决策树在这种情况下的应用不太常见。 可能需要析取的描述，决策树很自然代表了析取表达式。 训练数据可以包含错误。决策树学习对错误有很好的鲁棒性，无论是训练样例所属的分类错误还是描述这些样例的属性值错误。 训练数据可以包含缺少属性值的实例。决策树学习甚至可以在未知属性值的训练样例中使用（仅有一部分训练样例知道当天的湿度）。 基本的决策树学习算法ID3算法，通过自顶向下构造决策树来进行学习。构造过程是从“哪一个属性将在树的根节点被测试？”这个问题开始的。为了回答这个问题，使用统计测试来确定每一个实例属性单独分类训练样例的能力。分类能力最好的属性被选作为树的根节点的测试。然后为根节点属性的每个可能值产生一个分支，并把训练样例排列到适当的分支之下。然后重复整个过程，用每个分支节点关联的训练样例来选取在该点呗测试的最佳 属性。这形成了对合格决策树的贪婪搜索，也就是算法从不回溯重新考虑以前的选择。 ID3算法的核心问题是选取在树的每个节点要测试的属性。我们希望选择的是最有助于分类实例的属性。那么衡量属性价值的一个好的定量标准是什么呢？这里将定义一个统计属性，称为“信息增益”，用来衡量给定的属性区分训练样例的能力。ID3算法在增长树的每一步使用这个信息增益标准从候选属性中选择属性。 用 “熵” 度量样例的均一性，它刻画了任意样例的纯度（purity），熵介于0~1之间。在信息论中，熵被用来衡量一个随机变量出现的期望值。 与其它的归纳学习算法一样，ID3算法可以被描述为从一个假设空间搜索一个拟合训练样例的假设。被ID3算法搜索的假设空间就是可能的决策树的集合。ID3算法以一种简单到复杂的爬山算法遍历这个假设空间，从空的树开始，然后逐步考虑更加复杂的假设，目的是搜索到一个正确分类训练数据的决策树。引导这种爬山搜索的评估函数是信息增益度。 决策树学习的常见问题决策树学习的实际问题包括确定决策树增长的深度；处理连续值的属性；选择一个适当的属性筛选度量标准；处理属性值不完整的训练数据；处理不同代价的属性；以及提高计算效率。 过度拟合：给定一个假设空间 H，一个假设h∈H，如果存在其他的假设h´∈H，使得在训练样例上h 的错误率比h´小，但在整个实例分布上h´的错误率比h 小，那么就说假设h 过度拟合（overfit）训练数据。]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>AI</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python os.path 模块]]></title>
    <url>%2Fblog%2Fe6565eb5.html</url>
    <content type="text"><![CDATA[os.path.abspath(path) #返回绝对路径os.path.basename(path) #返回文件名os.path.commonprefix(list) #返回list(多个路径)中，所有path共有的最长的路径。os.path.dirname(path) #返回文件路径os.path.exists(path) #路径存在则返回True,路径损坏返回Falseos.path.lexists #路径存在则返回True,路径损坏也返回Trueos.path.expanduser(path) #把path中包含的”~”和”~user”转换成用户目录os.path.expandvars(path) #根据环境变量的值替换path中包含的”$name”和”${name}”os.path.getatime(path) #返回最后一次进入此path的时间。os.path.getmtime(path) #返回在此path下最后一次修改的时间。os.path.getctime(path) #返回path的大小os.path.getsize(path) #返回文件大小，如果文件不存在就返回错误os.path.isabs(path) #判断是否为绝对路径os.path.isfile(path) #判断路径是否为文件os.path.isdir(path) #判断路径是否为目录os.path.islink(path) #判断路径是否为链接os.path.ismount(path) #判断路径是否为挂载点（）os.path.join(path1[, path2[, …]]) #把目录和文件名合成一个路径os.path.normcase(path) #转换path的大小写和斜杠os.path.normpath(path) #规范path字符串形式os.path.realpath(path) #返回path的真实路径os.path.relpath(path[, start]) #从start开始计算相对路径os.path.samefile(path1, path2) #判断目录或文件是否相同os.path.sameopenfile(fp1, fp2) #判断fp1和fp2是否指向同一文件os.path.samestat(stat1, stat2) #判断stat tuple stat1和stat2是否指向同一个文件os.path.split(path) #把路径分割成dirname和basename，返回一个元组os.path.splitdrive(path) #一般用在windows下，返回驱动器名和路径组成的元组os.path.splitext(path) #分割路径，返回路径名和文件扩展名的元组os.path.splitunc(path) #把路径分割为加载点与文件os.path.walk(path, visit, arg) #遍历path，进入每个目录都调用visit函数，visit函数必须有3个参数(arg, dirname, names)，dirname表示当前目录的目录名，names代表当前目录下的所有文件名，args则为walk的第三个参数os.path.supports_unicode_filenames #设置是否支持unicode路径名]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微服务化架构特征]]></title>
    <url>%2Fblog%2Fbf5e30ae.html</url>
    <content type="text"><![CDATA[服务化架构：一种架构风格，即微服务架构。1.单个服务尽量专注一件事情，高内聚、低耦合；2.进程隔离；3.每个服务可以独立开发、测试、构建、部署；4.小且灵活； 微服务架构特征： 系统由多个服务组成，每个服务有明确的边界； 服务独立开发、编译、部署、测试、发布，有独立工程、独立版本、接口契约化，进程隔离； 由一个10人以下团队全生命周期负责，团队的目标负责产品的全生命周期，而不是负责一个短期的项目； 技术中立，不要求服务的编程语言统一。不同服务可以采用不同的编程语言实现，有利于逐步引入新技术。 智能服务端点和轻量级高性能通信机制。服务开发框架内置服务基本功能，如日志、度量、数据访问、输入校验、权限等，使得开发人员可以聚焦于业务服务的业务逻辑代码开发，降低了服务开发的门槛。 服务无状态，服务自动弹性伸缩。服务的无状态通过业务逻辑与数据分离，数据、会话保存在DB、Cache、对象存储等服务来实现；服务实例按需进行伸缩。 服务数据去中心化。每个服务拥有自己的数据库，服务不能直接访问其它服务的数据库，只能通过服务接口方案其它服务的数据。 服务去中心化治理。服务支持多版本并存、灰度发布、依赖关系管理、调用链分析快速故障定界。 Design for failure。任意服务节点失效、网络闪断等故障不影响业务正常运行。 重用、组合已有的服务实现新的业务功能服务。业务应用在实现功能时，会调用已有的服务，如Cache、MQ、IAM等公共服务，实现自己的业务功能。 微服务带来的好处和挑战好处： 服务模块的边界更清晰：微服务强调模块化结果（REST接口调用），这对大型团队非常重要。 支持独立不是：简单服务更易部署，由于服务是自治的，出现问题之后不会引起系统崩溃。 运行技术多样性：有了微服务，你可以混合使用多种语言、开发框架和数据存储技术。 挑战： 分布式变成难度大有风险：分布式变成难度更大，远程调用更慢且总存在失败风险。 需处理分布式系统的一致性：对于分布式系统来说，保持一致性非常困难，意味着大家都要处理最终一致性。 增加运维复杂性：需要一个成熟的运维团队（机制）来管理大量需要频繁部署的服务。]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>架构设计</tag>
        <tag>微服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构设计原则]]></title>
    <url>%2Fblog%2F88049151.html</url>
    <content type="text"><![CDATA[架构坚持组件化，持续重构，小而美。架构设计十大原则： 1.全面解耦原则：对业务进行抽象建模，业务数据与业务逻辑解耦，软硬件解耦，平台和产品解耦，系统各部件解耦。模块、组件高内聚，低耦合。2.服务化/组件化原则：以服务、数据为中心，构建服务化、组件化架构，具备灵活，按需组合的能力。3.接口隔离及服务自治原则：通过接口隐藏服务/组件实现细节，服务/组件只能通过接口进行交互，接口契约化，标准化，跨版本兼容；服务/组件可独立发展、独立发布、独立升级，服务自治，可视、可管、可控、可测、可维，故障自愈。4.弹性伸缩原则：构建全分布云化架构，或借鉴云化架构思想，每个服务具备横向扩展能力，支持按需使用，自动弹性伸缩，可动态替换、灵活部署，支撑高性能、高吞吐量、高并发、高可用业务场景。5.安全可靠环保原则：构建最小权限，纵深防御、最小公共化、权限分离、不轻信、开放设计、完全仲裁、失效安全、保护薄弱环节、安全机制、经济性、用户接受度以及加强隐私保护的安全体系，确保系统、网络和数据的机密性、完整性、可用性、可追溯性；以业务系统零故障为导向；按需构筑分层分级的可靠性，通过故障的预流、预防、快速故障恢复、避免故障发生；系统资源使用有效最大化，实现节能、节地、节材、环保。6.用户体验和自动化运维原则：面向业务获取和使用场景，构建实时、按需、在线、自助、社区化、方便易用的用户体验；支持远程、自动、智能、安全、高效地完成网规/网设、安装、部署、调测、验收、扩缩容、软件升级、打补丁、日常维护、问题处理。7.开放生态原则：面向生态场景，按需开放平台设施、中间件、数据、业务逻辑、UI等能力；构建开放生态、支持分层、远程、自动、自助、简单高效地完成定制、集成、第三方应用开发。8.高效开发原则：创建支持迭代、增量、持续交付的架构，支持部件独立开发、自动化编译构建、测试、集成验证、并易于高效修改和持续优化；支持开发组织小型化，扁平化，支持小团队独立高效并行开发。9.柔性供应制造原则：模块化设计，模块/物料归一化、标准化，支持自动化、数字化、智能化、随需应变的柔性制造。10.持续演进原则：架构并非一蹴而就，需要有效地管理架构需求；持续构建和发展架构，适应业务需求变化，适时引入业界最佳实践，及时重构，确保架构生命力和竞争力。]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>架构设计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[元数据管理]]></title>
    <url>%2Fblog%2Fdb36e9b.html</url>
    <content type="text"><![CDATA[基本概念元数据描述的是数据的背景、内容、数据结构及其生命周期管理。简而言之，元数据是“数据的背景”。通俗可以理解为数据模型就是元数据。 元数据管理全景包括三部分内容： 元数据模型 元数据拓扑结构 元数据管理方法论 元数据管理最主要是能方便集成不同数据库、数据模型、OLAP和ETL(数据抽取、转换和装载)工具所包含的各式各样的元数据。元数据包括业务规则、数据源、汇总级别、数据别名、数据转换规则、技术配置、数据访问权限、数据用途等。 企业元数据模型在企业内部，业务和技术（IT）领域，彼此是一对一的关系，对元数据同样适用。业务元数据和IT/技术元数据也是一一对应。不这两个分支相交的三层概念如下表详述： 分层 业务元数据 IT/技术元数据 顶层 概念/主题域 系统 中层 业务实体/业务交易 技术对象 底层 业务术语 技术元素 顶层 ： 业务元数据中的最高概念层表示为‘主题域’戒者‘概念’。 例如HR (人力资源), CRM (客户关系管理)以及支付等等，往往在收集业务需求时界定。不乊对应，技术系统将根据每个主题域迚行开収，例如Oracle可以为HR主题域开収HRMS，也可以为CRM实施SIEBEL系统。这些形成了IT/技术元数据中的‘系统’层。 中层：每一个主题域可以被分解成业务实体戒者业务交易。客户、供应商、合作方、客户使用的仸何应用，以及诸如订单管理这样的业务交易等，形成了CRM中的业务实体。每个业务实体的细节通过技术对象来存储，比如用数据表、报表以及映射关系等。 底层：业务术诧形成了业务元数据最底层的抽象概念。对业务实体而言，比如某个应用，业务术诧可以是客户ID、客户姓名以及产品ID等等。而IT/技术的最底层是技术元素。元素级的细节信息，如列、字段戒转换形成了技术元素。 前台元数据后台元数据过程元数据 元数据集中式和分布式管理 元数据配置管理 BIDS元数据管理方法论：元数据框架定义]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>元数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[软件架构理解]]></title>
    <url>%2Fblog%2F30ef81f5.html</url>
    <content type="text"><![CDATA[系统架构：主要表述了契合一个环境的系统的基本元素及元素之间关系构成的结构集，在环境中体现出来的基本属性，以及设计与演进的原则。 架构包括三个部分： 组成系统的基本元素、元素之间关系构成的结构集 基本属性 设计与演进原则 架构的五维能力：架构支撑和反映了系统5个方面的基本能力，每个方面都反映了架构的一类关注点 开发与演进类属性：支撑系统能够快速、高效、高质量开发出来，并能够方便修改、重用，持续演进，相应的基本属性包括可构建性、可测试性、可演进性、可重用性和易学习性。 生态系统类属性：支撑系统构建开放、打造生态系统的能力，相应的基本属性包括开放性、可定制性、易集成性和兼容性。 交付类属性：支撑系统快速交付、快速部署的能力，相应的基本属性包括可供应性、可制造性和可部署性。 运行类属性：支撑系统运行维护的各种DFX属性，相应的基本属性包括可靠性、安全性、可服务性、性能、可伸缩性/可扩展性、节能减排和易用性。 功能属性：支撑系统提供有价值的功能特性的能力。]]></content>
      <categories>
        <category>程序随记</category>
      </categories>
      <tags>
        <tag>架构设计</tag>
        <tag>系统架构</tag>
      </tags>
  </entry>
</search>
